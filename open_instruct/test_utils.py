# Copyright 2024 AllenAI Team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# Copied from https://github.com/huggingface/alignment-handbook/blob/main/tests/test_data.py
import time
import unittest
from unittest import mock

import pytest
import vllm
from dateutil import parser
from parameterized import parameterized

from open_instruct import grpo_fast, utils
from open_instruct.finetune import FlatArguments

MODEL_DIMS: dict[str, utils.ModelDims] = {
    "Qwen/Qwen2.5-7B": utils.ModelDims(
        num_layers=28,
        hidden_size=3584,
        intermediate_size=18944,
        vocab_size=152064,
        num_attn_heads=28,
        head_dim=128,
        num_kv_heads=4,
        device_name="h100",
    ),
    "Qwen/Qwen2.5-1.5B": utils.ModelDims(
        num_layers=28,
        hidden_size=1536,
        intermediate_size=8960,
        vocab_size=151936,
        num_attn_heads=12,
        head_dim=128,
        num_kv_heads=2,
        device_name="h100",
    ),
    "Qwen/Qwen3-1.7B": utils.ModelDims(
        num_layers=28,
        hidden_size=2048,
        intermediate_size=6144,
        vocab_size=151936,
        num_attn_heads=16,
        head_dim=128,
        num_kv_heads=8,
        device_name="h100",
    ),
}


class GetDatasetsTest(unittest.TestCase):
    """Each of these test datasets has 100 examples"""

    def test_loading_data_args(self):
        dataset_mixer = {
            "HuggingFaceH4/testing_alpaca_small": 0.5,
            "HuggingFaceH4/testing_self_instruct_small": 0.3,
            "HuggingFaceH4/testing_codealpaca_small": 0.2,
        }
        datasets = utils.get_datasets(dataset_mixer, columns_to_keep=["prompt", "completion"])
        self.assertEqual(len(datasets["train"]), 100)
        self.assertEqual(len(datasets["test"]), 300)

    def test_loading_with_unit_fractions(self):
        dataset_mixer = {
            "HuggingFaceH4/testing_alpaca_small": 1.0,
            "HuggingFaceH4/testing_self_instruct_small": 1.0,
            "HuggingFaceH4/testing_codealpaca_small": 1.0,
        }
        datasets = utils.get_datasets(dataset_mixer, columns_to_keep=["prompt", "completion"])
        self.assertEqual(len(datasets["train"]), 300)
        self.assertEqual(len(datasets["test"]), 300)

    def test_loading_with_fractions_greater_than_unity(self):
        dataset_mixer = {"HuggingFaceH4/testing_alpaca_small": 0.7, "HuggingFaceH4/testing_self_instruct_small": 0.4}
        datasets = utils.get_datasets(dataset_mixer, columns_to_keep=["prompt", "completion"])
        self.assertEqual(len(datasets["train"]), 70 + 40)
        self.assertEqual(len(datasets["test"]), 200)

    def test_loading_fails_with_negative_fractions(self):
        dataset_mixer = {"HuggingFaceH4/testing_alpaca_small": 0.7, "HuggingFaceH4/testing_self_instruct_small": -0.3}
        with pytest.raises(ValueError, match=r"Dataset fractions / lengths cannot be negative."):
            utils.get_datasets(dataset_mixer, columns_to_keep=["prompt", "completion"])

    def test_loading_single_split_with_unit_fractions(self):
        dataset_mixer = {"HuggingFaceH4/testing_alpaca_small": 1.0}
        datasets = utils.get_datasets(dataset_mixer, splits=["test"], columns_to_keep=["prompt", "completion"])
        self.assertEqual(len(datasets["test"]), 100)
        self.assertRaises(KeyError, lambda: datasets["train"])

    def test_loading_preference_data(self):
        dataset_mixer = {
            "ai2-adapt-dev/ultrafeedback-small": 1000,
            "ai2-adapt-dev/summarize_from_feedback_small": 1000,
        }
        pref_datasets = utils.get_datasets(dataset_mixer, splits=["train"], columns_to_keep=["chosen", "rejected"])
        self.assertEqual(len(pref_datasets["train"]), 2000)

    def test_time_parser_used_in_get_beaker_dataset_ids(self):
        # two special cases which beaker uses
        self.assertTrue(parser.parse("2024-09-16T19:03:02.31502Z"))
        self.assertTrue(parser.parse("0001-01-01T00:00:00Z"))


def _setup_beaker_mocks(mock_beaker_from_env, mock_is_beaker_job, initial_description):
    """Shared mock setup for beaker tests."""
    mock_is_beaker_job.return_value = True

    mock_client = mock.MagicMock()
    mock_beaker_from_env.return_value = mock_client

    # Mock the workload object
    mock_workload = mock.MagicMock()
    mock_client.workload.get.return_value = mock_workload

    # Mock the spec object returned by experiment.get_spec
    mock_spec = mock.MagicMock()
    mock_spec.description = initial_description
    mock_client.experiment.get_spec.return_value = mock_spec

    description_history = []

    def track_description(workload, description=None):
        if description is not None:
            description_history.append(description)

    mock_client.workload.update.side_effect = track_description

    return mock_client, mock_spec, description_history


class TestBeakerDescription(unittest.TestCase):
    """Test the beaker description update function."""

    @mock.patch("os.environ.get")
    @mock.patch("beaker.Beaker.from_env")
    @mock.patch("open_instruct.utils.is_beaker_job")
    def test_description_does_not_accumulate(self, mock_is_beaker_job, mock_beaker_from_env, mock_environ_get):
        """Test that the description doesn't accumulate git info and wandb URLs on repeated calls."""
        # Configure os.environ.get mock
        env_values = {"BEAKER_WORKLOAD_ID": "test-id-123", "GIT_COMMIT": "abc123", "GIT_BRANCH": "main"}
        mock_environ_get.side_effect = lambda key, default=None: env_values.get(key, default)

        mock_client, mock_spec, description_history = _setup_beaker_mocks(
            mock_beaker_from_env, mock_is_beaker_job, "Beaker-Mason job."
        )

        wandb_url = "https://wandb.ai/ai2-llm/open_instruct_internal/runs/1f3ow3oh"
        start_time = time.time()

        original_descriptions = {}

        for step in [10, 20, 30]:
            utils.maybe_update_beaker_description(
                current_step=step,
                total_steps=100,
                start_time=start_time,
                wandb_url=wandb_url,
                original_descriptions=original_descriptions,
            )
            if description_history:
                mock_spec.description = description_history[-1]

        self.assertEqual(len(description_history), 3)

        for i, desc in enumerate(description_history):
            git_commit_count = desc.count("git_commit:")
            git_branch_count = desc.count("git_branch:")
            wandb_count = desc.count(wandb_url)

            self.assertEqual(
                git_commit_count,
                1,
                f"Step {(i + 1) * 10}: git_commit should appear once, but appears {git_commit_count} times in: {desc}",
            )
            self.assertEqual(
                git_branch_count,
                1,
                f"Step {(i + 1) * 10}: git_branch should appear once, but appears {git_branch_count} times in: {desc}",
            )
            self.assertEqual(
                wandb_count,
                1,
                f"Step {(i + 1) * 10}: wandb URL should appear once, but appears {wandb_count} times in: {desc}",
            )

            self.assertIn("Beaker-Mason job.", desc)
            self.assertIn("git_commit: abc123", desc)
            self.assertIn("git_branch: main", desc)
            self.assertIn(wandb_url, desc)
            self.assertIn(f"% complete (step {(i + 1) * 10}/100)", desc)

    @mock.patch("os.environ.get")
    @mock.patch("beaker.Beaker.from_env")
    @mock.patch("open_instruct.utils.is_beaker_job")
    def test_description_without_progress(self, mock_is_beaker_job, mock_beaker_from_env, mock_environ_get):
        """Test description updates without progress information."""
        # Configure os.environ.get mock
        env_values = {"BEAKER_WORKLOAD_ID": "test-id-123", "GIT_COMMIT": "def456", "GIT_BRANCH": "dev"}
        mock_environ_get.side_effect = lambda key, default=None: env_values.get(key, default)

        mock_client, mock_spec, description_history = _setup_beaker_mocks(
            mock_beaker_from_env, mock_is_beaker_job, "Initial job description"
        )

        original_descriptions = {}

        utils.maybe_update_beaker_description(
            wandb_url="https://wandb.ai/team/project/runs/xyz789", original_descriptions=original_descriptions
        )

        self.assertEqual(len(description_history), 1)
        desc = description_history[0]

        self.assertIn("Initial job description", desc)
        self.assertIn("git_commit: def456", desc)
        self.assertIn("git_branch: dev", desc)
        self.assertIn("https://wandb.ai/team/project/runs/xyz789", desc)
        self.assertNotIn("% complete", desc)


class TestUtilityFunctions(unittest.TestCase):
    """Test utility functions in utils module."""

    @parameterized.expand(
        [
            ("basic_repeat", ["a", "b", "c"], 3, ["a", "a", "a", "b", "b", "b", "c", "c", "c"]),
            ("repeat_once", ["a", "b", "c"], 1, ["a", "b", "c"]),
            ("repeat_zero", ["a", "b", "c"], 0, []),
            ("empty_sequence", [], 3, []),
            ("integers", [1, 2, 3], 2, [1, 1, 2, 2, 3, 3]),
            ("mixed_types", ["a", 1, None, True], 2, ["a", "a", 1, 1, None, None, True, True]),
            ("single_element", ["x"], 5, ["x", "x", "x", "x", "x"]),
        ]
    )
    def test_repeat_each(self, name, sequence, k, expected):
        """Test the repeat_each function with various inputs."""
        result = utils.repeat_each(sequence, k)
        self.assertEqual(result, expected)

    def test_repeat_each_mutation_isolation(self):
        """Test that mutating a sequence item after repeat_each doesn't change the repeated versions."""
        original_list = [1, 2]
        sequence = [original_list, ["a", "b"], [True, False]]
        result = utils.repeat_each(sequence, 2)

        # Result should be: [[1, 2], [1, 2], ["a", "b"], ["a", "b"], [True, False], [True, False]]
        self.assertEqual(len(result), 6)

        # Mutate the original list
        original_list.append(3)

        # The repeated versions should all be affected since they are references to the same object
        self.assertEqual(result[0], [1, 2, 3])
        self.assertEqual(result[1], [1, 2, 3])

        # But the other lists should remain unchanged
        self.assertEqual(result[2], ["a", "b"])
        self.assertEqual(result[3], ["a", "b"])
        self.assertEqual(result[4], [True, False])
        self.assertEqual(result[5], [True, False])

    @parameterized.expand(
        [
            ("https://wandb.ai/org/project/runs/runid", "org/project/runid"),
            (
                "https://wandb.ai/ai2-llm/open_instruct_internal/runs/5nigq0mz",
                "ai2-llm/open_instruct_internal/5nigq0mz",
            ),
            (
                "https://wandb.ai/ai2-llm/open_instruct_internal/runs/vjyp36sp",
                "ai2-llm/open_instruct_internal/vjyp36sp",
            ),
        ]
    )
    def test_wandb_url_to_run_path(self, url: str, expected_run_path: str):
        self.assertEqual(utils.wandb_url_to_run_path(url), expected_run_path)

    @parameterized.expand(
        [
            ("NVIDIA H100 80GB HBM3", "h100"),
            ("NVIDIA L40S", "l40s"),
            ("NVIDIA RTX A6000", "a6000"),
            ("NVIDIA A100-SXM4-80GB", "a100"),
            ("NVIDIA RTX PRO 6000 Blackwell Server Edition", "pro 6000"),
            ("NVIDIA RTX 6000 Ada Generation", "6000"),
        ]
    )
    def test_get_device_name(self, device_name: str, expected_name: str):
        result = utils.get_device_name(device_name)
        self.assertEqual(result, expected_name)

    @parameterized.expand(
        [
            ("NVIDIA H100 80GB HBM3", {"flops": 990e12, "memory_size": 80e9, "memory_bandwidth": 3.35e12}),
            ("NVIDIA RTX A6000", {"flops": 155e12, "memory_size": 48e9, "memory_bandwidth": 768e9}),
            (
                "NVIDIA RTX PRO 6000 Blackwell Server Edition",
                {"flops": 503.8e12, "memory_size": 96e9, "memory_bandwidth": 1792e9},
            ),
            ("NVIDIA RTX 6000 Ada Generation", {"flops": 728.5e12, "memory_size": 48e9, "memory_bandwidth": 960e9}),
        ]
    )
    def test_get_device_name_returns_correct_specs(self, device_name: str, expected_specs: dict):
        device_key = utils.get_device_name(device_name)
        specs = utils.GPU_SPECS[device_key]
        self.assertEqual(specs["flops"], expected_specs["flops"])
        self.assertEqual(specs["memory_size"], expected_specs["memory_size"])
        self.assertEqual(specs["memory_bandwidth"], expected_specs["memory_bandwidth"])


class TestFlatArguments(unittest.TestCase):
    def test_additional_model_args(self) -> None:
        parser = utils.ArgumentParserPlus(FlatArguments)
        (args,) = parser.parse_args_into_dataclasses(
            ["--additional_model_arguments", '{"int": 1, "bool": true, "float": 0.0, "float2": 5e-7}']
        )
        self.assertIsInstance(args.additional_model_arguments, dict)
        self.assertIsInstance(args.additional_model_arguments["int"], int)
        self.assertIsInstance(args.additional_model_arguments["bool"], bool)
        self.assertIsInstance(args.additional_model_arguments["float"], float)
        self.assertIsInstance(args.additional_model_arguments["float2"], float)

    def test_no_additional_model_args(self) -> None:
        parser = utils.ArgumentParserPlus(FlatArguments)
        (args,) = parser.parse_args_into_dataclasses(["--exp_name", "test"])
        self.assertIsInstance(args.additional_model_arguments, dict)
        self.assertFalse(args.additional_model_arguments)


class TestModelDimsQwen25(unittest.TestCase):
    def test_qwen25_7b_flops_calculation(self):
        sequence_length = 34048
        model_dims = MODEL_DIMS["Qwen/Qwen2.5-7B"]
        total_flops = model_dims.flops([sequence_length], [1])
        prefill_flops = model_dims.flops([sequence_length], None)
        decode_flops = total_flops - prefill_flops
        decode_flops_in_gflops = decode_flops / 1e9
        self.assertAlmostEqual(decode_flops_in_gflops, 27.92, delta=0.01)

    def test_qwen25_7b_memory_calculation(self):
        sequence_length = 34048
        batch_size = 16
        model_dims = MODEL_DIMS["Qwen/Qwen2.5-7B"]

        embedding_params = model_dims.vocab_size * model_dims.hidden_size
        weight_params = model_dims.num_params - embedding_params
        lm_head_bytes = model_dims.vocab_size * model_dims.hidden_size
        embedding_bytes = model_dims.hidden_size

        total_bytes = weight_params / batch_size
        total_bytes += lm_head_bytes + embedding_bytes
        total_bytes += 2 * model_dims.num_kv_heads * model_dims.head_dim * model_dims.num_layers * sequence_length
        total_bytes += 2 * model_dims.num_layers * model_dims.num_kv_heads * model_dims.head_dim
        total_bytes *= 2

        memory_in_gb = total_bytes / 1e9
        self.assertAlmostEqual(memory_in_gb, 3.926, delta=0.01)

    @parameterized.expand(
        [
            ("beaker_212_percent_bug", "Qwen/Qwen3-1.7B", 8, 4, 145, 274.7, 1, 1, 1, 1, 2.048383, 5.0),
            ("small_batch", "Qwen/Qwen2.5-7B", 2, 2, 512, 512, 2, 2, 2, 1, 5.0, 3.0),
            ("large_batch", "Qwen/Qwen2.5-7B", 16, 2, 256, 256, 2, 4, 1, 2, 8.55, 4.0),
        ]
    )
    def test_mfu_mbu_under_100_percent(
        self,
        name,
        model_name,
        num_prompts,
        samples_per_prompt,
        prompt_len,
        response_len,
        num_inference_gpus,
        num_training_gpus,
        num_engines,
        num_gpus_per_engine,
        total_generation_time,
        training_time,
    ):
        prompt_lengths = [prompt_len] * num_prompts
        if name == "beaker_212_percent_bug":
            response_lengths = [275] * 22 + [274] * 10
        else:
            response_lengths = [int(response_len)] * (num_prompts * samples_per_prompt)

        metrics = grpo_fast.calculate_utilization_metrics(
            model_dims=MODEL_DIMS[model_name],
            prompt_lengths=prompt_lengths,
            response_lengths=response_lengths,
            total_generation_time=total_generation_time,
            samples_per_prompt=samples_per_prompt,
            num_engines=num_engines,
            num_gpus_per_engine=num_gpus_per_engine,
            training_time=training_time,
            num_training_gpus=num_training_gpus,
        )

        self.assertLessEqual(metrics["actor_mfu"], 100)
        self.assertLessEqual(metrics["actor_mbu"], 100)
        self.assertLessEqual(metrics["learner_mfu"], 100)

    def test_mbu_157_percent_reproduction(self):
        prompt_lengths = [
            183,
            147,
            64,
            312,
            193,
            206,
            171,
            436,
            80,
            176,
            210,
            165,
            268,
            195,
            230,
            93,
            162,
            56,
            362,
            135,
            257,
            57,
            304,
            163,
            326,
            324,
            155,
            119,
            108,
            234,
            82,
            205,
        ]
        response_lengths = [
            108,
            238,
            308,
            506,
            182,
            255,
            248,
            265,
            221,
            230,
            347,
            247,
            497,
            410,
            223,
            244,
            540,
            194,
            246,
            348,
            383,
            271,
            246,
            112,
            171,
            134,
            88,
            133,
            1,
            358,
            279,
            203,
            107,
            93,
            119,
            478,
            202,
            57,
            116,
            126,
            560,
            230,
            92,
            69,
            88,
            353,
            74,
            62,
            3976,
            407,
            3104,
            473,
            237,
            495,
            299,
            487,
            1181,
            1273,
            475,
            466,
            326,
            279,
            870,
            1053,
            289,
            585,
            432,
            476,
            66,
            340,
            307,
            512,
            632,
            526,
            552,
            117,
            163,
            541,
            143,
            226,
            187,
            196,
            4096,
            161,
            186,
            341,
            205,
            182,
            435,
            535,
            493,
            382,
            248,
            408,
            156,
            171,
            345,
            148,
            451,
            274,
            222,
            142,
            144,
            377,
            215,
            211,
            224,
            207,
            805,
            568,
            142,
            208,
            3739,
            1886,
            1541,
            671,
            100,
            2063,
            645,
            230,
            533,
            465,
            961,
            374,
            1,
            1076,
            715,
            4096,
            262,
            185,
            171,
            103,
            224,
            83,
            118,
            114,
            112,
            864,
            267,
            96,
            1,
            254,
            130,
            224,
            309,
            204,
            823,
            178,
            391,
            541,
            346,
            493,
            756,
            324,
            402,
            248,
            1,
            801,
            364,
            357,
            124,
            369,
            57,
            414,
            452,
            971,
            271,
            514,
            391,
            221,
            262,
            332,
            1,
            891,
            385,
            541,
            539,
            299,
            325,
            388,
            1045,
            237,
            347,
            322,
            162,
            456,
            598,
            170,
            1,
            259,
            354,
            401,
            286,
            500,
            190,
            545,
            298,
            421,
            599,
            374,
            300,
            154,
            357,
            366,
            240,
            302,
            1077,
            179,
            572,
            538,
            580,
            1210,
            339,
            500,
            597,
            681,
            149,
            499,
            622,
            423,
            75,
            391,
            508,
            175,
            958,
            548,
            359,
            302,
            461,
            608,
            547,
            360,
            295,
            1039,
            776,
            681,
            465,
            556,
            566,
            573,
            1046,
            209,
            156,
            467,
            872,
            481,
            88,
            265,
            215,
            62,
            343,
            190,
            1,
            240,
            264,
            404,
            255,
            239,
            135,
            344,
            440,
            200,
            388,
            355,
            185,
            300,
            192,
            1194,
            1039,
            661,
            380,
            184,
            455,
            461,
            306,
            212,
            1489,
            309,
            195,
            370,
            381,
            268,
            350,
            282,
            368,
            282,
            366,
            517,
            395,
            240,
            1154,
            402,
            601,
            678,
            502,
            445,
            555,
            102,
            689,
            362,
            1,
            337,
            1472,
            526,
            573,
            461,
            226,
            362,
            419,
            239,
            178,
            1542,
            889,
            528,
            295,
            168,
            587,
            308,
            323,
            827,
            714,
            733,
            429,
            271,
            509,
            630,
            746,
            1682,
            631,
            1459,
            631,
            439,
            1,
            786,
            992,
            717,
            1665,
            225,
            308,
            281,
            503,
            541,
            515,
            346,
            157,
            597,
            143,
            339,
            1,
            944,
            709,
            293,
            368,
            516,
            447,
            802,
            443,
            674,
            360,
            1894,
            422,
            760,
            631,
            1066,
            245,
            627,
            722,
            534,
            310,
            392,
            2009,
            119,
            537,
            311,
            465,
            164,
            318,
            417,
            551,
            269,
            1,
            597,
            114,
            523,
            660,
            499,
            584,
            1685,
            362,
            234,
            528,
            249,
            900,
            2014,
            92,
            383,
            1,
            991,
            741,
            278,
            587,
            579,
            250,
            2777,
            621,
            653,
            745,
            1355,
            579,
            1459,
            730,
            671,
            523,
            1497,
            652,
            832,
            362,
            139,
            189,
            109,
            361,
            205,
            65,
            101,
            314,
            125,
            73,
            363,
            1,
            283,
            166,
            146,
            99,
            123,
            135,
            54,
            236,
            118,
            329,
            119,
            111,
            249,
            196,
            75,
            197,
            308,
            237,
            232,
            234,
            106,
            385,
            213,
            154,
            191,
            248,
            199,
            235,
            184,
            242,
            167,
            182,
            184,
            146,
            223,
            220,
            224,
            287,
            287,
            174,
            392,
            219,
            342,
            194,
            172,
            179,
            192,
            303,
            164,
            307,
            159,
            113,
            302,
            149,
            345,
            279,
            71,
            102,
            576,
            254,
            395,
            143,
            155,
            176,
            279,
            190,
            270,
            317,
            68,
            173,
            173,
            242,
            446,
            209,
            199,
            118,
            167,
            93,
            117,
            174,
            128,
            234,
            132,
        ]

        metrics = grpo_fast.calculate_utilization_metrics(
            model_dims=MODEL_DIMS["Qwen/Qwen2.5-7B"],
            prompt_lengths=prompt_lengths,
            response_lengths=response_lengths,
            total_generation_time=13.85860692244023,
            samples_per_prompt=16,
            num_engines=8,
            num_gpus_per_engine=1,
            training_time=4.0,
            num_training_gpus=16,
        )

        self.assertLessEqual(metrics["actor_mfu"], 100)
        self.assertLessEqual(metrics["actor_mbu"], 100)
        self.assertLessEqual(metrics["learner_mfu"], 100)

    def test_mbu_161_percent_reproduction(self):
        prompt_lengths = [
            139,
            83,
            409,
            247,
            132,
            271,
            347,
            305,
            139,
            127,
            75,
            358,
            284,
            245,
            284,
            389,
            117,
            233,
            186,
            179,
            244,
            318,
            295,
            630,
            296,
            206,
            146,
            138,
            167,
            415,
            157,
            120,
        ]
        response_lengths = [
            1052,
            252,
            536,
            218,
            268,
            627,
            246,
            225,
            252,
            181,
            161,
            201,
            1,
            156,
            223,
            323,
            312,
            598,
            342,
            147,
            219,
            416,
            216,
            94,
            486,
            302,
            297,
            524,
            1,
            1106,
            254,
            192,
            1352,
            528,
            658,
            679,
            475,
            737,
            273,
            356,
            105,
            845,
            810,
            913,
            1,
            667,
            1057,
            1029,
            313,
            823,
            145,
            739,
            444,
            1380,
            34,
            1423,
            284,
            319,
            202,
            222,
            1,
            349,
            302,
            453,
            1248,
            284,
            618,
            204,
            170,
            440,
            316,
            512,
            174,
            615,
            257,
            234,
            223,
            233,
            578,
            181,
            86,
            262,
            148,
            1246,
            338,
            848,
            216,
            671,
            470,
            538,
            562,
            670,
            546,
            591,
            344,
            122,
            573,
            869,
            1095,
            178,
            196,
            838,
            161,
            599,
            1018,
            1058,
            924,
            379,
            689,
            465,
            490,
            414,
            449,
            791,
            328,
            667,
            583,
            228,
            1233,
            869,
            816,
            923,
            973,
            1211,
            1,
            736,
            947,
            918,
            354,
            491,
            187,
            170,
            471,
            383,
            199,
            178,
            596,
            287,
            143,
            124,
            145,
            195,
            173,
            1360,
            215,
            199,
            166,
            260,
            335,
            236,
            207,
            116,
            108,
            346,
            1632,
            357,
            1,
            236,
            387,
            120,
            512,
            294,
            120,
            1389,
            120,
            188,
            60,
            152,
            139,
            173,
            58,
            73,
            91,
            195,
            124,
            266,
            46,
            183,
            354,
            476,
            99,
            141,
            1191,
            1698,
            576,
            677,
            1212,
            94,
            1,
            1106,
            503,
            27,
            647,
            508,
            511,
            666,
            98,
            738,
            429,
            431,
            566,
            611,
            393,
            1275,
            1,
            457,
            417,
            513,
            168,
            327,
            229,
            404,
            120,
            1643,
            1107,
            93,
            297,
            388,
            643,
            364,
            1,
            560,
            408,
            689,
            757,
            1601,
            78,
            679,
            552,
            1264,
            1109,
            454,
            849,
            836,
            1125,
            1066,
            1,
            618,
            459,
            539,
            425,
            327,
            1488,
            873,
            815,
            543,
            800,
            406,
            1962,
            464,
            1813,
            360,
            1,
            729,
            788,
            1365,
            527,
            187,
            508,
            139,
            429,
            1519,
            470,
            284,
            178,
            1235,
            360,
            200,
            1,
            179,
            224,
            250,
            602,
            555,
            1778,
            565,
            1180,
            427,
            1679,
            732,
            167,
            681,
            509,
            508,
            339,
            1326,
            718,
            775,
            281,
            1729,
            352,
            362,
            1044,
            855,
            663,
            451,
            543,
            326,
            772,
            330,
            1,
            590,
            1151,
            359,
            1884,
            571,
            452,
            574,
            450,
            220,
            210,
            226,
            1294,
            588,
            287,
            989,
            1,
            199,
            1467,
            360,
            357,
            387,
            240,
            63,
            2146,
            295,
            234,
            417,
            475,
            271,
            170,
            703,
            294,
            465,
            404,
            359,
            639,
            728,
            343,
            659,
            285,
            873,
            270,
            830,
            383,
            706,
            35,
            2391,
            386,
            599,
            711,
            594,
            715,
            541,
            435,
            771,
            602,
            2520,
            335,
            1047,
            708,
            926,
            542,
            419,
            1703,
            310,
            490,
            773,
            515,
            300,
            661,
            736,
            594,
            521,
            60,
            702,
            2636,
            629,
            24,
            492,
            1,
            429,
            429,
            487,
            188,
            520,
            690,
            931,
            2613,
            627,
            341,
            82,
            443,
            356,
            738,
            1005,
            1,
            561,
            771,
            1178,
            495,
            491,
            564,
            881,
            489,
            148,
            340,
            511,
            718,
            563,
            301,
            309,
            1207,
            386,
            3066,
            256,
            137,
            208,
            192,
            150,
            199,
            128,
            161,
            107,
            145,
            126,
            180,
            194,
            1,
            256,
            139,
            207,
            183,
            54,
            116,
            270,
            194,
            225,
            125,
            393,
            121,
            89,
            124,
            273,
            168,
            185,
            162,
            189,
            140,
            65,
            289,
            217,
            315,
            76,
            119,
            130,
            143,
            229,
            115,
            56,
            258,
            195,
            414,
            284,
            389,
            1160,
            270,
            360,
            415,
            939,
            2735,
            273,
            371,
            886,
            748,
            1912,
            508,
            198,
            323,
            796,
            221,
            134,
            359,
            158,
            185,
            253,
            328,
            516,
            337,
            106,
            249,
            414,
            1,
            386,
            334,
            564,
            276,
            47,
            148,
            131,
            175,
            177,
            441,
            474,
            109,
            101,
            24,
            240,
            1,
            542,
            583,
            595,
        ]

        metrics = grpo_fast.calculate_utilization_metrics(
            model_dims=MODEL_DIMS["Qwen/Qwen2.5-7B"],
            prompt_lengths=prompt_lengths,
            response_lengths=response_lengths,
            total_generation_time=15.400770215317607,
            samples_per_prompt=16,
            num_engines=8,
            num_gpus_per_engine=1,
            training_time=4.0,
            num_training_gpus=16,
        )

        self.assertLessEqual(metrics["actor_mfu"], 100)
        self.assertLessEqual(metrics["actor_mbu"], 100)
        self.assertLessEqual(metrics["learner_mfu"], 100)

    def test_mbu_258_percent_reproduction(self):
        prompt_lengths = [
            88,
            72,
            450,
            163,
            172,
            69,
            240,
            197,
            531,
            189,
            115,
            293,
            326,
            320,
            115,
            234,
            326,
            108,
            275,
            229,
            217,
            360,
            181,
            232,
            195,
            286,
            449,
            135,
            184,
            65,
            114,
            138,
        ]
        response_lengths = [
            567,
            609,
            229,
            839,
            86,
            138,
            107,
            180,
            143,
            187,
            180,
            125,
            1,
            203,
            108,
            218,
            100,
            134,
            59,
            144,
            211,
            101,
            184,
            228,
            189,
            146,
            328,
            87,
            1,
            873,
            283,
            345,
            261,
            606,
            730,
            237,
            781,
            76,
            238,
            527,
            474,
            501,
            584,
            291,
            480,
            507,
            497,
            722,
            857,
            399,
            246,
            352,
            469,
            777,
            333,
            354,
            572,
            592,
            287,
            236,
            1,
            214,
            683,
            493,
            100,
            236,
            180,
            138,
            403,
            67,
            193,
            237,
            190,
            871,
            127,
            64,
            166,
            211,
            124,
            123,
            654,
            126,
            97,
            53,
            897,
            91,
            81,
            395,
            524,
            108,
            399,
            55,
            1,
            390,
            296,
            120,
            136,
            253,
            109,
            540,
            371,
            985,
            354,
            348,
            171,
            502,
            197,
            222,
            1,
            545,
            402,
            353,
            408,
            181,
            206,
            230,
            186,
            272,
            195,
            147,
            231,
            753,
            436,
            186,
            241,
            225,
            3753,
            226,
            585,
            425,
            678,
            926,
            752,
            914,
            826,
            591,
            965,
            350,
            24,
            608,
            1,
            551,
            251,
            256,
            363,
            507,
            1116,
            195,
            321,
            653,
            173,
            194,
            657,
            229,
            608,
            305,
            183,
            317,
            333,
            323,
            679,
            275,
            99,
            144,
            848,
            560,
            210,
            342,
            486,
            3937,
            261,
            573,
            1,
            171,
            236,
            178,
            521,
            1224,
            57,
            596,
            291,
            584,
            471,
            1291,
            303,
            499,
            719,
            546,
            415,
            535,
            365,
            533,
            573,
            174,
            2085,
            333,
            372,
            1831,
            4096,
            377,
            627,
            1202,
            280,
            4096,
            215,
            465,
            612,
            293,
            393,
            187,
            780,
            778,
            235,
            541,
            877,
            295,
            80,
            643,
            275,
            12,
            1,
            1512,
            240,
            451,
            149,
            288,
            185,
            206,
            186,
            57,
            288,
            95,
            244,
            68,
            131,
            159,
            92,
            442,
            1408,
            465,
            275,
            1190,
            822,
            3377,
            339,
            4096,
            2546,
            1604,
            1068,
            1328,
            4096,
            633,
            1,
            260,
            4096,
            516,
            110,
            414,
            208,
            368,
            336,
            1343,
            305,
            451,
            226,
            490,
            297,
            334,
            1,
            597,
            590,
            385,
            312,
            315,
            330,
            628,
            239,
            664,
            597,
            461,
            816,
            1512,
            305,
            421,
            1,
            552,
            270,
            674,
            1461,
            108,
            960,
            171,
            212,
            734,
            561,
            555,
            382,
            917,
            473,
            273,
            1,
            525,
            583,
            614,
            379,
            505,
            753,
            1523,
            329,
            778,
            332,
            783,
            390,
            55,
            728,
            259,
            1,
            125,
            524,
            234,
            349,
            201,
            437,
            150,
            1352,
            264,
            178,
            209,
            248,
            185,
            387,
            117,
            143,
            1559,
            277,
            811,
            357,
            572,
            514,
            288,
            523,
            1897,
            425,
            467,
            195,
            1686,
            4096,
            626,
            1,
            797,
            482,
            774,
            161,
            95,
            1150,
            1575,
            291,
            1414,
            502,
            1413,
            387,
            538,
            1096,
            1072,
            1,
            431,
            628,
            658,
            169,
            617,
            697,
            276,
            917,
            316,
            610,
            423,
            1057,
            1243,
            245,
            724,
            272,
            402,
            1093,
            1778,
            1220,
            555,
            240,
            1261,
            1040,
            356,
            151,
            275,
            557,
            1540,
            293,
            1884,
            1,
            670,
            1016,
            232,
            279,
            1183,
            578,
            871,
            752,
            2367,
            585,
            315,
            802,
            326,
            548,
            1194,
            820,
            580,
            943,
            583,
            1310,
            244,
            318,
            1996,
            753,
            2520,
            25,
            1719,
            1769,
            554,
            554,
            932,
            1,
            992,
            893,
            244,
            2113,
            1348,
            327,
            785,
            2424,
            525,
            350,
            887,
            408,
            534,
            961,
            186,
            1,
            383,
            533,
            244,
            2575,
            260,
            438,
            667,
            403,
            1519,
            948,
            1511,
            480,
            627,
            307,
            443,
            1,
            195,
            645,
            120,
            151,
            293,
            282,
            223,
            154,
            126,
            139,
            146,
            410,
            130,
            429,
            72,
            292,
            209,
            240,
            204,
            288,
            368,
            145,
            680,
            545,
            372,
            234,
            360,
            143,
            419,
            340,
            160,
            271,
            556,
            260,
            350,
            455,
            122,
            146,
            123,
            178,
            260,
            169,
            95,
            200,
            268,
            773,
            297,
            1,
            126,
            149,
            160,
        ]

        metrics = grpo_fast.calculate_utilization_metrics(
            model_dims=MODEL_DIMS["Qwen/Qwen2.5-7B"],
            prompt_lengths=prompt_lengths,
            response_lengths=response_lengths,
            total_generation_time=11.019336524419487,
            samples_per_prompt=16,
            num_engines=8,
            num_gpus_per_engine=1,
            training_time=4.0,
            num_training_gpus=16,
        )

        self.assertLessEqual(metrics["actor_mfu"], 100)
        self.assertLessEqual(metrics["actor_mbu"], 100)
        self.assertLessEqual(metrics["learner_mfu"], 100)

    @parameterized.expand(
        [
            ("two_engines_four_gpus_each", "Qwen/Qwen2.5-7B", 16, 2, 256, 256, 8, 2, 4, 4, 8.0, 4.0),
            ("four_engines_two_gpus_each", "Qwen/Qwen2.5-7B", 16, 2, 256, 256, 8, 4, 2, 4, 8.0, 4.0),
            ("single_engine_eight_gpus", "Qwen/Qwen2.5-7B", 16, 2, 256, 256, 8, 1, 8, 4, 8.0, 4.0),
        ]
    )
    def test_multi_engine_utilization(
        self,
        name,
        model_name,
        num_prompts,
        samples_per_prompt,
        prompt_len,
        response_len,
        num_inference_gpus,
        num_engines,
        num_gpus_per_engine,
        num_training_gpus,
        total_generation_time,
        training_time,
    ):
        prompt_lengths = [prompt_len] * num_prompts
        response_lengths = [int(response_len)] * (num_prompts * samples_per_prompt)

        metrics = grpo_fast.calculate_utilization_metrics(
            model_dims=MODEL_DIMS[model_name],
            prompt_lengths=prompt_lengths,
            response_lengths=response_lengths,
            total_generation_time=total_generation_time,
            samples_per_prompt=samples_per_prompt,
            num_engines=num_engines,
            num_gpus_per_engine=num_gpus_per_engine,
            training_time=training_time,
            num_training_gpus=num_training_gpus,
        )

        self.assertLessEqual(
            metrics["actor_mfu"],
            100,
            f"{name}: Actor MFU {metrics['actor_mfu']:.2f}% exceeded 100% "
            f"(num_engines={num_engines}, num_gpus_per_engine={num_gpus_per_engine})",
        )
        self.assertLessEqual(
            metrics["actor_mbu"],
            100,
            f"{name}: Actor MBU {metrics['actor_mbu']:.2f}% exceeded 100% "
            f"(num_engines={num_engines}, num_gpus_per_engine={num_gpus_per_engine})",
        )
        self.assertLessEqual(metrics["learner_mfu"], 100)

    def test_model_dims_match_vllm_config(self):
        model_name = "Qwen/Qwen2.5-7B"
        expected_dims = MODEL_DIMS[model_name]

        engine_args = vllm.EngineArgs(model=model_name, load_format="dummy", max_model_len=512)
        vllm_config = engine_args.create_engine_config()

        with mock.patch("torch.cuda.get_device_name", return_value="NVIDIA H100 80GB HBM3"):
            vllm_dims = utils.ModelDims.from_vllm_config(vllm_config)
        vllm_dims.device_name = "h100"

        self.assertEqual(vllm_dims, expected_dims)


# useful for checking if public datasets are still available
# class CheckTuluDatasetsTest(unittest.TestCase):
#     """
#     Try to rebuild Tulu from public sources
#     """

#     def test_loading_tulu(self):
#         dataset_mixer = {
#             "natolambert/tulu-v2-sft-mixture-flan": 50000,
#             "natolambert/tulu-v2-sft-mixture-cot": 49747,
#             "allenai/openassistant-guanaco-reformatted": 7708,  # not exact subset
#             "Vtuber-plan/sharegpt-cleaned": 114046,
#             # original https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered
#             "vicgalle/alpaca-gpt4": 20000,
#             "HuggingFaceH4/CodeAlpaca_20K": 18000,  # original uses https://github.com/sahil280114/codealpaca
#             "natolambert/tulu-v2-sft-mixture-lima": 1018,  # original has 1030
#             "WizardLMTeam/WizardLM_evol_instruct_V2_196k": 30000,
#             "Open-Orca/OpenOrca": 30000,
#             "natolambert/tulu-v2-sft-mixture-science": 7468,  # original data slightly different
#         }
#         _ = get_datasets(dataset_mixer, splits=["train"], columns_to_keep=["messages"])
