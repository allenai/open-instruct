version: v2
description: Beaker-Mason job.
tasks:
  - name: beaker_mason__0
    replicas: 2
    leaderSelection: true
    image:
      beaker: hamishivi/open_instruct_rl_rag_testing21
    command: [/bin/bash, -c]
    arguments: ['source configs/beaker_configs/ray_node_setup.sh && python open_instruct/grpo_fast.py --exp_name 1412_rl_rag_open_judge_citation_1237 --wandb_project_name rl-rag --beta 0.001 --num_samples_per_prompt_rollout 8 --num_unique_prompts_rollout 32 --num_mini_batches 1 --num_epochs 1 --learning_rate 5e-7 --per_device_train_batch_size 1 --output_dir /output --kl_estimator kl3 --dataset_mixer_list rl-rag/rl_rag_train_sqa_1k_clean_search_rubric_longform_rubrics_adaptive_rubric 1.0 rl-rag/rl_rag_train_os_0915_2k_search_rubric_longform_rubrics_adaptive_rubric 1.0 rl-rag/rl_rag_train_sa_3k_longform_rubrics_adaptive_rubric 1.0 rl-rag/RaR-Medicine-20k-o3-mini-converted 3000 rl-rag/RaR-Science-20k-o3-mini-converted 1000 --dataset_mixer_list_splits train --dataset_mixer_eval_list rl-rag/healthbench_all_adaptive_rubric 16 --dataset_mixer_eval_list_splits test --apply_adaptive_rubric_reward true --normalize_rubric_scores false --use_rubric_buffer true --use_static_rubrics_as_persistent_rubrics true --max_active_rubrics 5 --max_token_length 10240 --max_prompt_token_length 2048 --response_length 16384 --pack_length 18500 --model_name_or_path rl-rag/qwen3-8B-sft-mix-v20250921 --no_citation_reward false --non_stop_penalty False --non_stop_penalty_value 0.0 --temperature 1.0 --ground_truths_key ground_truth --sft_messages_key messages --total_episodes 10000000 --deepspeed_stage 3 --num_learners_per_node 8 --vllm_num_engines 8 --vllm_tensor_parallel_size 1 --lr_scheduler_type constant --apply_verifiable_reward true --seed 1 --num_evals 500 --save_freq 50 --try_launch_beaker_eval_jobs_on_weka False --gradient_checkpointing --with_tracking --max_tool_calls 10 --only_reward_good_outputs False --tools mcp --checkpoint_state_freq 50 --use_full_responses_for_adaptive_rubric False --answer_length_limit_in_words 8000 --mcp_parser_name v20250824 --system_prompt_file open_instruct/search_utils/system_prompts/unified_tool_calling_v20250907.yaml --mcp_tool_names snippet_search,google_search,browse_webpage --mcp_server_command ''python -m rl-rag-mcp.mcp_agents.mcp_backend.main --transport http --port 8000 --host 0.0.0.0 --path /mcp'' --hf_entity allenai --wandb_entity ai2-llm --checkpoint_state_dir /weka/oe-adapt-default/allennlp/deletable_checkpoint_states/hamishivi/1765674437_969826 --checkpoint_state_freq 50 --output_dir /weka/oe-adapt-default/allennlp/deletable_checkpoint/hamishivi/']
    envVars:
      - name: MCP_CACHE_DIR
        value: /weka/oe-adapt-default/hamishi/rl_rag_caching/1412_rl_rag_open_judge_citation_1237/mcp_cache
      - name: CRAWL4AI_BLOCKLIST_PATH
        value: /stage/rl-rag-mcp/utils/crawl4ai_block_list.txt
      - name: CRAWL4AI_API_URL
        value: http://kennel.csail.mit.edu:11236
      - name: CRAWL4AI_API_KEY
        value: dtt6kMlXr01HZhHi6hsfWaBl8mIp5acO2al4HAJI
      - name: MASSIVE_DS_URL
        value: http://saturn-cs-aus-232.reviz.ai2.in:44177/search
      - name: MCP_MAX_CONCURRENT_CALLS
        value: "512"
      - name: VLLM_ALLOW_LONG_MAX_MODEL_LEN
        value: "1"
      - name: CITATION_JUDGE_MODEL
        value: openai/Qwen/Qwen3-8B
      - name: RUBRIC_JUDGE_MODEL
        value: openai/Qwen/Qwen3-8B
      - name: RUBRIC_GENERATION_MODEL
        value: openai/Qwen/Qwen3-8B
      - name: OPENAI_API_BASE
        value: http://ceres-cs-aus-444.reviz.ai2.in:8003/v1
      - name: LITELLM_MAX_CONCURRENT_CALLS
        value: "32"
      - name: LITELLM_DEFAULT_TIMEOUT
        value: "600"
      - name: LITELLM_LOG
        value: DEBUG
      - name: S2_API_KEY
        secret: hamishivi_S2_API_KEY
      - name: SERPER_API_KEY
        secret: hamishivi_SERPER_API_KEY
      - name: OPENAI_API_KEY
        secret: empty_openai_api_key
      - name: HF_TOKEN
        secret: hamishivi_HF_TOKEN
      - name: WANDB_API_KEY
        secret: hamishivi_WANDB_API_KEY
      - name: BEAKER_TOKEN
        secret: hamishivi_BEAKER_TOKEN
      - name: OPENAI_API_KEY
        secret: hamishivi_OPENAI_API_KEY
      - name: HF_HOME
        value: /weka/oe-adapt-default/allennlp/.cache/huggingface
      - name: HF_DATASETS_CACHE
        value: /weka/oe-adapt-default/allennlp/.cache/huggingface
      - name: HF_HUB_CACHE
        value: /weka/oe-adapt-default/allennlp/.cache/hub
      - name: CHECKPOINT_OUTPUT_DIR
        value: /weka/oe-adapt-default/allennlp/deletable_checkpoint_states/c73q5cve
      - name: NCCL_SOCKET_IFNAME
        value: ib
      - name: NCCL_IB_HCA
        value: ^=mlx5_bond_0
      - name: NCCL_DEBUG
        value: INFO
    datasets:
      - mountPath: /weka/oe-adapt-default
        source:
          weka: oe-adapt-default
      - mountPath: /weka/oe-training-default
        source:
          weka: oe-training-default
    result:
      path: /output
    resources:
      gpuCount: 8
    context:
      priority: high
      preemptible: true
    constraints:
      cluster:
        - ai2/jupiter
    hostNetworking: true
    propagateFailure: true
    propagatePreemption: true
