{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e49d55",
   "metadata": {},
   "source": [
    "# Test MCP Launching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19323d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-10 20:05:41,769] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n",
      "[2025-09-10 20:05:41,774] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rulin/miniconda3/envs/open-instruct/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-09-10 20:05:46,290\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-10 20:05:51 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 09-10 20:05:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform\n",
      "WARNING 09-10 20:05:51 [_custom_ops.py:21] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')\n",
      "üöÄ Launching MCP server subprocess: cd ../rl-rag-mcp && python -m mcp_agents.mcp_backend.main --transport http --port 8000 --path /mcp\n",
      "‚úÖ Found fastmcp at: /home/rulin/miniconda3/envs/open-instruct/bin/fastmcp\n",
      "üìÅ Current working directory: /checkpoint/comem/rulin/open-instruct\n",
      "‚úÖ MCP server started successfully (PID: 228837)\n",
      "üìã MCP server logs: output/mcp_logs/mcp_server_stdout.log, output/mcp_logs/mcp_server_stderr.log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['cd ../rl-rag-mcp && python -m mcp_agents.mc...>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from open_instruct.grpo_fast import launch_mcp_subprocess\n",
    "run_mcp_command=\"cd ../rl-rag-mcp && python -m mcp_agents.mcp_backend.main --transport http --port 8000 --path /mcp\"\n",
    "launch_mcp_subprocess(run_mcp_command, \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc6fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ecc5e54",
   "metadata": {},
   "source": [
    "# Debug FGRPO Toy Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5754f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "rl_log_file = \"/checkpoint/comem/rulin/open-instruct/output/debug_rl_rag_fgrpo_toy_2wiki_5q_same_group_massive_serve__1__1757530995/traces_debug_rl_rag_fgrpo_toy_2wiki_5q_same_group_massive_serve__1__1757530995.jsonl\"\n",
    "data = [json.loads(line) for line in open(rl_log_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bff23fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['advantages', 'finish_reasons', 'responses', 'queries', 'ground_truths', 'datasets', 'training_step', 'objective/reward_log_values/question_0_accuracy', 'objective/reward_log_values/question_1_accuracy', 'objective/reward_log_values/question_2_accuracy', 'objective/reward_log_values/question_3_accuracy', 'objective/reward_log_values/question_4_accuracy', 'objective/reward_log_values/num_questions', 'objective/reward_log_values/averaged_accuracy', 'objective/reward_log_values/num_valid_spans'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48faf435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses: 128\n",
      "Example ground truth: ['no; Brooklyn; no; no; no']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of responses:\", len(data[0][\"responses\"]))\n",
    "print(\"Example ground truth:\", data[0][\"ground_truths\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ca8ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rulin/miniconda3/envs/open-instruct/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Decode the response and query\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai2-adapt-dev/tulu_3_long_finetune_qwen_7b_reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b108d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, query = data[0][\"responses\"][0], data[0][\"queries\"][0]\n",
    "response = tokenizer.decode(res, skip_special_tokens=True)\n",
    "question = tokenizer.decode(query, skip_special_tokens=True)\n",
    "ground_truth = json.dumps(data[0][\"ground_truths\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a182fb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"no; Brooklyn; no; no; no\"]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "667f541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def extract_ground_truth_per_question(ground_truth: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract ground truth answers for each individual question.\n",
    "    Expects ground truth in format: JSON arrays separated by semicolons\n",
    "    e.g., '[\"ans1\", \"ans2\"]; [\"ans3\", \"ans4\"]; [\"ans5\"]'\n",
    "    Returns: List of JSON strings, one per question\n",
    "    \"\"\"\n",
    "    ground_truth = json.loads(ground_truth)\n",
    "    if len(ground_truth) != 1:\n",
    "        return [json.dumps(item) if isinstance(item, list) else str(item) for item in ground_truth]\n",
    "    else:\n",
    "        ground_truth = ground_truth[0]\n",
    "        return ground_truth.split(\";\")  # TODO: the use of this is terrible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04756bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "import re\n",
    "def split_response_and_get_spans(response: str, num_questions: int) -> Tuple[List[str], List[List[Tuple[int, int]]]]:\n",
    "    \"\"\"\n",
    "    Split a multi-question response into individual question responses and get their spans.\n",
    "    Splits by </answer{i}> tags where i is the question number (1-indexed).\n",
    "    \n",
    "    Args:\n",
    "        response: The full response containing multiple answers\n",
    "        num_questions: Number of questions expected\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (sub_responses, spans) where:\n",
    "        - sub_responses: List of response text for each question\n",
    "        - spans: List of span tuples [(start_char, end_char)] for each question\n",
    "    \"\"\"\n",
    "    if num_questions <= 1:\n",
    "        return [response], [[(0, len(response))]], 1\n",
    "    \n",
    "    sub_responses = []\n",
    "    spans = []\n",
    "    num_valid_spans = 0\n",
    "    \n",
    "    # Find split points using </answer{i}> tags\n",
    "    start_char = 0\n",
    "    for i in range(1, num_questions + 1):\n",
    "        end_tag = f\"</answer{i}>\"\n",
    "        match = re.search(re.escape(end_tag), response[start_char:])\n",
    "        if match:\n",
    "            end_char = start_char + match.end()\n",
    "            sub_responses.append(response[start_char:end_char])\n",
    "            spans.append([(start_char, end_char)])\n",
    "            num_valid_spans += 1\n",
    "            start_char = end_char\n",
    "        elif i == num_questions:\n",
    "            sub_responses.append(response[start_char:])\n",
    "            spans.append([(start_char, len(response))])\n",
    "            break\n",
    "        else:\n",
    "            # # Otherwise, return invalid spans that will trigger the fallback mechanism to use the entire response\n",
    "            # sub_responses.append(response)\n",
    "            # spans.append([(-1, -1)])\n",
    "            # Or, penalize the entire response and return empty sub_response\n",
    "            sub_responses.append(\"\")\n",
    "            spans.append([(-1, -1)])\n",
    "        \n",
    "    return sub_responses, spans, num_valid_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bf93fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_per_question = extract_ground_truth_per_question(ground_truth)\n",
    "num_questions = len(ground_truth_per_question)\n",
    "sub_responses, spans, num_valid_spans = split_response_and_get_spans(response, num_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64a94000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_valid_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "747c5191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<answer1>\\boxed{No}</answer1>\n",
      "[(0, 29)]\n",
      "====================================================================================================\n",
      "\n",
      "<search>Do Sucker Punch (2011 film) and Plaga Zombie share the same director nationality?</search>\n",
      "<snippets id=4fbd077c>\n",
      "Plaga Zombie (film series) studio based in New Bedford, Massachusetts, the company is best known for its award-winning 2007 horror film \"The Terror Factor\". Writer-director Garry Mederios discovered the Plaga Zombie series after watching the Fangoria Film DVD. Mederios enjoyed the series so much that he contacted the filmmakers via e-mail and became friends. He jokingly suggested making an American-based Plaga Zombie film during one of their exchanges but FARSA Productions was very receptive to the idea and plans were eventually made to produce a feature-length film. Set in the same universe as the original trilogy, Plaga Zombie: American Invasion is to feature three\n",
      "\n",
      "Nathan Schiff The poetic, whirling, free style of its imagery is remarkably close in spirit to James Joyce\". Schiff later returned to filmmaking with the horror short \"Abracadaver!\" (2008), made for British producer David McGillivray. Promoted as \"a gruesome tale of magic and mutilation,\" the film was part of McGillivray's \"Worst Fears\" series. \"Long Island Cannibal Massacre\" and \"Weasels Rip My Flesh\" were selections of Cinefamily's 2008 Homemade Horror festival, and Schiff was flown to the West Coast as an invited guest of the Cinefamily film study group. The features were shown under the umbrella title \"The Super-8 Gorenography of Nathan Schiff!\"\n",
      "\n",
      "Plaga Zombie (film series) Raimi's Evil Dead II. The filmmakers themselves are admitted fans of these films but claim never to have seen George Romero's Night of the Living Dead series. Peter Dendle, a Penn State Mont Alto film scholar, has said that the films are more akin to Japanese-style horror with \"the deliberate piling up of non-sequiters and flaunting of narrative expectations\". Plaga Zombie (film series) Plaga Zombie is an Argentine comedy horror film series created by Pablo Par√©s, Berta Mu√±iz, and Hern√°n S√°ez. The films follow three misfit heroes who uncover an alien-government conspiracy after a zombie outbreak occurs in their hometown.\n",
      "</snippets> \n",
      "Hanjin Colombia warned that the group will not allow its cargo vessels, which entered eight months ago, ... ... ... Plaga Zombie: American Invasion is not finished yet!\n",
      "\n",
      "Plaga Zombi (Gorri√≥n Pierce) was also made by Daniel Estep at New Bedford, ORDER Back to Plaga Zombi Meltingmilk Films Henri: 'Wanted' (2012 - 44mins). Henri's film 'Wanted' tells the story of a couple who are high school students.\n",
      "\n",
      "<answer2>\\boxed{Palermo, Sicily}</answer2>\n",
      "[(29, 2602)]\n",
      "====================================================================================================\n",
      "\n",
      "<search>Where was the director of Steel (1979 Film) born?</search>\n",
      "<snippets id=e2290384>\n",
      "Don Levy position at the Carpenter Center for the Visual Arts at Harvard University, where he stayed for two years. He then moved to Los Angeles to work at the California Institute of the Arts, where he taught and conducted research in film, video and multimedia until his death in 1987 by committing suicide. Don Levy Don Levy (1932 ‚Äì January 1987) was an artist and filmmaker. Levy was born in Bathurst, New South Wales, Australia. After studying theoretical chemistry at the University of Sydney, he was awarded a Research Scholarship to the University of Cambridge. There he obtained a PhD in\n",
      "\n",
      "Roger Sherman (filmmaker) in 1969. He attended Union College (1969-1971), majoring in political science and experimental education, played freshman soccer, and spent a semester in Bogot√°, Colombia where he studied Spanish. He left Union and went to Denmark for his junior year abroad at The University of Copenhagen, Denmark. He studied architecture and history that fall and moved to , where he worked that winter at a hotel at the base of La Daille lift and a restaurant on top of the mountain. After returning from his year abroad, he attended Hampshire College, in Amherst, Massachusetts, where he graduated in 1975 with a\n",
      "\n",
      "James Goldstone the Vermont Arts Council which named its award for new talent the James Goldstone Award. Goldstone was the son of Hollywood agent and early television producer, Jules Goldstone. James Goldstone James Goldstone (born June 8, 1931 in Los Angeles, California; died November 5, 1999 in Shaftsbury, Vermont) was an American film and television director whose career spanned over thirty years. Goldstone was noted for the momentum and \"fifteen-minute cliffhangers\" that he brought to TV pilots such as \"\" (\"Where No Man Has Gone Before\", 1966), \"Ironside\", and \"\". His later career helped pioneer the concept of \"thirty-second attention span\" pacing\n",
      "</snippets> \n",
      "\n",
      "Robert E. Goldstone by opening him to film criticism.\n",
      "\n",
      "Sam Davis (actor) embellished this philosophy in his opening narrative to an Arcana Publishing interview\" Once, an actor forced into a Hollywood life, I fully surrender any knowledge of this man. But, he always knew that his parents must be proud. My father was born in Palermo, Sicily and my mother was born in New York City's Lower East Side. My father lived there until he left for America with his family. My father, a street-rat who gambled with them, was beaten as a child. He used to tell me about like a boy with candy felons. My mother was a stray adult heir of a grandmother with only one arm, and a grandmother with only one arm for the self-defense industry's sake. My mother, pruned I'm a wine-field wrestling\n",
      "\n",
      "<answer3>\\boxed{No}</answer3>\n",
      "[(2602, 5401)]\n",
      "====================================================================================================\n",
      "\n",
      "[(-1, -1)]\n",
      "====================================================================================================\n",
      "\n",
      "<search>Did Uwe Bollm and Shibusawa Eiichi share the same nationality?</search>\n",
      "<snippets id=4a1199ae>\n",
      "Shigeo Kishibe hichiriki), the n≈çkan, nagauta, itchu-b≈´shi, and the Chinese guqin. Shigeo Kishibe Kishibe was born in Tokyo in the district of Kanda-Jinb≈çch≈ç, to Fukuo Kishibe, an educator and children‚Äôs writer. He was first exposed to music through music in his father‚Äôs stories, and made his first record and stage appearance at age 9 (by East Asian age reckoning) and first appeared on the radio at age 14. As a teenager, he became fascinated by Asian history. At this time he also met the eminent scholar of Japanese and Asian music Hisao Tanabe. In April 1933, he enrolled at the Tokyo Imperial\n",
      "\n",
      "Japanese people were forced to repatriate to Hokkaid≈ç by the Soviet Union as a part of Japanese people. On the other hand, many Sakhalin Koreans who had held Japanese citizenship until the end of the war were left stateless by the Soviet occupation. Article 10 of the Constitution of Japan defines the term \"Japanese\" based upon Japanese nationality. The concept of \"ethnic groups\" in Japanese census statistics differs from the concept applied in many other countries. For example, the United Kingdom Census queries the respondent's \"ethnic or racial background\", regardless of nationality. The Japanese Statistics Bureau, however, asks only about nationality in\n",
      "\n",
      "Wolfgang Michel-Zaitsu Gakkai). Wolfgang Michel-Zaitsu Wolfgang Michel/Michel-Zaitsu (born 1946 in Frankfurt am Main, Germany) is a professor emeritus of Kyushu University in Fukuoka (Japan). He is a specialist in medicine and allied sciences in the history of East-West cultural exchange. In 1984 he was granted tenure as the first foreigner in a Japanese national university. By combining Japanese and Western manuscript sources, Michel shed new light on Western medicine and allied sciences in early modern Japan and the interdependence of Western studies on Eastern medicine and Japanese studies on Western medicine. His research clarified the mechanism of early medical interactions between Japan\n",
      "</snippets>\n",
      "[(5401, 7484)]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for sub_response, span in zip(sub_responses, spans):\n",
    "    print(sub_response)\n",
    "    print(span)\n",
    "    print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddd7815e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7484"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e37f4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from open_instruct.search_rewards.toy_case_multi_dataset_reward import normalize_answer, extract_boxed_answer_from_response\n",
    "def verify_one_question(response: str, target: str, use_exact_match: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Verify a single question response against ground truth.\n",
    "    \n",
    "    Args:\n",
    "        response: The response text for one question\n",
    "        ground_truth: Ground truth data for this question\n",
    "        use_exact_match: If True, use exact match; if False, use contains match\n",
    "        \n",
    "    Returns:\n",
    "        Score between 0.0 and 1.0\n",
    "    \"\"\"\n",
    "    if not response or not target:\n",
    "        return 0.0\n",
    "    \n",
    "    # check if the response is a list of answers\n",
    "    parsed_labels: Union[List, str]\n",
    "    try:\n",
    "        parsed = json.loads(target)\n",
    "        parsed_labels = parsed if isinstance(parsed, list) else [parsed]\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        # Fallback: treat label as raw string or list-of-strings\n",
    "        if isinstance(target, list):\n",
    "            parsed_labels = target\n",
    "        else:\n",
    "            parsed_labels = [str(target).strip()]\n",
    "    \n",
    "    for label in parsed_labels:\n",
    "        # Normalize both strings for comparison\n",
    "        response_normalized = normalize_answer(extract_boxed_answer_from_response(response.strip()))\n",
    "        target_normalized = normalize_answer(str(label).strip())\n",
    "        print(\"extracted answer:\", response_normalized)\n",
    "        print(\"ground truth:\", target_normalized)\n",
    "        \n",
    "        if use_exact_match:\n",
    "            # Exact match after normalization\n",
    "            if response_normalized == target_normalized:\n",
    "                return 1.0\n",
    "        else:\n",
    "            # Contains match - check if ground truth is contained in response\n",
    "            if target_normalized.lower() in response_normalized.lower():\n",
    "                return 1.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2dc09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Optional\n",
    "from open_instruct.search_rewards.toy_case_multi_dataset_reward import FinegrainedScore\n",
    "\n",
    "def compute_multi_question_reward(\n",
    "    response: str, \n",
    "    ground_truth: str, \n",
    "    query: Optional[str] = None,\n",
    "    use_exact_match: bool = False,\n",
    "    reward_type: str = \"finegrained\",\n",
    "    ) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compute finegrained multi-question reward with simple verifiable scoring and spans.\n",
    "    \n",
    "    Args:\n",
    "        response: The full response containing multiple answers\n",
    "        ground_truth: Dictionary containing ground truth data\n",
    "        use_exact_match: If True, use exact match; if False, use contains match\n",
    "        \n",
    "    Returns:\n",
    "        Dict with:\n",
    "            - finegrained_scores: List of (score, (start_char, end_char), reward_group_id, response_idx) tuples\n",
    "            - log_values: Dict of metrics for logging\n",
    "    \"\"\"\n",
    "    # Get verifiable reward scores for each question\n",
    "    ground_truth_per_question = extract_ground_truth_per_question(ground_truth)\n",
    "    print(f\"üéÄ ground_truth_per_question: {ground_truth_per_question}\")\n",
    "    num_questions = len(ground_truth_per_question)\n",
    "    \n",
    "    # Split the response into individual question components for span generation\n",
    "    sub_responses, spans, num_valid_spans = split_response_and_get_spans(response, num_questions)\n",
    "    \n",
    "    # Compute finegrained scores for each question\n",
    "    finegrained_scores = []\n",
    "    for i, (sub_response, gt, span) in enumerate(zip(sub_responses, ground_truth_per_question, spans)):\n",
    "        sub_score = verify_one_question(sub_response, gt, use_exact_match)\n",
    "\n",
    "        group_id = 0  # rulin: assume the same group for all questions\n",
    "        finegrained_scores.append(\n",
    "            FinegrainedScore(\n",
    "                score=sub_score,\n",
    "                effective_spans=span,\n",
    "                reward_group_id=group_id,  \n",
    "                reward_group_name=f\"question_{group_id}\",\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    averaged_score = sum(item.score for item in finegrained_scores) / len(finegrained_scores)\n",
    "    \n",
    "    # Create log values for tracking\n",
    "    log_values = {\n",
    "        **{f\"question_{i}_accuracy\": item.score for i, item in enumerate(finegrained_scores)},\n",
    "        \"num_questions\": num_questions,\n",
    "        \"averaged_accuracy\": averaged_score,\n",
    "        \"num_valid_spans\": num_valid_spans,\n",
    "    }\n",
    "    \n",
    "    if reward_type == \"finegrained\":\n",
    "        print(f\"üéÄ finegrained_scores: {log_values}\")\n",
    "        return {\n",
    "            \"finegrained_scores\": finegrained_scores,\n",
    "            \"log_values\": log_values,\n",
    "        }\n",
    "    elif reward_type == \"averaged\":\n",
    "        print(f\"üéÄ averaged_score: {averaged_score}\")\n",
    "        return {\n",
    "            \"score\": averaged_score,\n",
    "            \"log_values\": log_values,\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid reward type: {reward_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a5987c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÄ ground_truth_per_question: ['no', ' Brooklyn', ' no', ' no', ' no']\n",
      "extracted answer: no\n",
      "ground truth: no\n",
      "extracted answer: palermo sicily\n",
      "ground truth: brooklyn\n",
      "extracted answer: no\n",
      "ground truth: no\n",
      "extracted answer: \n",
      "ground truth: no\n",
      "üéÄ finegrained_scores: {'question_0_accuracy': 1.0, 'question_1_accuracy': 0.0, 'question_2_accuracy': 1.0, 'question_3_accuracy': 0.0, 'question_4_accuracy': 0.0, 'num_questions': 5, 'averaged_accuracy': 0.4, 'num_valid_spans': 3}\n"
     ]
    }
   ],
   "source": [
    "reward_per_question = compute_multi_question_reward(\n",
    "    response,\n",
    "    ground_truth,\n",
    "    query,\n",
    "    use_exact_match=False,\n",
    "    reward_type=\"finegrained\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d609c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantage = data[0][\"advantages\"][0]\n",
    "len(advantage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7143b48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc0f5d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_instruct.search_rewards.utils.span_convertion import (\n",
    "    message_span_aware_tokenization,\n",
    "    convert_string_spans_to_token_spans\n",
    ")\n",
    "import logging\n",
    "\n",
    "\n",
    "def convert_string_span_to_token_span(effective_spans, decoded_resp, token_resp, tokenizer):\n",
    "    \"\"\"\n",
    "    Convert character spans to token spans and create a mask for training.\n",
    "    Uses the span conversion logic from open_instruct/search_rewards/span_convertion.py\n",
    "    \n",
    "    Args:\n",
    "        effective_spans: List of tuples (start_char, end_char) in decoded response\n",
    "        decoded_resp: Decoded string response\n",
    "        token_resp: Tokenized response (list of token IDs)\n",
    "        tokenizer: Tokenizer used to decode the responses\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (mask, span_mapping_stats) where:\n",
    "        - mask: List of integers where 1 means the token should be trained on, 0 means masked\n",
    "        - span_mapping_stats: Dict with mapping quality statistics\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # Initialize statistics tracking\n",
    "    span_stats = {\n",
    "        \"total_spans\": len(effective_spans) if effective_spans else 0,\n",
    "        \"valid_start_mappings\": 0,\n",
    "        \"valid_end_mappings\": 0,\n",
    "        \"fallback_start_mappings\": 0,\n",
    "        \"fallback_end_mappings\": 0,\n",
    "    }\n",
    "    \n",
    "    if not effective_spans or len(token_resp) == 0:\n",
    "        # If no effective spans or no tokens, mask everything except last EOS\n",
    "        mask = [0] * len(token_resp)\n",
    "        if len(token_resp) > 0 and token_resp[-1] == tokenizer.eos_token_id:\n",
    "            mask[-1] = 1\n",
    "        return mask, span_stats\n",
    "    \n",
    "    # Use the span conversion utilities directly without creating dummy messages\n",
    "    # We'll tokenize the decoded response directly and get offset mappings\n",
    "    tokenized_resp = tokenizer(\n",
    "        decoded_resp,\n",
    "        return_tensors=\"pt\",\n",
    "        return_offsets_mapping=True,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    \n",
    "    # Check for empty tokenization\n",
    "    if len(tokenized_resp[\"input_ids\"][0]) == 0:\n",
    "        logger.warning(f\"Empty tokenization for decoded_resp: '{decoded_resp[:100]}...'\")\n",
    "        # Return all-masked except EOS\n",
    "        mask = [0] * len(token_resp)\n",
    "        if len(token_resp) > 0 and token_resp[-1] == tokenizer.eos_token_id:\n",
    "            mask[-1] = 1\n",
    "        return mask, span_stats\n",
    "    \n",
    "    # Create a simple tokenized_input structure that the conversion function expects\n",
    "    tokenized_input = {\n",
    "        \"offset_mapping\": tokenized_resp[\"offset_mapping\"][0],  # Remove batch dimension\n",
    "        \"message_token_spans\": {0: [0, len(tokenized_resp[\"input_ids\"][0])]},  # Single message spanning all tokens\n",
    "    }\n",
    "    \n",
    "    # Convert string spans to token spans\n",
    "    token_spans = convert_string_spans_to_token_spans(\n",
    "        tokenized_input,\n",
    "        effective_spans,\n",
    "        target_message_span_index=0\n",
    "    )\n",
    "    \n",
    "    # Initialize mask - everything masked by default\n",
    "    mask = [0] * len(token_resp)\n",
    "    \n",
    "    # Update statistics and create mask\n",
    "    for span_idx, (token_start, token_end) in enumerate(token_spans):\n",
    "        if token_start is not None and token_end is not None:\n",
    "            span_stats[\"valid_start_mappings\"] += 1\n",
    "            span_stats[\"valid_end_mappings\"] += 1\n",
    "            \n",
    "            # Clamp to valid token range for our response\n",
    "            token_start = max(0, min(token_start, len(token_resp)))\n",
    "            token_end = max(token_start, min(token_end, len(token_resp)))\n",
    "            \n",
    "            # Unmask tokens in this span\n",
    "            for token_idx in range(token_start, token_end):\n",
    "                if token_idx < len(mask):\n",
    "                    mask[token_idx] = 1\n",
    "        else:\n",
    "            span_stats[\"fallback_start_mappings\"] += 1\n",
    "            span_stats[\"fallback_end_mappings\"] += 1\n",
    "            logger.warning(f\"Span {span_idx} could not be converted to token span. No reward will be applied.\")\n",
    "    \n",
    "    # Always keep the last EOS token unmasked if it exists\n",
    "    if len(token_resp) > 0 and token_resp[-1] == tokenizer.eos_token_id:\n",
    "        mask[-1] = 1\n",
    "    \n",
    "    return mask, span_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b79587a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.9276126027107239, 0.0, -0.2757767140865326, -1.0780363082885742}\n",
      "[[(0, 29)], [(29, 2602)], [(2602, 5401)], [(-1, -1)], [(5401, 7484)]]\n",
      "****************************************************************************************************\n",
      "[(0, 29)]\n",
      "1742\n",
      "1742\n",
      "{'total_spans': 1, 'valid_start_mappings': 1, 'valid_end_mappings': 1, 'fallback_start_mappings': 0, 'fallback_end_mappings': 0}\n",
      "<answer1>\\boxed{No}</answer1>\n",
      "<search>Do Sucker Punch (2011 film) and Plaga Zombie share the same director nationality?</search>\n",
      "<snippets id=4fbd077c>\n",
      "Plaga Zombie (film series) studio based in New Bedford, Massachusetts, the company is best known for its award-winning 2007 horror film \"The Terror Factor\". Writer-director Garry Mederios discovered the Plaga Zombie series after watching the Fangoria Film DVD. Mederios enjoyed the series so much that he contacted the filmmakers via e-mail and became friends. He jokingly suggested making an American-based Plaga Zombie film during one of their exchanges but FARSA Productions was very receptive to the idea and plans were eventually made to produce a feature-length film. Set in the same universe as the original trilogy, Plaga Zombie: American Invasion is to feature three\n",
      "\n",
      "Nathan Schiff The poetic, whirling, free style of its imagery is remarkably close in spirit to James Joyce\". Schiff later returned to filmmaking with the horror short \"Abracadaver!\" (2008), made for British producer David McGillivray. Promoted as \"a gruesome tale of magic and mutilation,\" the film was part of McGillivray's \"Worst Fears\" series. \"Long Island Cannibal Massacre\" and \"Weasels Rip My Flesh\" were selections of Cinefamily's 2008 Homemade Horror festival, and Schiff was flown to the West Coast as an invited guest of the Cinefamily film study group. The features were shown under the umbrella title \"The Super-8 Gorenography of Nathan Schiff!\"\n",
      "\n",
      "Plaga Zombie (film series) Raimi's Evil Dead II. The filmmakers themselves are admitted fans of these films but claim never to have seen George Romero's Night of the Living Dead series. Peter Dendle, a Penn State Mont Alto film scholar, has said that the films are more akin to Japanese-style horror with \"the deliberate piling up of non-sequiters and flaunting of narrative expectations\". Plaga Zombie (film series) Plaga Zombie is an Argentine comedy horror film series created by Pablo Par√©s, Berta Mu√±iz, and Hern√°n S√°ez. The films follow three misfit heroes who uncover an alien-government conspiracy after a zombie outbreak occurs in their hometown.\n",
      "</snippets> \n",
      "Hanjin Colombia warned that the group will not allow its cargo vessels, which entered eight months ago, ... ... ... Plaga Zombie: American Invasion is not finished yet!\n",
      "\n",
      "Plaga Zombi (Gorri√≥n Pierce) was also made by Daniel Estep at New Bedford, ORDER Back to Plaga Zombi Meltingmilk Films Henri: 'Wanted' (2012 - 44mins). Henri's film 'Wanted' tells the story of a couple who are high school students.\n",
      "\n",
      "<answer2>\\boxed{Palermo, Sicily}</answer2>\n",
      "<search>Where was the director of Steel (1979 Film) born?</search>\n",
      "<snippets id=e2290384>\n",
      "Don Levy position at the Carpenter Center for the Visual Arts at Harvard University, where he stayed for two years. He then moved to Los Angeles to work at the California Institute of the Arts, where he taught and conducted research in film, video and multimedia until his death in 1987 by committing suicide. Don Levy Don Levy (1932 ‚Äì January 1987) was an artist and filmmaker. Levy was born in Bathurst, New South Wales, Australia. After studying theoretical chemistry at the University of Sydney, he was awarded a Research Scholarship to the University of Cambridge. There he obtained a PhD in\n",
      "\n",
      "Roger Sherman (filmmaker) in 1969. He attended Union College (1969-1971), majoring in political science and experimental education, played freshman soccer, and spent a semester in Bogot√°, Colombia where he studied Spanish. He left Union and went to Denmark for his junior year abroad at The University of Copenhagen, Denmark. He studied architecture and history that fall and moved to , where he worked that winter at a hotel at the base of La Daille lift and a restaurant on top of the mountain. After returning from his year abroad, he attended Hampshire College, in Amherst, Massachusetts, where he graduated in 1975 with a\n",
      "\n",
      "James Goldstone the Vermont Arts Council which named its award for new talent the James Goldstone Award. Goldstone was the son of Hollywood agent and early television producer, Jules Goldstone. James Goldstone James Goldstone (born June 8, 1931 in Los Angeles, California; died November 5, 1999 in Shaftsbury, Vermont) was an American film and television director whose career spanned over thirty years. Goldstone was noted for the momentum and \"fifteen-minute cliffhangers\" that he brought to TV pilots such as \"\" (\"Where No Man Has Gone Before\", 1966), \"Ironside\", and \"\". His later career helped pioneer the concept of \"thirty-second attention span\" pacing\n",
      "</snippets> \n",
      "\n",
      "Robert E. Goldstone by opening him to film criticism.\n",
      "\n",
      "Sam Davis (actor) embellished this philosophy in his opening narrative to an Arcana Publishing interview\" Once, an actor forced into a Hollywood life, I fully surrender any knowledge of this man. But, he always knew that his parents must be proud. My father was born in Palermo, Sicily and my mother was born in New York City's Lower East Side. My father lived there until he left for America with his family. My father, a street-rat who gambled with them, was beaten as a child. He used to tell me about like a boy with candy felons. My mother was a stray adult heir of a grandmother with only one arm, and a grandmother with only one arm for the self-defense industry's sake. My mother, pruned I'm a wine-field wrestling\n",
      "\n",
      "<answer3>\\boxed{No}</answer3>\n",
      "<search>Did Uwe Bollm and Shibusawa Eiichi share the same nationality?</search>\n",
      "<snippets id=4a1199ae>\n",
      "Shigeo Kishibe hichiriki), the n≈çkan, nagauta, itchu-b≈´shi, and the Chinese guqin. Shigeo Kishibe Kishibe was born in Tokyo in the district of Kanda-Jinb≈çch≈ç, to Fukuo Kishibe, an educator and children‚Äôs writer. He was first exposed to music through music in his father‚Äôs stories, and made his first record and stage appearance at age 9 (by East Asian age reckoning) and first appeared on the radio at age 14. As a teenager, he became fascinated by Asian history. At this time he also met the eminent scholar of Japanese and Asian music Hisao Tanabe. In April 1933, he enrolled at the Tokyo Imperial\n",
      "\n",
      "Japanese people were forced to repatriate to Hokkaid≈ç by the Soviet Union as a part of Japanese people. On the other hand, many Sakhalin Koreans who had held Japanese citizenship until the end of the war were left stateless by the Soviet occupation. Article 10 of the Constitution of Japan defines the term \"Japanese\" based upon Japanese nationality. The concept of \"ethnic groups\" in Japanese census statistics differs from the concept applied in many other countries. For example, the United Kingdom Census queries the respondent's \"ethnic or racial background\", regardless of nationality. The Japanese Statistics Bureau, however, asks only about nationality in\n",
      "\n",
      "Wolfgang Michel-Zaitsu Gakkai). Wolfgang Michel-Zaitsu Wolfgang Michel/Michel-Zaitsu (born 1946 in Frankfurt am Main, Germany) is a professor emeritus of Kyushu University in Fukuoka (Japan). He is a specialist in medicine and allied sciences in the history of East-West cultural exchange. In 1984 he was granted tenure as the first foreigner in a Japanese national university. By combining Japanese and Western manuscript sources, Michel shed new light on Western medicine and allied sciences in early modern Japan and the interdependence of Western studies on Eastern medicine and Japanese studies on Western medicine. His research clarified the mechanism of early medical interactions between Japan\n",
      "</snippets>\n",
      "====================================================================================================\n",
      "[(29, 2602)]\n",
      "1742\n",
      "1742\n",
      "{'total_spans': 1, 'valid_start_mappings': 1, 'valid_end_mappings': 1, 'fallback_start_mappings': 0, 'fallback_end_mappings': 0}\n",
      "<search>Do Sucker Punch (2011 film) and Plaga Zombie share the same director nationality?</search>\n",
      "<snippets id=4fbd077c>\n",
      "Plaga Zombie (film series) studio based in New Bedford, Massachusetts, the company is best known for its award-winning 2007 horror film \"The Terror Factor\". Writer-director Garry Mederios discovered the Plaga Zombie series after watching the Fangoria Film DVD. Mederios enjoyed the series so much that he contacted the filmmakers via e-mail and became friends. He jokingly suggested making an American-based Plaga Zombie film during one of their exchanges but FARSA Productions was very receptive to the idea and plans were eventually made to produce a feature-length film. Set in the same universe as the original trilogy, Plaga Zombie: American Invasion is to feature three\n",
      "\n",
      "Nathan Schiff The poetic, whirling, free style of its imagery is remarkably close in spirit to James Joyce\". Schiff later returned to filmmaking with the horror short \"Abracadaver!\" (2008), made for British producer David McGillivray. Promoted as \"a gruesome tale of magic and mutilation,\" the film was part of McGillivray's \"Worst Fears\" series. \"Long Island Cannibal Massacre\" and \"Weasels Rip My Flesh\" were selections of Cinefamily's 2008 Homemade Horror festival, and Schiff was flown to the West Coast as an invited guest of the Cinefamily film study group. The features were shown under the umbrella title \"The Super-8 Gorenography of Nathan Schiff!\"\n",
      "\n",
      "Plaga Zombie (film series) Raimi's Evil Dead II. The filmmakers themselves are admitted fans of these films but claim never to have seen George Romero's Night of the Living Dead series. Peter Dendle, a Penn State Mont Alto film scholar, has said that the films are more akin to Japanese-style horror with \"the deliberate piling up of non-sequiters and flaunting of narrative expectations\". Plaga Zombie (film series) Plaga Zombie is an Argentine comedy horror film series created by Pablo Par√©s, Berta Mu√±iz, and Hern√°n S√°ez. The films follow three misfit heroes who uncover an alien-government conspiracy after a zombie outbreak occurs in their hometown.\n",
      "</snippets> \n",
      "Hanjin Colombia warned that the group will not allow its cargo vessels, which entered eight months ago, ... ... ... Plaga Zombie: American Invasion is not finished yet!\n",
      "\n",
      "Plaga Zombi (Gorri√≥n Pierce) was also made by Daniel Estep at New Bedford, ORDER Back to Plaga Zombi Meltingmilk Films Henri: 'Wanted' (2012 - 44mins). Henri's film 'Wanted' tells the story of a couple who are high school students.\n",
      "\n",
      "<answer2>\\boxed{Palermo, Sicily}</answer2>\n",
      "<search>Where was the director of Steel (1979 Film) born?</search>\n",
      "<snippets id=e2290384>\n",
      "Don Levy position at the Carpenter Center for the Visual Arts at Harvard University, where he stayed for two years. He then moved to Los Angeles to work at the California Institute of the Arts, where he taught and conducted research in film, video and multimedia until his death in 1987 by committing suicide. Don Levy Don Levy (1932 ‚Äì January 1987) was an artist and filmmaker. Levy was born in Bathurst, New South Wales, Australia. After studying theoretical chemistry at the University of Sydney, he was awarded a Research Scholarship to the University of Cambridge. There he obtained a PhD in\n",
      "\n",
      "Roger Sherman (filmmaker) in 1969. He attended Union College (1969-1971), majoring in political science and experimental education, played freshman soccer, and spent a semester in Bogot√°, Colombia where he studied Spanish. He left Union and went to Denmark for his junior year abroad at The University of Copenhagen, Denmark. He studied architecture and history that fall and moved to , where he worked that winter at a hotel at the base of La Daille lift and a restaurant on top of the mountain. After returning from his year abroad, he attended Hampshire College, in Amherst, Massachusetts, where he graduated in 1975 with a\n",
      "\n",
      "James Goldstone the Vermont Arts Council which named its award for new talent the James Goldstone Award. Goldstone was the son of Hollywood agent and early television producer, Jules Goldstone. James Goldstone James Goldstone (born June 8, 1931 in Los Angeles, California; died November 5, 1999 in Shaftsbury, Vermont) was an American film and television director whose career spanned over thirty years. Goldstone was noted for the momentum and \"fifteen-minute cliffhangers\" that he brought to TV pilots such as \"\" (\"Where No Man Has Gone Before\", 1966), \"Ironside\", and \"\". His later career helped pioneer the concept of \"thirty-second attention span\" pacing\n",
      "</snippets> \n",
      "\n",
      "Robert E. Goldstone by opening him to film criticism.\n",
      "\n",
      "Sam Davis (actor) embellished this philosophy in his opening narrative to an Arcana Publishing interview\" Once, an actor forced into a Hollywood life, I fully surrender any knowledge of this man. But, he always knew that his parents must be proud. My father was born in Palermo, Sicily and my mother was born in New York City's Lower East Side. My father lived there until he left for America with his family. My father, a street-rat who gambled with them, was beaten as a child. He used to tell me about like a boy with candy felons. My mother was a stray adult heir of a grandmother with only one arm, and a grandmother with only one arm for the self-defense industry's sake. My mother, pruned I'm a wine-field wrestling\n",
      "\n",
      "<answer3>\\boxed{No}</answer3>\n",
      "<search>Did Uwe Bollm and Shibusawa Eiichi share the same nationality?</search>\n",
      "<snippets id=4a1199ae>\n",
      "Shigeo Kishibe hichiriki), the n≈çkan, nagauta, itchu-b≈´shi, and the Chinese guqin. Shigeo Kishibe Kishibe was born in Tokyo in the district of Kanda-Jinb≈çch≈ç, to Fukuo Kishibe, an educator and children‚Äôs writer. He was first exposed to music through music in his father‚Äôs stories, and made his first record and stage appearance at age 9 (by East Asian age reckoning) and first appeared on the radio at age 14. As a teenager, he became fascinated by Asian history. At this time he also met the eminent scholar of Japanese and Asian music Hisao Tanabe. In April 1933, he enrolled at the Tokyo Imperial\n",
      "\n",
      "Japanese people were forced to repatriate to Hokkaid≈ç by the Soviet Union as a part of Japanese people. On the other hand, many Sakhalin Koreans who had held Japanese citizenship until the end of the war were left stateless by the Soviet occupation. Article 10 of the Constitution of Japan defines the term \"Japanese\" based upon Japanese nationality. The concept of \"ethnic groups\" in Japanese census statistics differs from the concept applied in many other countries. For example, the United Kingdom Census queries the respondent's \"ethnic or racial background\", regardless of nationality. The Japanese Statistics Bureau, however, asks only about nationality in\n",
      "\n",
      "Wolfgang Michel-Zaitsu Gakkai). Wolfgang Michel-Zaitsu Wolfgang Michel/Michel-Zaitsu (born 1946 in Frankfurt am Main, Germany) is a professor emeritus of Kyushu University in Fukuoka (Japan). He is a specialist in medicine and allied sciences in the history of East-West cultural exchange. In 1984 he was granted tenure as the first foreigner in a Japanese national university. By combining Japanese and Western manuscript sources, Michel shed new light on Western medicine and allied sciences in early modern Japan and the interdependence of Western studies on Eastern medicine and Japanese studies on Western medicine. His research clarified the mechanism of early medical interactions between Japan\n",
      "</snippets>\n",
      "====================================================================================================\n",
      "[(2602, 5401)]\n",
      "1742\n",
      "1742\n",
      "{'total_spans': 1, 'valid_start_mappings': 1, 'valid_end_mappings': 1, 'fallback_start_mappings': 0, 'fallback_end_mappings': 0}\n",
      "<search>Where was the director of Steel (1979 Film) born?</search>\n",
      "<snippets id=e2290384>\n",
      "Don Levy position at the Carpenter Center for the Visual Arts at Harvard University, where he stayed for two years. He then moved to Los Angeles to work at the California Institute of the Arts, where he taught and conducted research in film, video and multimedia until his death in 1987 by committing suicide. Don Levy Don Levy (1932 ‚Äì January 1987) was an artist and filmmaker. Levy was born in Bathurst, New South Wales, Australia. After studying theoretical chemistry at the University of Sydney, he was awarded a Research Scholarship to the University of Cambridge. There he obtained a PhD in\n",
      "\n",
      "Roger Sherman (filmmaker) in 1969. He attended Union College (1969-1971), majoring in political science and experimental education, played freshman soccer, and spent a semester in Bogot√°, Colombia where he studied Spanish. He left Union and went to Denmark for his junior year abroad at The University of Copenhagen, Denmark. He studied architecture and history that fall and moved to , where he worked that winter at a hotel at the base of La Daille lift and a restaurant on top of the mountain. After returning from his year abroad, he attended Hampshire College, in Amherst, Massachusetts, where he graduated in 1975 with a\n",
      "\n",
      "James Goldstone the Vermont Arts Council which named its award for new talent the James Goldstone Award. Goldstone was the son of Hollywood agent and early television producer, Jules Goldstone. James Goldstone James Goldstone (born June 8, 1931 in Los Angeles, California; died November 5, 1999 in Shaftsbury, Vermont) was an American film and television director whose career spanned over thirty years. Goldstone was noted for the momentum and \"fifteen-minute cliffhangers\" that he brought to TV pilots such as \"\" (\"Where No Man Has Gone Before\", 1966), \"Ironside\", and \"\". His later career helped pioneer the concept of \"thirty-second attention span\" pacing\n",
      "</snippets> \n",
      "\n",
      "Robert E. Goldstone by opening him to film criticism.\n",
      "\n",
      "Sam Davis (actor) embellished this philosophy in his opening narrative to an Arcana Publishing interview\" Once, an actor forced into a Hollywood life, I fully surrender any knowledge of this man. But, he always knew that his parents must be proud. My father was born in Palermo, Sicily and my mother was born in New York City's Lower East Side. My father lived there until he left for America with his family. My father, a street-rat who gambled with them, was beaten as a child. He used to tell me about like a boy with candy felons. My mother was a stray adult heir of a grandmother with only one arm, and a grandmother with only one arm for the self-defense industry's sake. My mother, pruned I'm a wine-field wrestling\n",
      "\n",
      "<answer3>\\boxed{No}</answer3>\n",
      "<search>Did Uwe Bollm and Shibusawa Eiichi share the same nationality?</search>\n",
      "<snippets id=4a1199ae>\n",
      "Shigeo Kishibe hichiriki), the n≈çkan, nagauta, itchu-b≈´shi, and the Chinese guqin. Shigeo Kishibe Kishibe was born in Tokyo in the district of Kanda-Jinb≈çch≈ç, to Fukuo Kishibe, an educator and children‚Äôs writer. He was first exposed to music through music in his father‚Äôs stories, and made his first record and stage appearance at age 9 (by East Asian age reckoning) and first appeared on the radio at age 14. As a teenager, he became fascinated by Asian history. At this time he also met the eminent scholar of Japanese and Asian music Hisao Tanabe. In April 1933, he enrolled at the Tokyo Imperial\n",
      "\n",
      "Japanese people were forced to repatriate to Hokkaid≈ç by the Soviet Union as a part of Japanese people. On the other hand, many Sakhalin Koreans who had held Japanese citizenship until the end of the war were left stateless by the Soviet occupation. Article 10 of the Constitution of Japan defines the term \"Japanese\" based upon Japanese nationality. The concept of \"ethnic groups\" in Japanese census statistics differs from the concept applied in many other countries. For example, the United Kingdom Census queries the respondent's \"ethnic or racial background\", regardless of nationality. The Japanese Statistics Bureau, however, asks only about nationality in\n",
      "\n",
      "Wolfgang Michel-Zaitsu Gakkai). Wolfgang Michel-Zaitsu Wolfgang Michel/Michel-Zaitsu (born 1946 in Frankfurt am Main, Germany) is a professor emeritus of Kyushu University in Fukuoka (Japan). He is a specialist in medicine and allied sciences in the history of East-West cultural exchange. In 1984 he was granted tenure as the first foreigner in a Japanese national university. By combining Japanese and Western manuscript sources, Michel shed new light on Western medicine and allied sciences in early modern Japan and the interdependence of Western studies on Eastern medicine and Japanese studies on Western medicine. His research clarified the mechanism of early medical interactions between Japan\n",
      "</snippets>\n",
      "====================================================================================================\n",
      "[(-1, -1)]\n",
      "====================================================================================================\n",
      "[(5401, 7484)]\n",
      "1742\n",
      "1742\n",
      "{'total_spans': 1, 'valid_start_mappings': 1, 'valid_end_mappings': 1, 'fallback_start_mappings': 0, 'fallback_end_mappings': 0}\n",
      "<search>Did Uwe Bollm and Shibusawa Eiichi share the same nationality?</search>\n",
      "<snippets id=4a1199ae>\n",
      "Shigeo Kishibe hichiriki), the n≈çkan, nagauta, itchu-b≈´shi, and the Chinese guqin. Shigeo Kishibe Kishibe was born in Tokyo in the district of Kanda-Jinb≈çch≈ç, to Fukuo Kishibe, an educator and children‚Äôs writer. He was first exposed to music through music in his father‚Äôs stories, and made his first record and stage appearance at age 9 (by East Asian age reckoning) and first appeared on the radio at age 14. As a teenager, he became fascinated by Asian history. At this time he also met the eminent scholar of Japanese and Asian music Hisao Tanabe. In April 1933, he enrolled at the Tokyo Imperial\n",
      "\n",
      "Japanese people were forced to repatriate to Hokkaid≈ç by the Soviet Union as a part of Japanese people. On the other hand, many Sakhalin Koreans who had held Japanese citizenship until the end of the war were left stateless by the Soviet occupation. Article 10 of the Constitution of Japan defines the term \"Japanese\" based upon Japanese nationality. The concept of \"ethnic groups\" in Japanese census statistics differs from the concept applied in many other countries. For example, the United Kingdom Census queries the respondent's \"ethnic or racial background\", regardless of nationality. The Japanese Statistics Bureau, however, asks only about nationality in\n",
      "\n",
      "Wolfgang Michel-Zaitsu Gakkai). Wolfgang Michel-Zaitsu Wolfgang Michel/Michel-Zaitsu (born 1946 in Frankfurt am Main, Germany) is a professor emeritus of Kyushu University in Fukuoka (Japan). He is a specialist in medicine and allied sciences in the history of East-West cultural exchange. In 1984 he was granted tenure as the first foreigner in a Japanese national university. By combining Japanese and Western manuscript sources, Michel shed new light on Western medicine and allied sciences in early modern Japan and the interdependence of Western studies on Eastern medicine and Japanese studies on Western medicine. His research clarified the mechanism of early medical interactions between Japan\n",
      "</snippets>\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(set(advantage))\n",
    "print(spans)\n",
    "print(\"*\"*100)\n",
    "mask_list, span_stats_list, decoded_list = [], [], []\n",
    "for i in range(len(spans)):\n",
    "    print(spans[i])\n",
    "    if spans[i][0][0] != -1:\n",
    "        mask, span_stats = convert_string_span_to_token_span(effective_spans=spans[i], decoded_resp=response, token_resp=res, tokenizer=tokenizer)\n",
    "        decoded_res = tokenizer.decode(res[mask.index(1):], skip_special_tokens=True)\n",
    "        mask_list.append(mask)\n",
    "        span_stats_list.append(span_stats)\n",
    "        decoded_list.append(decoded_res)\n",
    "        print(len(mask))\n",
    "        print(len(res))\n",
    "        print(span_stats)\n",
    "        print(decoded_res)\n",
    "        \n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37052b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 29)],\n",
       " [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...],\n",
       " [27, 9217, 16, 8449, 79075, 90, 2753, 5361, 9217, 16, 151643])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans[0], mask_list[0], [res[i] for i in range(len(res)) if mask_list[0][i] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82917df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<answer1>\\\\boxed{No}</answer1'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 0\n",
    "effective_tokens = [res[i] for i in range(len(res)) if mask_list[j][i] == 1]\n",
    "tokenizer.decode(effective_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f6186b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<search>Do Sucker Punch (2011 film) and Plaga Zombie share the same director nationality?</search>\\n<snippets id=4fbd077c>\\nPlaga Zombie (film series) studio based in New Bedford, Massachusetts, the company is best known for its award-winning 2007 horror film \"The Terror Factor\". Writer-director Garry Mederios discovered the Plaga Zombie series after watching the Fangoria Film DVD. Mederios enjoyed the series so much that he contacted the filmmakers via e-mail and became friends. He jokingly suggested making an American-based Plaga Zombie film during one of their exchanges but FARSA Productions was very receptive to the idea and plans were eventually made to produce a feature-length film. Set in the same universe as the original trilogy, Plaga Zombie: American Invasion is to feature three\\n\\nNathan Schiff The poetic, whirling, free style of its imagery is remarkably close in spirit to James Joyce\". Schiff later returned to filmmaking with the horror short \"Abracadaver!\" (2008), made for British producer David McGillivray. Promoted as \"a gruesome tale of magic and mutilation,\" the film was part of McGillivray\\'s \"Worst Fears\" series. \"Long Island Cannibal Massacre\" and \"Weasels Rip My Flesh\" were selections of Cinefamily\\'s 2008 Homemade Horror festival, and Schiff was flown to the West Coast as an invited guest of the Cinefamily film study group. The features were shown under the umbrella title \"The Super-8 Gorenography of Nathan Schiff!\"\\n\\nPlaga Zombie (film series) Raimi\\'s Evil Dead II. The filmmakers themselves are admitted fans of these films but claim never to have seen George Romero\\'s Night of the Living Dead series. Peter Dendle, a Penn State Mont Alto film scholar, has said that the films are more akin to Japanese-style horror with \"the deliberate piling up of non-sequiters and flaunting of narrative expectations\". Plaga Zombie (film series) Plaga Zombie is an Argentine comedy horror film series created by Pablo Par√©s, Berta Mu√±iz, and Hern√°n S√°ez. The films follow three misfit heroes who uncover an alien-government conspiracy after a zombie outbreak occurs in their hometown.\\n</snippets> \\nHanjin Colombia warned that the group will not allow its cargo vessels, which entered eight months ago, ... ... ... Plaga Zombie: American Invasion is not finished yet!\\n\\nPlaga Zombi (Gorri√≥n Pierce) was also made by Daniel Estep at New Bedford, ORDER Back to Plaga Zombi Meltingmilk Films Henri: \\'Wanted\\' (2012 - 44mins). Henri\\'s film \\'Wanted\\' tells the story of a couple who are high school students.\\n\\n<answer2>\\\\boxed{Palermo, Sicily}</answer2'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 1\n",
    "effective_tokens = [res[i] for i in range(len(res)) if mask_list[j][i] == 1]\n",
    "tokenizer.decode(effective_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b268503e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<search>Where was the director of Steel (1979 Film) born?</search>\\n<snippets id=e2290384>\\nDon Levy position at the Carpenter Center for the Visual Arts at Harvard University, where he stayed for two years. He then moved to Los Angeles to work at the California Institute of the Arts, where he taught and conducted research in film, video and multimedia until his death in 1987 by committing suicide. Don Levy Don Levy (1932 ‚Äì January 1987) was an artist and filmmaker. Levy was born in Bathurst, New South Wales, Australia. After studying theoretical chemistry at the University of Sydney, he was awarded a Research Scholarship to the University of Cambridge. There he obtained a PhD in\\n\\nRoger Sherman (filmmaker) in 1969. He attended Union College (1969-1971), majoring in political science and experimental education, played freshman soccer, and spent a semester in Bogot√°, Colombia where he studied Spanish. He left Union and went to Denmark for his junior year abroad at The University of Copenhagen, Denmark. He studied architecture and history that fall and moved to , where he worked that winter at a hotel at the base of La Daille lift and a restaurant on top of the mountain. After returning from his year abroad, he attended Hampshire College, in Amherst, Massachusetts, where he graduated in 1975 with a\\n\\nJames Goldstone the Vermont Arts Council which named its award for new talent the James Goldstone Award. Goldstone was the son of Hollywood agent and early television producer, Jules Goldstone. James Goldstone James Goldstone (born June 8, 1931 in Los Angeles, California; died November 5, 1999 in Shaftsbury, Vermont) was an American film and television director whose career spanned over thirty years. Goldstone was noted for the momentum and \"fifteen-minute cliffhangers\" that he brought to TV pilots such as \"\" (\"Where No Man Has Gone Before\", 1966), \"Ironside\", and \"\". His later career helped pioneer the concept of \"thirty-second attention span\" pacing\\n</snippets> \\n\\nRobert E. Goldstone by opening him to film criticism.\\n\\nSam Davis (actor) embellished this philosophy in his opening narrative to an Arcana Publishing interview\" Once, an actor forced into a Hollywood life, I fully surrender any knowledge of this man. But, he always knew that his parents must be proud. My father was born in Palermo, Sicily and my mother was born in New York City\\'s Lower East Side. My father lived there until he left for America with his family. My father, a street-rat who gambled with them, was beaten as a child. He used to tell me about like a boy with candy felons. My mother was a stray adult heir of a grandmother with only one arm, and a grandmother with only one arm for the self-defense industry\\'s sake. My mother, pruned I\\'m a wine-field wrestling\\n\\n<answer3>\\\\boxed{No}</answer3'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 2\n",
    "effective_tokens = [res[i] for i in range(len(res)) if mask_list[j][i] == 1]\n",
    "tokenizer.decode(effective_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5ee0891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.0,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " -1.0780363082885742,\n",
       " 0.0,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " 0.9276126027107239,\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73327082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b179e61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2900/2900 [00:00<00:00, 73586.95 examples/s]\n",
      "Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [00:00<00:00, 10432.29 examples/s]\n",
      "Generating validation split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 15325.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rulins/multi_question_synthetic_single_source_2wiki_5q\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60a6f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = dataset[0][\"ground_truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00943cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "gt_list = json.loads(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f947cf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['California Institute of the Arts', 'no', 'no']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7201d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-instruct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
