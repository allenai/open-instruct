# TODO When updating flash-attn or torch in the future, make sure to update the version in the Dockerfile 
torch
scipy
packaging
sentencepiece
datasets
accelerate==0.31.0
peft>=0.11.1
bitsandbytes>=0.41.1
evaluate>=0.4.0
tokenizers==0.19.1
protobuf
transformers>=4.40
openai>=1.0.0
tiktoken
rouge_score
tensorboard
wandb
gradio>=3.50.2
termcolor
jsonlines
unidic-lite
einops
flash-attn==2.5.8 # should really only be in dockerfile. Local env often doesn't have GPUs
fire
alpaca-eval==0.6.2
# for human eval web app
flask
vllm>=0.5.4  # for llama 3 + olmo compat.
openpyxl
# for ifeval
nltk==3.8.1
langdetect
immutabledict
# for linting
black
flake8
isort
autoflake
