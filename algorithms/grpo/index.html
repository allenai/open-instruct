
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://github.com/allenai/open-instruct/algorithms/grpo/">
      
      
        <link rel="prev" href="../dpo/">
      
      
        <link rel="next" href="../ppo/">
      
      
        
      
      
      <link rel="icon" href="../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Grouped Relative Policy Optimization (GRPO) - Open Instruct</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="ai2-dark" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#grouped-relative-policy-optimization-grpo" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Open Instruct" class="md-header__button md-logo" aria-label="Open Instruct" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Open Instruct
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Grouped Relative Policy Optimization (GRPO)
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="ai2-dark" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 0-7 7c0 2.38 1.19 4.47 3 5.74V17a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1v-2.26c1.81-1.27 3-3.36 3-5.74a7 7 0 0 0-7-7M9 21a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1H9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="ai2" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 1 7 7c0 2.38-1.19 4.47-3 5.74V17a1 1 0 0 1-1 1H9a1 1 0 0 1-1-1v-2.26C6.19 13.47 5 11.38 5 9a7 7 0 0 1 7-7M9 21v-1h6v1a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1m3-17a5 5 0 0 0-5 5c0 2.05 1.23 3.81 3 4.58V16h4v-2.42c1.77-.77 3-2.53 3-4.58a5 5 0 0 0-5-5"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/allenai/open-instruct" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    allenai/open-instruct
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Open Instruct" class="md-nav__button md-logo" aria-label="Open Instruct" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Open Instruct
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/allenai/open-instruct" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    allenai/open-instruct
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Get Started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Get Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../get_started/installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../get_started/ai2_internal_setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ai2 Internal Setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../olmo3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    OLMo 3
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../olmo2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    OLMo 2 Commands
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tulu3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tulu3 Reproduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tulu1_tulu2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tulu1 tulu2
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Training
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Training
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dataset_transformation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Dataset Transformations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trained_model_location/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Trained Model Location
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Supervised finetuning (SFT)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dpo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Direct Preference Optimization (DPO)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Grouped Relative Policy Optimization (GRPO)
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Grouped Relative Policy Optimization (GRPO)
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#implemented-variants" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implemented Variants
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grpo_fastpy" class="md-nav__link">
    <span class="md-ellipsis">
      
        grpo_fast.py
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="grpo_fast.py">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#debug-single-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      
        Debug (Single GPU)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reproduce-allenaillama-31-tulu-31-8b-1-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reproduce allenai/Llama-3.1-Tulu-3.1-8B (1 Nodes)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experimental-qwen-25-7b-grpo-fast-zero-style" class="md-nav__link">
    <span class="md-ellipsis">
      
        (ðŸ§ª Experimental) Qwen 2.5 7B GRPO Fast Zero-style
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experimental-olmo2-7b-grpo-fast-zero-style" class="md-nav__link">
    <span class="md-ellipsis">
      
        (ðŸ§ª Experimental) Olmo2 7B GRPO Fast Zero-style
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experimental-olmo2-13b-grpo-fast-zero-style" class="md-nav__link">
    <span class="md-ellipsis">
      
        (ðŸ§ª Experimental) Olmo2 13B GRPO Fast Zero-style
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training Metrics
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grpo_vllm_thread_ray_gtrlpy" class="md-nav__link">
    <span class="md-ellipsis">
      
        grpo_vllm_thread_ray_gtrl.py
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="grpo_vllm_thread_ray_gtrl.py">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#debug-single-gpu_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Debug (Single GPU)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reproduce-allenaillama-31-tulu-31-8b-2-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reproduce allenai/Llama-3.1-Tulu-3.1-8B (2 Nodes)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reproduce-allenaiolmo-2-1124-7b-instruct-but-better-2-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reproduce allenai/OLMo-2-1124-7B-Instruct but better (2 Nodes)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experimental-qwen-25-7b-zero-style" class="md-nav__link">
    <span class="md-ellipsis">
      
        (ðŸ§ª Experimental) Qwen 2.5 7B Zero-style
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-metrics_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training Metrics
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#acknowledgements" class="md-nav__link">
    <span class="md-ellipsis">
      
        Acknowledgements
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ppo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Proximal Policy Optimization (PPO)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reward_modeling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Reward Modeling (RM)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Not Maintained
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Not Maintained
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../synthetic_preference_dataset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Synthetic preference dataset
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#implemented-variants" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implemented Variants
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grpo_fastpy" class="md-nav__link">
    <span class="md-ellipsis">
      
        grpo_fast.py
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="grpo_fast.py">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#debug-single-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      
        Debug (Single GPU)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reproduce-allenaillama-31-tulu-31-8b-1-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reproduce allenai/Llama-3.1-Tulu-3.1-8B (1 Nodes)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experimental-qwen-25-7b-grpo-fast-zero-style" class="md-nav__link">
    <span class="md-ellipsis">
      
        (ðŸ§ª Experimental) Qwen 2.5 7B GRPO Fast Zero-style
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experimental-olmo2-7b-grpo-fast-zero-style" class="md-nav__link">
    <span class="md-ellipsis">
      
        (ðŸ§ª Experimental) Olmo2 7B GRPO Fast Zero-style
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experimental-olmo2-13b-grpo-fast-zero-style" class="md-nav__link">
    <span class="md-ellipsis">
      
        (ðŸ§ª Experimental) Olmo2 13B GRPO Fast Zero-style
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training Metrics
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grpo_vllm_thread_ray_gtrlpy" class="md-nav__link">
    <span class="md-ellipsis">
      
        grpo_vllm_thread_ray_gtrl.py
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="grpo_vllm_thread_ray_gtrl.py">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#debug-single-gpu_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Debug (Single GPU)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reproduce-allenaillama-31-tulu-31-8b-2-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reproduce allenai/Llama-3.1-Tulu-3.1-8B (2 Nodes)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reproduce-allenaiolmo-2-1124-7b-instruct-but-better-2-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reproduce allenai/OLMo-2-1124-7B-Instruct but better (2 Nodes)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experimental-qwen-25-7b-zero-style" class="md-nav__link">
    <span class="md-ellipsis">
      
        (ðŸ§ª Experimental) Qwen 2.5 7B Zero-style
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-metrics_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training Metrics
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#acknowledgements" class="md-nav__link">
    <span class="md-ellipsis">
      
        Acknowledgements
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="grouped-relative-policy-optimization-grpo">Grouped Relative Policy Optimization (GRPO)</h1>
<p>GRPO is an online RL method used in <a href="https://arxiv.org/abs/2501.12948">DeepSeek R1 paper</a> and its first appearance is in <a href="https://arxiv.org/abs/2402.03300">DeepSeekMath</a></p>
<h2 id="implemented-variants">Implemented Variants</h2>
<ul>
<li><code>grpo_fast.py</code> is a faster variant using <a href="https://huggingface.co/blog/sirluk/llm-sequence-packing">packing techniques</a>.</li>
<li><code>grpo_vllm_thread_ray_gtrl.py</code> is a more vanilla GRPO implementation, using vLLM and Ray.</li>
</ul>
<h2 id="grpo_fastpy"><code>grpo_fast.py</code></h2>
<p>This implementation has the following features:</p>
<ul>
<li>Uses packing techniques to speed up the training process, inspired by <a href="https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero">Open-Reasoner-Zero/Open-Reasoner-Zero</a></li>
<li>Uses a thread-based approach to parallelize the training and inference processes, based on <a href="https://arxiv.org/abs/2410.18252">Asynchronous RLHF</a>.</li>
<li>Uses a data preparation thread to prepare the data for the training process.</li>
</ul>
<p>In simpler tasks, we see 2x faster training, and even 10x faster for more complex tasks. With <code>grpo_fast.py</code>, we can run crank up <code>number_samples_per_prompt</code> and train on really large batch sizes.</p>
<p>It implements additional optimizations:</p>
<ul>
<li><code>grpo_fast.py</code> also implements an optimization to skip zero gradient batches. If we solve a prompt 100% correct or 0% correct, the std of the group is 0. So <code>adv = (score - score.mean()) / (score.std + 1e-5) = 0 / 1e-5 = 0</code>, causing 0 gradients. <code>grpo_fast.py</code> will skip these batches before packing the sequences.</li>
</ul>
<p><img alt="" src="grpo_fast_gradient.png" /></p>
<p>Figure taken from <a href="https://discord.com/channels/1179127597926469703/1208183216843005962/1357712190957682839">this discord thread by @the_real_jrb</a></p>
<ul>
<li><code>grpo_fast.py</code> only applies the verification reward if the format reward is enabled (via <code>--additive_format_reward False</code> by default). See (<a href="https://github.com/allenai/open-instruct/pull/659">allenai/open-instruct/pull/659</a>). A direct additive format reward is undesirable. In GRPO, the scale of the rewards is not relevant due to group normalization. For example, a group of [0, 0, 0, 0, 10], [0, 0, 0, 0, 11], [0, 0, 0, 0, 1] reward will have the same advantage.</li>
</ul>
<p>Now imagine there are cases where the model generates a really long response (8k) gen length, but only get the format reward right, GRPO will push up the probs for this long response even though the response is not really correct. As a result, when using the format reward directly, we see the response length of unsolved prompts to fluctuate significantly, causing stability issues.</p>
<p><img alt="" src="additive_format_reward.png" /></p>
<h3 id="debug-single-gpu">Debug (Single GPU)</h3>
<p>You can run the script in a single GPU mode to debug the training process.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># single GPU</span>
bash<span class="w"> </span>scripts/train/debug/grpo_fast.sh
<span class="c1"># 3 GPU: 2 for training, 1 for inference (a more realistic setting for async training)</span>
bash<span class="w"> </span>scripts/train/debug/grpo_fast_3_gpu.sh
</code></pre></div>
<h3 id="reproduce-allenaillama-31-tulu-31-8b-1-nodes">Reproduce <code>allenai/Llama-3.1-Tulu-3.1-8B</code> (1 Nodes)</h3>
<p>You can reproduce our <code>allenai/Llama-3.1-Tulu-3.1-8B</code> model by running the following command:</p>
<div class="highlight"><pre><span></span><code>bash<span class="w"> </span>scripts/train/tulu3/grpo_fast_8b_single_node.sh
</code></pre></div>
<details class="info" open="open">
<summary>Info</summary>
<p>Here the <code>grpo_fast.py</code> actually use 6 GPUs for training and 2 GPUs for inference, so it's using less hardware but runs faster than <code>grpo_vllm_thread_ray_gtrl.py</code> which uses 2 nodes (12 GPUs for training and 4 GPUs for inference).</p>
</details>
<p><img alt="grpo_tulu3_8b" src="tulu3.1_8b_grpo_fast.png" />
<img alt="grpo_tulu3_8b_time" src="tulu3.1_8b_grpo_fast-time.png" /></p>
<details class="note">
<summary>ðŸ‘‰ Tracked WandB Experiments (Click to expand)</summary>
<p><iframe loading="lazy" src="https://wandb.ai/ai2-llm/open_instruct_public/reports/Tulu3-1-8B-GRPO-Fast--VmlldzoxMTk0NzcwOA" style="width:100%; height:500px" title="Tulu3-8B-GRPO-Fast"></iframe></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>Below are some learning curves for the evaluation metrics during training. Basically, ifeval, gsm8k, and math:flex all go up.</p>
<p><img alt="grpo_plot" src="tulu3.1_8b_grpo_fast_eval_curve.png" /></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>Based on our internal evaluation, the GRPO model is roughly on par with the original <code>allenai/Llama-3.1-Tulu-3.1-8B</code> model, though there are some slight differences. Note that your results may vary slightly due to the random seeds used in the training.</p>
<p><img alt="grpo_plot" src="tulu3.1_8b_grpo_fast_eval.png" /></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>We haven't quite figured out how to make our internal evaluation toolchains more open yet. Stay tuned!</p>
</details>
<h3 id="experimental-qwen-25-7b-grpo-fast-zero-style">(ðŸ§ª Experimental) Qwen 2.5 7B GRPO Fast Zero-style</h3>
<p>We have</p>
<div class="highlight"><pre><span></span><code>bash<span class="w"> </span>scripts/train/qwen/grpo_fast_7b.sh
</code></pre></div>
<p><img alt="grpo_qwen2.5_7B_works" src="qwen2.5_7b_grpo_fast_zero.png" />
<img alt="grpo_qwen2.5_7B_works_time" src="qwen2.5_7b_grpo_fast_zero-time.png" /></p>
<details class="note">
<summary>ðŸ‘‰ Tracked WandB Experiments (Click to expand)</summary>
<p><iframe loading="lazy" src="https://wandb.ai/ai2-llm/open_instruct_public/reports/Qwen2-5-7B-GRPO-Fast-Zero--VmlldzoxMjA2NDExMA" style="width:100%; height:500px" title="Qwen2.5-7B-GRPO-Fast-Zero"></iframe></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>Below are some learning curves for the evaluation metrics during training. Basically, ifeval, gsm8k, and math:flex all go up.</p>
<p><img alt="grpo_plot" src="qwen2.5_7b_grpo_fast_zero_eval_curve.png" /></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>We haven't quite figured out how to make our internal evaluation toolchains more open yet. Stay tuned!</p>
</details>
<h3 id="experimental-olmo2-7b-grpo-fast-zero-style">(ðŸ§ª Experimental) Olmo2 7B GRPO Fast Zero-style</h3>
<p>We have</p>
<div class="highlight"><pre><span></span><code>bash<span class="w"> </span>scripts/train/olmo2/grpo_fast_7b_zero.sh
</code></pre></div>
<p><img alt="grpo_olmo2_7b_zero" src="olmo2_7b_grpo_fast_zero.png" />
<img alt="grpo_olmo2_7b_zero_time" src="olmo2_7b_grpo_fast_zero-time.png" /></p>
<details class="note">
<summary>ðŸ‘‰ Tracked WandB Experiments (Click to expand)</summary>
<p><iframe loading="lazy" src="https://wandb.ai/ai2-llm/open_instruct_public/reports/OLMo-2-7B-GRPO-Fast-Zero--VmlldzoxMjA0MjU4MQ" style="width:100%; height:500px" title="OLMo2-7B-GRPO-Fast-Zero"></iframe></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>Below are some learning curves for the evaluation metrics during training. Basically, ifeval, gsm8k, and math:flex all go up.</p>
<p><img alt="grpo_plot" src="olmo2_7b_grpo_fast_zero_eval_curve.png" /></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>We haven't quite figured out how to make our internal evaluation toolchains more open yet. Stay tuned!</p>
</details>
<h3 id="experimental-olmo2-13b-grpo-fast-zero-style">(ðŸ§ª Experimental) Olmo2 13B GRPO Fast Zero-style</h3>
<p>We have</p>
<div class="highlight"><pre><span></span><code>bash<span class="w"> </span>scripts/train/olmo2/grpo_fast_13b_zero.sh
</code></pre></div>
<p><img alt="grpo_olmo2_13b_zero" src="olmo2_13b_grpo_fast_zero.png" />
<img alt="grpo_olmo2_13b_zero_time" src="olmo2_13b_grpo_fast_zero-time.png" /></p>
<details class="note">
<summary>ðŸ‘‰ Tracked WandB Experiments (Click to expand)</summary>
<p><iframe loading="lazy" src="https://wandb.ai/ai2-llm/open_instruct_public/reports/OLMo-2-13B-GRPO-Fast-Zero--VmlldzoxMjA0MjU4Mw" style="width:100%; height:500px" title="OLMo2-13B-GRPO-Fast-Zero"></iframe></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>Below are some learning curves for the evaluation metrics during training. Basically, ifeval, gsm8k, and math:flex all go up.</p>
<p><img alt="grpo_plot" src="olmo2_13b_grpo_fast_zero_eval_curve.png" /></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>We haven't quite figured out how to make our internal evaluation toolchains more open yet. Stay tuned!</p>
</details>
<h3 id="training-metrics">Training Metrics</h3>
<p>See the Training Metrics for <code>grpo_vllm_thread_ray_gtrl.py</code> below for general metrics. <code>grpo_fast.py</code> includes the following additional metrics:</p>
<ul>
<li><code>other/real_batch_size_ratio</code>: In GRPO, as we train we actually get smaller and smaller batch sizes. This is because if we solve a prompt 100% correct or 0% correct, the std of the group is 0. So <code>adv = (score - score.mean()) / (score.std + 1e-5) = 0 / 1e-5 = 0</code>, causing 0 gradients. This metric is the ratio of the samples that have gradients vs the total number of samples,</li>
<li><code>other/packed_ratio</code>: The ratio of the packed sequences vs the total number of sequences. The lower the ratio, the more efficiently we have packed the sequences. E.g., if we have 100 sequences and the ratio is 0.1, it means we only have to do 10% of the forward passes than if we didn't pack.</li>
</ul>
<h2 id="grpo_vllm_thread_ray_gtrlpy"><code>grpo_vllm_thread_ray_gtrl.py</code></h2>
<p>This implementation has the following features:</p>
<ul>
<li>Uses a thread-based approach to parallelize the training and inference processes, based on <a href="https://arxiv.org/abs/2410.18252">Asynchronous RLHF</a>.</li>
<li>Uses vLLM and Ray to parallelize the training process, based on how <a href="https://github.com/OpenRLHF/OpenRLHF">OpenRLHF</a> does it</li>
</ul>
<h3 id="debug-single-gpu_1">Debug (Single GPU)</h3>
<p>You can run the script in a single GPU mode to debug the training process.</p>
<div class="highlight"><pre><span></span><code>bash<span class="w"> </span>scripts/train/debug/grpo.sh
</code></pre></div>
<h3 id="reproduce-allenaillama-31-tulu-31-8b-2-nodes">Reproduce <code>allenai/Llama-3.1-Tulu-3.1-8B</code> (2 Nodes)</h3>
<p>You can reproduce our <code>allenai/Llama-3.1-Tulu-3.1-8B</code> model by running the following command:</p>
<div class="highlight"><pre><span></span><code>bash<span class="w"> </span>scripts/train/tulu3/grpo_8b.sh
</code></pre></div>
<p><img alt="grpo_tulu3_8b" src="tulu3.1_8b_grpo.png" />
<img alt="grpo_tulu3_8b_time" src="tulu3.1_8b_grpo-time.png" /></p>
<details class="note">
<summary>ðŸ‘‰ Tracked WandB Experiments (Click to expand)</summary>
<p><iframe loading="lazy" src="https://wandb.ai/ai2-llm/open_instruct_public/reports/Tulu3-1-8B-GRPO--VmlldzoxMTkyNzc2MA" style="width:100%; height:500px" title="Tulu3-8B-GRPO"></iframe></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>Below are some learning curves for the evaluation metrics during training. Basically, ifeval, gsm8k, and math:flex all go up.</p>
<p><img alt="grpo_plot" src="tulu3.1_8b_grpo_eval_curve.png" /></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>Based on our internal evaluation, the GRPO model is roughly on par with the original <code>allenai/Llama-3.1-Tulu-3.1-8B</code> model, though there are some slight differences. Note that your results may vary slightly due to the random seeds used in the training.</p>
<p><img alt="grpo_plot" src="tulu3.1_8b_grpo_eval.png" /></p>
</details>
<h3 id="reproduce-allenaiolmo-2-1124-7b-instruct-but-better-2-nodes">Reproduce <code>allenai/OLMo-2-1124-7B-Instruct</code> but better (2 Nodes)</h3>
<p>You can reproduce our <code>allenai/OLMo-2-1124-7B-Instruct</code> model by running the following command:</p>
<div class="highlight"><pre><span></span><code>bash<span class="w"> </span>scripts/train/olmo2/grpo_7b.sh
</code></pre></div>
<p><img alt="grpo_olmo2_7b" src="olmo2_7b_grpo.png" />
<img alt="grpo_olmo2_7b_time" src="olmo2_7b_grpo-time.png" /></p>
<details class="note">
<summary>ðŸ‘‰ Tracked WandB Experiments (Click to expand)</summary>
<p><iframe loading="lazy" src="https://wandb.ai/ai2-llm/open_instruct_public/reports/OLMo-2-7B-GRPO--VmlldzoxMTkyNzc1OA" style="width:100%; height:500px" title="OLMo2-7B-GRPO"></iframe></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>Below are some learning curves for the evaluation metrics during training. Basically, ifeval, gsm8k, and math:flex all go up.</p>
<p><img alt="grpo_plot" src="olmo2_7b_grpo_eval_curve.png" /></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>Based on our internal evaluation, the GRPO model actually outperforms the original <code>allenai/OLMo-2-1124-7B-Instruct</code> model. This is mostly because the original <code>allenai/OLMo-2-1124-7B-Instruct</code> was trained with PPO, which may suffer from not using a outcome reward model to initialize the value model (since it uses a genreal RM to initialize the value model). Note that your results may vary slightly due to the random seeds used in the training.</p>
<p><img alt="grpo_plot" src="olmo2_7b_grpo_eval.png" /></p>
</details>
<h3 id="experimental-qwen-25-7b-zero-style">(ðŸ§ª Experimental) Qwen 2.5 7B Zero-style</h3>
<p>Here is a command to run GRPO on the <code>Qwen/Qwen2.5-7B</code> on <a href="https://huggingface.co/datasets/ai2-adapt-dev/math_ground_truth_zs">ai2-adapt-dev/math_ground_truth_zs</a>, which is simply a zero-shot version of the RLVR MATH dataset. The training is done starting from a base model, similar to how <a href="https://arxiv.org/abs/2501.12948">DeepSeek R1</a> does it.</p>
<div class="highlight"><pre><span></span><code>bash<span class="w"> </span>scripts/train/qwen/grpo_7b.sh
</code></pre></div>
<p><img alt="grpo_qwen2.5_7B_works" src="qwen2.5_7b_grpo_zero.png" />
<img alt="grpo_qwen2.5_7B_works_time" src="qwen2.5_7b_grpo_zero-time.png" /></p>
<details class="note">
<summary>ðŸ‘‰ Tracked WandB Experiments (Click to expand)</summary>
<p><iframe loading="lazy" src="https://wandb.ai/ai2-llm/open_instruct_public/reports/Qwen2-5-7B-GRPO-Zero--VmlldzoxMjA0MjY5OA" style="width:100%; height:500px" title="Qwen2.5-7B-GRPO-Zero"></iframe></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>Below are some learning curves for the evaluation metrics during training. Basically, ifeval, gsm8k, and math:flex all go up.</p>
<p><img alt="grpo_plot" src="qwen2.5_7b_grpo_zero_eval_curve.png" /></p>
</details>
<details class="info" open="open">
<summary>Info</summary>
<p>We haven't quite figured out how to make our internal evaluation toolchains more open yet. Stay tuned!</p>
</details>
<h3 id="training-metrics_1">Training Metrics</h3>
<p>During training, the following metrics are logged:</p>
<ul>
<li><code>episode</code>: the global episode number training has gone through (e.g., <code>3000</code> means we have trained on 3000 data points already -- in the case of RLVR that is prompts, which can repeat)</li>
<li><code>lr</code>: the current learning rate</li>
<li><code>epoch</code>: the fraction or multiple of the epoch (e.g., <code>2.7</code> means we have trained on the dataset for 2 epochs and 70% of the third epoch)</li>
<li><code>objective/kl</code>: the KL divergence between the current policy and the reference policy (sum of the KL divergence of each response token)</li>
<li><code>objective/scores</code>: the scores of the current response, rated by a combination of reward model and other rewards (e.g., R1 style format reward, verifiable reward, etc.)</li>
<li><code>objective/rlhf_reward</code>: the RLHF reward, which is <code>objective/scores</code> - <code>beta</code> * <code>objective/kl</code></li>
<li><code>objective/non_score_reward</code>: <code>beta</code> * <code>objective/kl</code></li>
<li><code>objective/entropy</code>: the entropy of the current policy</li>
<li><code>objective/loss</code>: the GRPO loss</li>
<li><code>objective/kl2</code>: the second variant of KL divergence used in the training process, calculated similarly to <code>objective/kl</code></li>
<li><code>objective/kl3</code>: the third variant of KL divergence used in the training process, providing additional insights into policy divergence</li>
<li><code>objective/scores_mean</code>: the mean of the scores of the current response, providing an average measure of response quality</li>
<li><code>objective/reward_std</code>: the standard deviation of the rewards, indicating the variability in the reward distribution</li>
<li><code>objective/verifiable_correct_rate</code>: the rate at which responses are verifiably correct, providing a measure of response accuracy</li>
<li><code>loss/policy_avg</code>: the average policy loss, indicating the mean loss incurred during policy updates</li>
<li><code>policy/approxkl_avg</code>: the average approximate KL divergence, used to monitor policy stability</li>
<li><code>policy/clipfrac_avg</code>: the average fraction of updates where the policy was clipped, indicating how often clipping occurs</li>
<li><code>policy/entropy_avg</code>: the average entropy of the policy, providing a measure of policy randomness</li>
<li><code>time/from_scratch</code>: the time taken to train the model from scratch</li>
<li><code>time/training</code>: the time taken to do one training step</li>
<li><code>val/sequence_lengths</code>: the length of the sequences in the generated responses</li>
<li><code>val/num_stop_token_ids</code>: the number of stop tokens in the generated responses</li>
<li><code>val/ratio</code>: the mean ratio of the new policy to the old policy, used to assess policy updates</li>
<li><code>val/ratio_var</code>: the variance of the ratio of the new policy to the old policy, indicating the variability in policy updates</li>
<li><code>val/stop_token_rate</code>: the rate at which stop tokens appear in the responses, providing a measure of response termination</li>
<li><code>val/format_scores</code>: the mean format scores, indicating the quality of response formatting (only logged if <code>add_r1_style_format_reward</code> is enabled)</li>
<li><code>other/real_batch_size_ratio</code>: In GRPO, as we train we actually get smaller and smaller batch sizes. This is because if we solve a prompt 100% correct or 0% correct, the std of the group is 0. So <code>adv = (score - score.mean()) / (score.std + 1e-5) = 0 / 1e-5 = 0</code>, causing 0 gradients. This metric is the ratio of the samples that have gradients vs the total number of samples,</li>
<li><code>other/packed_ratio</code>: The ratio of the packed sequences vs the total number of sequences. The lower the ratio, the more efficiently we have packed the sequences. E.g., if we have 100 sequences and the ratio is 0.1, it means we only have to do 10% of the forward passes than if we didn't pack.</li>
</ul>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>We would like to thank the following resources for GRPO theory:</p>
<ul>
<li><a href="https://arxiv.org/abs/2501.12948">DeepSeek R1</a></li>
<li><a href="https://arxiv.org/abs/2402.03300">DeepSeekMath</a></li>
<li><a href="https://arxiv.org/abs/2410.18252">Asynchronous RLHF</a></li>
</ul>
<p>We would like to thank the following resources for GRPO implementation and Ray usage:</p>
<ul>
<li><a href="https://huggingface.co/blog/sirluk/llm-sequence-packing">Packing Techniques</a></li>
<li><a href="https://github.com/OpenRLHF/OpenRLHF">OpenRLHF/OpenRLHF</a></li>
<li><a href="https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero">Open-Reasoner-Zero/Open-Reasoner-Zero</a></li>
</ul>
<p>We would like to thank the following projects for general infrastructure:</p>
<ul>
<li><a href="https://github.com/vllm-project/vllm">vLLM</a></li>
<li><a href="https://github.com/ray-project/ray">Ray</a></li>
<li><a href="https://github.com/deepspeedai/DeepSpeed">DeepSpeedAI/DeepSpeed</a></li>
<li><a href="https://github.com/huggingface/transformers">HuggingFace/Transformers</a></li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tracking", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>