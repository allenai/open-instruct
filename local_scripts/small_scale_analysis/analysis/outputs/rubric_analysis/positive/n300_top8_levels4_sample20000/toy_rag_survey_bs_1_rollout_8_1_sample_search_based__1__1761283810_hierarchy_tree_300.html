
        <!DOCTYPE html>
        <html>
        <head>
            <title>Hierarchy Tree Visualization</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    margin: 20px;
                    background-color: #f5f5f5;
                }
                .tree {
                    --spacing: 1.5rem;
                    --radius: 10px;
                }
                .tree li {
                    display: block;
                    position: relative;
                    padding-left: calc(2 * var(--spacing) - var(--radius) - 2px);
                }
                .tree ul {
                    margin-left: calc(var(--radius) - var(--spacing));
                    padding-left: 0;
                }
                .tree ul li {
                    border-left: 2px solid #ddd;
                }
                .tree ul li:last-child {
                    border-color: transparent;
                }
                .tree ul li::before {
                    content: '';
                    display: block;
                    position: absolute;
                    top: calc(var(--spacing) / -2);
                    left: -2px;
                    width: calc(var(--spacing) + 2px);
                    height: calc(var(--spacing) + 1px);
                    border: solid #ddd;
                    border-width: 0 0 2px 2px;
                }
                .tree summary {
                    display: block;
                    cursor: pointer;
                }
                .tree summary::marker,
                .tree summary::-webkit-details-marker {
                    display: none;
                }
                .tree summary:focus {
                    outline: none;
                }
                .tree summary:focus-visible {
                    outline: 1px dotted #000;
                }
                .tree li div.node {
                    position: relative;
                    display: flex;
                    align-items: center;
                    min-height: var(--spacing);
                    padding: 0.25rem 0.75rem;
                    background-color: white;
                    border: 1px solid #ddd;
                    border-radius: var(--radius);
                    color: #333;
                    font-size: 0.9rem;
                }
                .level-0 > div.node { background-color: #e6f3ff; border-color: #b3d7ff; }
                .level-1 > div.node { background-color: #e6ffe6; border-color: #b3ffb3; }
                .level-2 > div.node { background-color: #fff2e6; border-color: #ffcc99; }
                .level-3 > div.node { background-color: #f9e6ff; border-color: #e6b3ff; }
                .level-4 > div.node { background-color: #ffe6e6; border-color: #ffb3b3; }
                
                details.tree-item {
                    margin-bottom: 0.125rem;
                }
                
                details.tree-item[open] > summary div.node::before {
                    content: "▼";
                    position: absolute;
                    right: 0.5rem;
                    font-size: 0.7rem;
                    color: #666;
                }
                
                details.tree-item:not([open]) > summary div.node::before {
                    content: "▶";
                    position: absolute;
                    right: 0.5rem;
                    font-size: 0.7rem;
                    color: #666;
                }
                
                .node-label {
                    font-weight: bold;
                    margin-right: 0.5rem;
                }
                
                .node-desc {
                    white-space: nowrap;
                    overflow: hidden;
                    text-overflow: ellipsis;
                    max-width: 500px;
                }
                
                .leaf-item {
                    font-size: 0.85rem;
                    padding: 0.1rem 0;
                }
            </style>
        </head>
        <body>
            <h1>Hierarchy Tree Visualization</h1>
            <p>Click on nodes to expand/collapse. The tree shows minimal descriptions of each cluster.</p>
            <ul class="tree">
        <li class="level-3"><details class="tree-item" open><summary><div class="node"><span class="node-label">L3-0:</span> <span class="node-desc">Label: Comprehensive RAG Survey Frameworks  </span></div></summary><ul><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-13:</span> <span class="node-desc">Label: Accessible and Practical RAG Insights  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-22:</span> <span class="node-desc">Label: Accessible and Insightful RAG Exploration  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 27:</span> <span class="node-desc">Provides concrete, illustrative examples (e.g., code snippets, real-world applications, or case studies) that clarify complex RAG concepts and make technical advances accessible to a broad audience.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 129:</span> <span class="node-desc">Presents survey questions that not only cover recent RAG advancements but also contextualize each topic with concise, accessible background information, enabling respondents of varying expertise to engage meaningfully without requiring extensive prior knowledge.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 124:</span> <span class="node-desc">Provides concrete, illustrative examples or case studies (such as specific RAG applications or real-world deployments) that clarify abstract concepts and demonstrate practical relevance.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 167:</span> <span class="node-desc">Structures the survey to elicit both breadth and depth of respondent knowledge, balancing high-level overview questions with targeted prompts about specific technical aspects or recent innovations in RAG.</span></div></li></ul></details></li></ul></details></li><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-4:</span> <span class="node-desc">Label: Integrated Synthesis of RAG Research  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-24:</span> <span class="node-desc">Label: Synthesizing RAG Advancements</span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 57:</span> <span class="node-desc">Demonstrates nuanced understanding by contextualizing recent RAG advancements within broader trends in NLP or AI, explicitly connecting innovations like reasoning-intensive retrieval or context engineering to their implications for the field’s evolution.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 30:</span> <span class="node-desc">Demonstrates nuanced synthesis of recent RAG research by explicitly connecting technical advancements (e.g., reasoning-intensive retrieval, context engineering) to their practical implications or open challenges, rather than merely listing developments.</span></div></li></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-11:</span> <span class="node-desc">Label: Integrated Synthesis of RAG Advances  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 163:</span> <span class="node-desc">Synthesizes disparate recent advancements (e.g., Deep Research, reasoning-intensive retrieval, context engineering) into a logically connected narrative, explicitly articulating how each development interrelates and advances the RAG field, rather than listing them in isolation.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 276:</span> <span class="node-desc">Synthesizes and contextualizes recent research trends, challenges, and open questions in RAG (e.g., deep research, reasoning-intensive retrieval, context engineering) rather than merely listing topics, demonstrating an integrative understanding of the field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 156:</span> <span class="node-desc">Synthesizes recent research trends and subfields (e.g., Deep Research, reasoning-intensive retrieval, context engineering) into a cohesive narrative or structure, demonstrating an integrated understanding of how these advances interrelate within RAG rather than listing them in isolation.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 297:</span> <span class="node-desc">Synthesizes multiple technical subtopics (such as deep research, reasoning-intensive retrieval, and context engineering) into a coherent, logically structured narrative that highlights their interconnections and collective impact on RAG advancements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 150:</span> <span class="node-desc">Demonstrates a sophisticated grasp of current RAG research by accurately referencing recognized subfields, recent advancements, and open challenges, while avoiding outdated, generic, or tangentially related topics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 109:</span> <span class="node-desc">Demonstrates clear awareness of the latest RAG subfields (e.g., deep research, reasoning-intensive retrieval, context engineering) by explicitly referencing and integrating them into distinct, targeted survey items rather than treating them as generic or interchangeable topics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 69:</span> <span class="node-desc">Demonstrates nuanced differentiation between foundational RAG concepts and recent, specialized advancements (such as reasoning-intensive retrieval and context engineering), ensuring the survey not only covers breadth but also clarifies the evolution and interrelation of subtopics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 12:</span> <span class="node-desc">Demonstrates a nuanced synthesis of recent RAG research by not only listing subfields (e.g., deep research, reasoning-intensive retrieval, context engineering) but also articulating their interconnections, current challenges, and open research questions, thereby providing a cohesive, forward-looking perspective rather than a mere enumeration.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 188:</span> <span class="node-desc">Elaborates on the interplay between retrieval, reasoning, and context engineering by illustrating how these components interact or are jointly optimized in recent RAG systems, rather than treating them as isolated topics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 95:</span> <span class="node-desc">Demonstrates nuanced understanding by contextualizing RAG advancements within broader research trends, such as comparing new techniques to prior approaches or highlighting how recent innovations address known limitations in the field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 93:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by accurately distinguishing between subfields (e.g., deep retrieval research, reasoning-intensive retrieval, context engineering), and contextualizing their interrelations and unique contributions within the broader RAG landscape.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 157:</span> <span class="node-desc">Integrates up-to-date, field-specific terminology and references to recent research trends (e.g., 'multi-stage reasoning', 'contextual embeddings', 'compositional evolutionary learning'), demonstrating awareness of the evolving RAG landscape and providing respondents with cues to current discourse.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 151:</span> <span class="node-desc">Synthesizes and contrasts recent research directions, methods, or challenges in RAG (e.g., deep research, reasoning-intensive retrieval, context engineering) by explicitly comparing approaches, highlighting open problems, or proposing future research avenues, thereby demonstrating critical engagement with the evolving landscape rather than merely listing topics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 173:</span> <span class="node-desc">Frames survey questions that not only reference RAG subfields (e.g., deep research, reasoning-intensive retrieval, context engineering) but also demonstrate nuanced understanding by probing their mechanisms, challenges, and interrelations, enabling the survey to elicit informed, insightful responses from domain experts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 202:</span> <span class="node-desc">Synthesizes recent RAG advancements by not only listing technical developments but also articulating the interconnections and cumulative impact of innovations (e.g., how deep research, reasoning-intensive retrieval, and context engineering collectively advance the field), providing a holistic and integrative perspective rather than isolated topic summaries.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 286:</span> <span class="node-desc">Demonstrates a nuanced synthesis of recent research by not only listing RAG advancements but also contextualizing their significance, interrelations, and open challenges, thereby elevating the survey beyond a mere enumeration of topics.</span></div></li></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-9:</span> <span class="node-desc">Label: Research Trends and Contextualization  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 70:</span> <span class="node-desc">Synthesizes and contextualizes recent research trends, challenges, and future directions in RAG, providing not just a list of topics but a narrative that connects advancements, open questions, and their implications for the field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 10:</span> <span class="node-desc">Provides a comprehensive, well-structured introduction and contextual framing that orients the respondent to RAG and its latest research directions, setting clear expectations for the survey and demonstrating an understanding of the field’s evolution.</span></div></li></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-5:</span> <span class="node-desc">Label: Structured RAG Research Surveys  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 22:</span> <span class="node-desc">Synthesizes recent research trends and technical advancements in RAG (such as deep research, reasoning-intensive retrieval, and context engineering) into a logically structured, readable survey that contextualizes each area and highlights their interconnections, demonstrating both breadth and depth of understanding.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 116:</span> <span class="node-desc">Presents a logically structured, thematically focused survey that not only covers the latest RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering) but also contextualizes their significance, interrelations, and impact on the field, enabling respondents to understand both the state-of-the-art and its practical implications.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 85:</span> <span class="node-desc">Presents a logically organized, thematically coherent survey structure that systematically covers the requested RAG subtopics (e.g., Deep Research, reasoning-intensive retrieval, context engineering), ensuring each is addressed in a focused and relevant manner rather than as a superficial or disjointed list.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 99:</span> <span class="node-desc">Presents a logically organized, multi-section survey that not only lists current RAG topics but also contextualizes them with clear explanations, recent trends, challenges, and future directions, resulting in a resource that is both informative and comprehensive for the intended audience.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 229:</span> <span class="node-desc">Synthesizes recent research trends and technical advancements in RAG into a logically structured, comprehensive survey outline that contextualizes each topic, demonstrates awareness of the field’s evolution, and provides clear rationale for the inclusion of each section or question.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 294:</span> <span class="node-desc">Demonstrates a nuanced understanding of the RAG field by structuring the survey to reflect current research directions, emerging subtopics, and real-world applications, resulting in a comprehensive and up-to-date instrument that both informs and elicits meaningful insights.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 166:</span> <span class="node-desc">Synthesizes recent research trends and technical advancements (such as reasoning-intensive retrieval and context engineering) into a logically organized, narrative survey that contextualizes developments, compares approaches, and highlights their significance for the field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 148:</span> <span class="node-desc">Synthesizes recent research advances and challenges into a logically structured, readable survey format that mirrors the conventions of academic surveys (e.g., clear sections, progression from background to future directions, explicit referencing of recent work), enabling both lay and expert readers to grasp the field’s state and trajectory.</span></div></li></ul></details></li></ul></details></li><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-0:</span> <span class="node-desc">Label: Advanced Retrieval-Augmented Generation Sur...</span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-26:</span> <span class="node-desc">Label: Advanced RAG Survey Design  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 43:</span> <span class="node-desc">Designs survey questions that explicitly probe respondents' familiarity with, and opinions on, the most current and nuanced RAG advancements (such as deep research, reasoning-intensive retrieval, and context engineering), ensuring the survey captures both breadth and depth of recent progress rather than generic or outdated aspects.</span></div></li></ul></details></li></ul></details></li><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-6:</span> <span class="node-desc">Label: Comprehensive Mixed-Method Surveys  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-14:</span> <span class="node-desc">Label: Mixed-Method Survey Design</span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 34:</span> <span class="node-desc">Presents a complete, well-structured set of survey questions that directly elicit respondent perspectives, experiences, and preferences regarding RAG advancements, using a variety of question types (e.g., Likert scales, multiple choice, open-ended) to capture nuanced insights from diverse stakeholders.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 259:</span> <span class="node-desc">Structures the survey to elicit both quantitative (e.g., multiple choice, Likert scale) and qualitative (e.g., open-ended, scenario-based) responses, enabling richer, multi-dimensional insights into participant expertise, experiences, and perspectives.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 287:</span> <span class="node-desc">Designs survey questions that elicit both quantitative (e.g., rating scales, multiple choice) and qualitative (e.g., open-ended, free-text) responses, enabling nuanced data collection on both knowledge and opinions regarding RAG advancements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 180:</span> <span class="node-desc">Frames survey questions to elicit both quantitative (e.g., multiple choice, Likert scale) and qualitative (e.g., open-ended, explanatory) responses, enabling nuanced insights into user experience, technical challenges, and future directions in RAG.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 8:</span> <span class="node-desc">Demonstrates nuanced understanding of survey design by tailoring question types (e.g., Likert scales, open-ended, scenario-based) to elicit actionable insights on specific RAG advancements, rather than relying on generic or surface-level question formats.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 111:</span> <span class="node-desc">Incorporates both closed-ended (e.g., multiple choice, rating scales) and open-ended questions, enabling quantitative analysis while also eliciting nuanced, qualitative insights from respondents.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 249:</span> <span class="node-desc">Designs survey to capture both quantitative (e.g., Likert scales, ranking) and qualitative (e.g., open-ended, scenario-based) feedback, thereby enabling richer, multi-dimensional analysis of expert opinions and experiences with RAG progress.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 268:</span> <span class="node-desc">Structures the survey to elicit both quantitative (e.g., Likert scales, multiple choice) and qualitative (e.g., open-ended) responses, ensuring a comprehensive capture of participant perspectives and facilitating both statistical analysis and in-depth thematic exploration.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 214:</span> <span class="node-desc">Structures the survey to elicit both quantitative (e.g., multiple choice, Likert scale) and qualitative (e.g., open-ended) responses, allowing for a comprehensive assessment of user knowledge, attitudes, and expectations regarding RAG, and supporting both statistical analysis and rich, context-sensitive feedback.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 16:</span> <span class="node-desc">Structures the survey to elicit both quantitative (e.g., multiple choice, Likert scale) and qualitative (e.g., open-ended, scenario-based) responses, allowing for comprehensive data collection that captures both trends and nuanced perspectives.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 261:</span> <span class="node-desc">Structures the survey to balance both closed (quantitative) and open-ended (qualitative) questions, enabling collection of both measurable trends and rich, explanatory data about RAG progress.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 273:</span> <span class="node-desc">Designs survey items that elicit both quantitative (e.g., Likert scale) and qualitative (e.g., open-ended) responses, enabling rich, actionable data collection about RAG progress and challenges.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 141:</span> <span class="node-desc">Incorporates a mix of question formats (e.g., open-ended, multiple-choice, Likert scale) tailored to the complexity and nature of each topic, thereby eliciting both quantitative and qualitative insights and supporting richer, more actionable survey data.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 161:</span> <span class="node-desc">Frames survey questions to elicit both quantitative (e.g., multiple choice, Likert scale) and qualitative (e.g., open-ended, explanatory) responses, enabling nuanced insights into user expertise, experiences, and opinions on RAG advancements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 38:</span> <span class="node-desc">Structures the survey to elicit both quantitative (e.g., multiple-choice, Likert scale) and qualitative (e.g., open-ended) responses, enabling nuanced insights into user experience, expertise, and perspectives on RAG advancements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 80:</span> <span class="node-desc">Adapts the survey format and question types (e.g., multiple choice, open-ended, rating scales) to the complexity and nuance of the RAG subtopics, ensuring that each aspect (such as context engineering or reasoning-intensive retrieval) is explored with an appropriate depth and granularity.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 295:</span> <span class="node-desc">Structures the survey to balance both closed (quantitative) and open-ended (qualitative) questions, ensuring it gathers actionable data while also allowing for in-depth, context-rich responses. Superior surveys use this mix to facilitate both statistical analysis and the surfacing of novel insights from respondents.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 114:</span> <span class="node-desc">Designs survey structure to facilitate both quantitative benchmarking (e.g., Likert scales, ranking) and qualitative insight (e.g., open-ended prompts), enabling a multidimensional understanding of RAG progress and community perspectives.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 158:</span> <span class="node-desc">Frames survey questions to elicit both quantitative (e.g., multiple choice, frequency scales) and qualitative (e.g., open-ended, scenario-based) responses, enabling nuanced data collection that captures both breadth and depth of stakeholder perspectives on RAG advancements.</span></div></li></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-10:</span> <span class="node-desc">Label: Integrated Factual and Reflective Inquiry</span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 200:</span> <span class="node-desc">Frames survey questions to elicit not only factual knowledge but also critical analysis, personal experience, and forward-looking perspectives (e.g., challenges, future directions, application scenarios), thereby enabling richer, more actionable insights from respondents.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 31:</span> <span class="node-desc">Frames survey questions to elicit both factual knowledge and critical perspectives (e.g., asking about limitations, future directions, or comparative effectiveness), thereby enabling richer, more actionable insights from respondents beyond surface-level understanding.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 103:</span> <span class="node-desc">Structures the survey to elicit both factual knowledge and informed opinions from respondents, balancing objective questions (e.g., definitions, components) with open-ended prompts about future directions, challenges, or personal perspectives on RAG advancements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 226:</span> <span class="node-desc">Frames survey questions to elicit not only factual knowledge but also critical analysis, personal experience, or forward-looking perspectives (e.g., asking for opinions on future trends, challenges, or applications), thereby encouraging deeper engagement and richer, more insightful responses from participants.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 136:</span> <span class="node-desc">Structures the survey to elicit both factual knowledge and reflective, experience-based insights (e.g., combining technical understanding, practical challenges, and personal strategies), enabling multidimensional analysis of respondent expertise and perspectives.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 131:</span> <span class="node-desc">Balances technical inquiry with questions about real-world impact, challenges, and future directions, ensuring the survey elicits both expert technical insights and broader perspectives on RAG’s significance and trajectory.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 216:</span> <span class="node-desc">Incorporates survey questions that probe for both technical understanding and practical experience, such as asking respondents to compare, critique, or forecast the impact of specific RAG advancements, thereby enabling the collection of both objective and subjective insights.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 206:</span> <span class="node-desc">Designs survey questions that probe not only for factual knowledge but also for nuanced opinions, experiences, or predictions regarding RAG advancements, thereby eliciting richer, more actionable insights from respondents.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 243:</span> <span class="node-desc">Frames survey questions to elicit both breadth and depth of respondent knowledge, enabling nuanced insights into familiarity, practical experience, and opinions on recent RAG advancements, rather than limiting to superficial or binary responses.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 2:</span> <span class="node-desc">Frames survey questions to elicit not only factual knowledge but also respondents' critical perspectives, experiences, and nuanced opinions on the impact, limitations, and future directions of RAG advancements, thereby enabling richer, more actionable insights.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 11:</span> <span class="node-desc">Frames survey questions to elicit not only factual knowledge but also critical analysis, personal experience, and forward-looking perspectives (e.g., asking for opinions on future directions, challenges, or innovative applications), thereby enabling richer, more actionable insights from respondents.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 187:</span> <span class="node-desc">Frames survey questions to elicit both evaluative and experiential responses from a range of stakeholders (e.g., researchers, practitioners, end-users), ensuring the instrument captures diverse perspectives and practical insights rather than focusing solely on factual recall or definitions.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 33:</span> <span class="node-desc">Designs survey questions that probe not only factual knowledge but also perceptions, applications, and critical evaluation of RAG, enabling nuanced insights into both technical understanding and broader implications.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 224:</span> <span class="node-desc">Frames survey questions to not only assess factual knowledge but also to elicit respondents’ critical perspectives on the implications, limitations, and future directions of RAG advancements, thereby enabling richer, more actionable insights from both experts and novices.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 275:</span> <span class="node-desc">Frames survey questions to elicit not only factual knowledge but also critical evaluation, personal experience, or forward-looking perspectives (e.g., asking respondents to assess challenges, propose improvements, or predict future trends), thereby enabling richer, more actionable insights from expert participants.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 154:</span> <span class="node-desc">Frames survey questions to elicit both subjective opinions (e.g., perceived benefits, satisfaction, or future directions) and objective knowledge (e.g., familiarity, awareness of subfields), thereby capturing a multidimensional understanding of respondents' perspectives and expertise.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 219:</span> <span class="node-desc">Designs survey questions that explicitly elicit both subjective experiences and objective knowledge, enabling nuanced insights into both user perceptions and technical understanding of RAG advancements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 272:</span> <span class="node-desc">Structures the survey to elicit both factual knowledge and expert opinion, balancing objective questions (e.g., about techniques or metrics) with open-ended prompts that invite critical reflection on future directions, challenges, or ethical considerations in RAG.</span></div></li></ul></details></li></ul></details></li></ul></details></li><li class="level-3"><details class="tree-item" open><summary><div class="node"><span class="node-label">L3-1:</span> <span class="node-desc">Label: Survey Design and Structuring  </span></div></summary><ul><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-2:</span> <span class="node-desc">Label: Progressive Survey Structuring  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-3:</span> <span class="node-desc">Label: Progressive and Adaptive Survey Design  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 91:</span> <span class="node-desc">Structures the survey to logically progress from foundational definitions through current challenges to future directions, ensuring each section builds upon the previous and collectively forms a coherent, comprehensive exploration of the RAG field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 97:</span> <span class="node-desc">Structures the survey with clear, logically ordered sections and subsections that reflect the progression of the field, enabling readers to easily follow the development from foundational concepts to advanced topics and open challenges.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 217:</span> <span class="node-desc">Organizes the survey with a logical progression that builds conceptual understanding—starting from foundational definitions, moving through technical components, and culminating in advanced topics and future directions—thereby scaffolding respondent engagement and maximizing the informativeness of responses.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 196:</span> <span class="node-desc">Designs survey structure to progressively build respondent understanding, starting from foundational concepts and leading into advanced or emerging topics, thereby scaffolding expertise and enabling more informed, granular responses.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 298:</span> <span class="node-desc">Structures the survey to progressively build respondent engagement and depth, starting from foundational familiarity and moving toward advanced, open-ended, or speculative questions, thereby maximizing both accessibility and insightfulness.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 125:</span> <span class="node-desc">Adapts survey structure and question types (e.g., conditional branching, open-ended prompts, domain-specific options) to accommodate diverse respondent backgrounds and levels of RAG familiarity, thereby maximizing relevance and data quality.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 88:</span> <span class="node-desc">Frames survey questions or sections to explicitly distinguish between general familiarity, hands-on experience, and deep research involvement, allowing nuanced segmentation of respondent expertise and perspectives.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 68:</span> <span class="node-desc">Structures the survey to systematically cover the breadth of the field (e.g., deep research, reasoning, context engineering) while also enabling depth by including targeted sub-questions or prompts that elicit detailed, expert-level insights from respondents.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 192:</span> <span class="node-desc">Structures the survey to systematically progress from respondent background, through baseline understanding, to targeted questions on recent RAG developments, ensuring logical flow and maximizing respondent engagement and data quality.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 62:</span> <span class="node-desc">Structures the survey to progressively build respondent engagement and depth—beginning with context-setting or demographic items, then moving to increasingly sophisticated, targeted questions about RAG progress, challenges, and future directions. This scaffolding supports both novice and expert respondents, maximizing data quality and completion rates.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 247:</span> <span class="node-desc">Structures the survey with clear, logically sequenced questions and supporting context, ensuring that respondents can easily follow the survey flow and understand the rationale behind each question.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 46:</span> <span class="node-desc">Organizes survey questions to progressively deepen engagement, starting from general familiarity and interest, then moving to specific technical subtopics and finally to open-ended future-oriented or feedback questions, thereby scaffolding respondent reflection and maximizing actionable insight.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 258:</span> <span class="node-desc">Organizes the survey with a clear, logical structure (e.g., introduction, topical sections, conclusion) that guides the reader through the evolution, challenges, and future directions of RAG, enabling both novices and experts to follow the field’s progression and context.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 171:</span> <span class="node-desc">Organizes survey questions into a coherent, thematically grouped structure that guides respondents logically from foundational concepts through advanced topics, ensuring a smooth and engaging progression.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 32:</span> <span class="node-desc">Provides clear, context-rich explanations for advanced or emerging concepts (such as reasoning-intensive retrieval or context engineering), including definitions, motivations, and illustrative scenarios, making the survey accessible and informative for readers with varying levels of prior knowledge.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 100:</span> <span class="node-desc">Frames survey content at an appropriate level of technical depth and accessibility for the intended audience, avoiding both oversimplification and excessive jargon, thereby enabling both newcomers and experts to engage meaningfully with the material.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 182:</span> <span class="node-desc">Incorporates a respondent profiling section (e.g., background, expertise, familiarity with RAG) that enables segmentation of survey results, ensuring that responses can be meaningfully interpreted in light of the participant's knowledge level and context.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 142:</span> <span class="node-desc">Implements interactive or adaptive survey logic (e.g., branching questions, dynamic follow-ups) that tailors the survey experience to respondent expertise or interests, thereby increasing relevance and depth of collected insights.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 13:</span> <span class="node-desc">Organizes the survey into logically progressive sections that mirror the research landscape (e.g., from foundational concepts to advanced topics and future directions), enabling respondents to build understanding and provide nuanced feedback across the breadth and depth of RAG advancements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 233:</span> <span class="node-desc">Structures the survey with clear, logically ordered sections that guide the reader through background, current challenges, recent advances, and future directions, demonstrating an understanding of both the field and effective survey design.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 284:</span> <span class="node-desc">Structures the survey to progressively deepen respondent engagement, beginning with accessible, general questions and advancing to more complex, reflective, or open-ended items that elicit expert insight, thus accommodating a range of expertise and maximizing the survey’s diagnostic value.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 237:</span> <span class="node-desc">Frames the survey with a clear, multi-stage structure that guides respondents from foundational knowledge through perceptions, experiences, and future expectations, ensuring comprehensive coverage and logical progression.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 240:</span> <span class="node-desc">Structures the survey to progressively build respondent engagement, starting from general familiarity and moving toward specific technical or application-focused questions, which enhances both accessibility for novices and depth for experts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 271:</span> <span class="node-desc">Presents a logically organized, sectioned survey structure that not only covers all requested RAG subtopics (deep research, reasoning-intensive retrieval, context engineering, etc.) but also contextualizes each with clear introductions, definitions, and rationale for inclusion, enabling both expert and non-expert respondents to engage meaningfully.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 94:</span> <span class="node-desc">Organizes the survey with clear thematic sections and logical progression, ensuring that each question builds upon previous ones and that the overall structure guides respondents through increasingly sophisticated aspects of RAG, from fundamentals to advanced topics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 164:</span> <span class="node-desc">Structures survey content to progressively build understanding, starting from foundational RAG concepts and advancing to nuanced or emerging topics, thereby supporting respondents with varying expertise levels.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 193:</span> <span class="node-desc">Designs survey structure and question flow to progressively deepen respondent engagement, starting from general familiarity and moving toward expert-level perspectives, thereby accommodating a range of expertise and maximizing the survey's utility for both broad and specialized analysis.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 118:</span> <span class="node-desc">Organizes survey sections and questions in a logical progression that mirrors the conceptual development of RAG (e.g., from foundational understanding to advanced challenges and future directions), thereby facilitating respondent engagement and comprehensive coverage.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 126:</span> <span class="node-desc">Provides a comprehensive, logically organized survey structure that covers foundational concepts, recent advancements, applications, challenges, and future directions, ensuring each section builds upon the previous and collectively forms a cohesive, standalone research instrument.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 197:</span> <span class="node-desc">Structures the survey with a logical flow, including a concise introduction, thematically grouped questions, and a clear progression from general to specific topics, enhancing respondent engagement and data quality.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 239:</span> <span class="node-desc">Organizes the survey with a logical progression that contextualizes advanced RAG topics, smoothly guiding respondents from background and foundational concepts to recent innovations and future directions, thereby enhancing respondent engagement and data quality.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 209:</span> <span class="node-desc">Frames survey questions that are tailored to the respondent's level of expertise or experience with RAG, allowing both novices and experts to provide meaningful input and ensuring the survey captures a broad spectrum of perspectives.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 162:</span> <span class="node-desc">Structures the survey with clear sections, logical progression, and introductory context, ensuring that even complex or technical topics are accessible and that respondents understand the purpose and scope of each part. This organizational clarity enhances respondent engagement and data quality.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 283:</span> <span class="node-desc">Designs survey structure to scaffold respondent understanding, beginning with foundational concepts and progressively introducing advanced or emerging topics, thereby supporting both expert and non-expert engagement without sacrificing technical depth.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 185:</span> <span class="node-desc">Organizes the survey with a logical progression that contextualizes RAG, builds on foundational concepts, and systematically explores each major research direction, resulting in a coherent and engaging instrument that facilitates comprehensive insight gathering.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 181:</span> <span class="node-desc">Adapts question phrasing and answer options to accommodate a range of respondent expertise, ensuring accessibility for beginners while still engaging experts with open-ended or advanced prompts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 117:</span> <span class="node-desc">Structures the survey to progressively build reader understanding, starting from foundational concepts and leading to advanced topics, with clear transitions and logical flow that facilitate engagement for both novices and experts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 254:</span> <span class="node-desc">Structures the survey with clear, logically ordered sections that guide respondents from foundational understanding to advanced topics, ensuring smooth progression and minimizing cognitive load.</span></div></li></ul></details></li></ul></details></li><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-16:</span> <span class="node-desc">Label: Undefined Cluster  </span></div></summary><ul></ul></details></li><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-12:</span> <span class="node-desc">Label: Survey Structure and Design  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-21:</span> <span class="node-desc">Label: Undefined Cluster  </span></div></summary><ul></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-12:</span> <span class="node-desc">Label: Structured Survey Design for RAG  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 55:</span> <span class="node-desc">Organizes survey content to systematically cover the breadth of RAG advancements (e.g., Deep Research, reasoning-intensive retrieval, context engineering) while ensuring each area is addressed with distinct, non-overlapping questions, reflecting comprehensive topical coverage.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 290:</span> <span class="node-desc">Structures the survey to systematically cover the landscape of RAG progress, including background, applications, technical challenges, evaluation metrics, and future directions, ensuring comprehensive and logically organized respondent engagement.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 262:</span> <span class="node-desc">Structures the survey with clear sections, logical progression, and a mix of question types (e.g., multiple choice, Likert scales, open-ended), facilitating comprehensive and organized data collection while enhancing respondent engagement.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 172:</span> <span class="node-desc">Balances breadth and depth by covering all major requested subtopics (e.g., Deep Research, reasoning-intensive retrieval, context engineering) with specific, actionable questions, ensuring comprehensive yet focused data collection.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 41:</span> <span class="node-desc">Presents a logically organized, sectioned survey structure that mirrors the conventions of academic or technical surveys (e.g., clear introduction, thematic sections, conclusion), enabling readers to easily follow the progression of RAG advancements and related subtopics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 123:</span> <span class="node-desc">Organizes the survey into logically coherent sections that reflect the major subtopics of the field (e.g., Deep Research, Reasoning-Intensive Retrieval, Context Engineering), with each section containing focused, relevant, and respondent-facing questions. This structure demonstrates a nuanced understanding of the domain and facilitates comprehensive, targeted feedback from respondents.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 110:</span> <span class="node-desc">Presents a logically organized, multi-section survey structure that mirrors the progression of a professional research instrument (e.g., introduction, thematic sections, targeted questions, and closing), enabling comprehensive and systematic exploration of RAG advancements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 137:</span> <span class="node-desc">Structures the survey with clear sections and logical progression (e.g., background, current state, challenges, future directions), enhancing respondent engagement and ensuring comprehensive coverage of the topic without redundancy or omission.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 143:</span> <span class="node-desc">Organizes the survey with clear, logical sectioning (e.g., background, technical advances, challenges, applications) that mirrors the structure of contemporary research surveys, facilitating both respondent comprehension and actionable data collection.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 212:</span> <span class="node-desc">Organizes the survey with clear, labeled sections or thematic groupings (e.g., 'Deep Research', 'Reasoning-Intensive Retrieval', 'Context Engineering'), enabling respondents to navigate complex subtopics efficiently and ensuring comprehensive topical coverage.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 183:</span> <span class="node-desc">Designs survey structure to systematically cover multiple dimensions of RAG progress (e.g., technical methods, applications, challenges, future directions), ensuring comprehensive and logically organized coverage that facilitates meaningful analysis of respondent perspectives.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 282:</span> <span class="node-desc">Organizes the survey with clear thematic sections (e.g., introduction, technical progress, applications, challenges), each containing logically grouped and progressively structured questions, thereby facilitating a coherent and comprehensive exploration of the RAG field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 90:</span> <span class="node-desc">Synthesizes recent research trends and technical advances into a logically structured, domain-appropriate survey format, with clear topical sections and concise, relevant explanations that would be accessible and useful to a practitioner or researcher in the field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 174:</span> <span class="node-desc">Explicitly structures the survey to segment respondents by expertise, use case, or industry, allowing for targeted analysis and more actionable insights into RAG's impact and adoption across different communities.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 37:</span> <span class="node-desc">Demonstrates clear, logical organization by grouping questions into thematic sections (e.g., deep research, reasoning-intensive retrieval, context engineering), making the survey easy to navigate and ensuring comprehensive coverage of the topic.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 54:</span> <span class="node-desc">Organizes the survey into logically distinct, thematically coherent sections (e.g., introduction, technical advancements, challenges, applications, and ethical considerations), each with focused, relevant questions or prompts that collectively provide a comprehensive and navigable structure for respondents and demonstrate a holistic grasp of the RAG field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 213:</span> <span class="node-desc">Structures the survey with clear thematic sections (such as background, challenges, future directions), providing logical flow and making it easy for respondents to navigate and engage with complex RAG topics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 207:</span> <span class="node-desc">Synthesizes recent RAG advancements into thematically organized survey sections (e.g., Deep Research, Reasoning-Intensive Retrieval, Context Engineering), each with context-setting explanations and targeted questions, demonstrating nuanced understanding of the field’s evolution.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 223:</span> <span class="node-desc">Organizes the survey with original, thoughtfully named sections or topics (e.g., 'Deep Research', 'Reasoning-Intensive Retrieval', 'Context Engineering') that reflect nuanced understanding and creative framing of current RAG research trends.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 3:</span> <span class="node-desc">Designs survey structure to logically progress from foundational concepts to advanced topics, ensuring that each section builds upon the previous, thereby guiding respondents through a coherent exploration of RAG developments rather than presenting a disjointed or unordered set of questions.</span></div></li></ul></details></li></ul></details></li><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-14:</span> <span class="node-desc">Label: RAG Survey Methodology  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-23:</span> <span class="node-desc">Label: Survey Design for RAG Insights  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 28:</span> <span class="node-desc">Designs a survey that not only covers the breadth of RAG advancements but also structures questions to elicit both foundational knowledge and nuanced, experience-based insights from respondents, enabling differentiation between novice and expert perspectives.</span></div></li></ul></details></li></ul></details></li><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-7:</span> <span class="node-desc">Label: Audience-Centered Survey Design  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-13:</span> <span class="node-desc">Label: Tailored, Contextualized Survey Design  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 155:</span> <span class="node-desc">Designs survey questions that are clearly targeted to the intended respondent group (e.g., researchers, practitioners, or general audience), with language, depth, and context tailored to their expertise, thereby maximizing the relevance and actionability of collected responses.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 105:</span> <span class="node-desc">Explicitly contextualizes each survey section or question with a brief, targeted introduction, clarifying the relevance of the topic (e.g., deep research, reasoning-intensive retrieval) and priming respondents for more informed and focused answers.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 56:</span> <span class="node-desc">Transforms complex, cutting-edge technical concepts (such as reasoning-intensive retrieval or context engineering) into clear, targeted survey questions that are accessible to the intended audience, demonstrating both subject mastery and survey design skill.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 176:</span> <span class="node-desc">Presents the survey in a format that is both accessible and professionally structured (e.g., clear sections, logical flow, appropriate use of formatting or interactive elements), enhancing respondent engagement and data quality beyond basic question listing.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 244:</span> <span class="node-desc">Integrates recent research trends and technical concepts (such as deep research, reasoning-intensive retrieval, and context engineering) with clear, accessible explanations and relevant examples, making advanced topics understandable to a broad audience.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 14:</span> <span class="node-desc">Integrates both structured survey questions and informative context (e.g., definitions, explanations, or background) that directly support respondent understanding of RAG advancements, resulting in a self-contained and educational survey instrument.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 245:</span> <span class="node-desc">Explicitly tailors survey content and instructions to the intended audience (e.g., researchers, practitioners, or general participants), clarifying expectations and maximizing the relevance and interpretability of responses.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 160:</span> <span class="node-desc">Synthesizes recent research trends and technical developments into accessible, respondent-facing questions that both inform and elicit expert opinion, rather than merely listing topics or papers.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 39:</span> <span class="node-desc">Explicitly contextualizes each survey section or question with brief, targeted explanations or definitions (e.g., what 'reasoning-intensive retrieval' or 'context engineering' means), ensuring accessibility for respondents with varying levels of prior knowledge.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 194:</span> <span class="node-desc">Structures the survey using clear, logical organization (e.g., with headings, subheadings, and bullet points) that enhances readability and respondent comprehension, while maintaining a professional and focused tone throughout.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 220:</span> <span class="node-desc">Synthesizes recent research trends and technical advancements in RAG into clear, accessible survey questions that probe both conceptual understanding and practical implications, demonstrating nuanced awareness of the field's evolution.</span></div></li></ul></details></li></ul></details></li><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-1:</span> <span class="node-desc">Label: Survey Quality and Impact Enhancement  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-1:</span> <span class="node-desc">Label: Enhancing Survey Rigor and Impact  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 138:</span> <span class="node-desc">Explicitly addresses both technical challenges and ethical considerations (e.g., bias, misinformation, evaluation pitfalls) within the survey, demonstrating awareness of the broader impact and limitations of RAG technologies.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 121:</span> <span class="node-desc">Goes beyond a basic survey outline by incorporating actionable, constructive feedback and suggestions for improvement, such as recommending the inclusion of examples, clarifying technical terms, or proposing enhancements to survey structure, thereby elevating the utility and clarity of the survey instrument.</span></div></li></ul></details></li></ul></details></li></ul></details></li><li class="level-3"><details class="tree-item" open><summary><div class="node"><span class="node-label">L3-2:</span> <span class="node-desc">Label: Current Research Integration  </span></div></summary><ul><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-3:</span> <span class="node-desc">Label: Integration of Current Research  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-4:</span> <span class="node-desc">Label: Integration of Current RAG Research  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 210:</span> <span class="node-desc">Integrates recent, field-specific research advances (e.g., named models, techniques, or studies) with accurate attributions and clear explanations, demonstrating up-to-date domain knowledge and contextualizing progress within the RAG landscape.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 248:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by explicitly connecting survey questions or content to cutting-edge topics (e.g., reasoning-intensive retrieval, context engineering, Deep Research), rather than merely mentioning them or providing generic overviews.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 92:</span> <span class="node-desc">Synthesizes recent research trends and technical advancements in RAG (such as deep research, reasoning-intensive retrieval, and context engineering) into survey questions that both inform and probe respondent knowledge, demonstrating up-to-date field awareness and fostering engagement with cutting-edge topics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 264:</span> <span class="node-desc">Integrates recent, field-specific terminology and concrete examples (e.g., 'multi-modal data', 'retriever-retriever objective', 'zero-shot retrieval under uncertainty') into survey questions, demonstrating up-to-date domain awareness and enabling respondents to engage with current research directions.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 132:</span> <span class="node-desc">Demonstrates awareness of recent RAG advancements by explicitly referencing or integrating cutting-edge topics (such as reasoning-intensive retrieval, context engineering, or deep research) into the survey items, ensuring topical relevance and depth.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 5:</span> <span class="node-desc">Demonstrates up-to-date awareness of the RAG research landscape by referencing and probing for respondent familiarity with genuinely current, field-recognized advancements (e.g., deep retrieval, context engineering, reasoning-intensive retrieval), avoiding outdated or generic framing.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 4:</span> <span class="node-desc">Integrates recent, field-specific advancements (such as Deep Research, reasoning-intensive retrieval, and context engineering) into the survey not just as topics, but as distinct, targeted questions or sections that probe respondents’ awareness, experience, or opinions on these innovations, thereby enabling nuanced data collection on the state-of-the-art.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 119:</span> <span class="node-desc">Integrates recent, specific advancements and subtopics (e.g., retrieval-generation interaction, probabilistic retrieval, dynamic context modeling) into survey content, reflecting up-to-date knowledge and distinguishing the survey from generic or outdated questionnaires.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 215:</span> <span class="node-desc">Incorporates concrete, up-to-date examples or references to recent research, benchmarks, or real-world applications, grounding the survey in the current state of the field and enabling respondents to connect questions to actual progress.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 96:</span> <span class="node-desc">Frames survey questions that not only cover general awareness and usage but also probe for nuanced opinions on specific subfields (e.g., deep research, reasoning-intensive retrieval, context engineering), enabling the survey to capture both breadth and depth of respondent expertise and interest.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 133:</span> <span class="node-desc">Demonstrates deep familiarity with the latest research by referencing specific, up-to-date papers, methods, or named systems (e.g., 'DeepResearch', 'Reasoning-intensive retriever by Clark et al. (2021)', 'Context Engineering 101 by Keller et al. (2021)'), and integrates these references meaningfully into the survey context or questions, rather than mentioning them superficially.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 211:</span> <span class="node-desc">Demonstrates awareness of the latest RAG subfields and progress by explicitly referencing and integrating contemporary topics (such as deep research, reasoning-intensive retrieval, and context engineering) into the survey structure, ensuring the instrument is up-to-date and relevant to current expert discourse.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 225:</span> <span class="node-desc">Demonstrates up-to-date awareness by referencing and integrating the most recent, field-specific advancements (e.g., deep research, reasoning-intensive retrieval, context engineering) in both the structure and content of the survey, ensuring that questions probe the latest trends and not just foundational concepts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 79:</span> <span class="node-desc">Integrates nuanced, up-to-date technical distinctions within RAG advancements (e.g., differentiating between types of context engineering, specifying recent datasets, or highlighting novel evaluation metrics), demonstrating a sophisticated grasp of the field’s current landscape beyond surface-level trends.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 257:</span> <span class="node-desc">Demonstrates deep familiarity with current RAG research by referencing and structuring around recent, field-specific advancements (e.g., reasoning-intensive retrieval, context engineering, hybrid approaches), rather than generic or outdated concepts, and organizes the survey to elicit nuanced insights on these topics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 267:</span> <span class="node-desc">Integrates recent, field-relevant technical concepts and terminology (such as context engineering, reasoning-intensive retrieval, and deep research) accurately and appropriately into survey questions, reflecting up-to-date knowledge and ensuring the survey remains relevant to current RAG research and practice.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 65:</span> <span class="node-desc">Demonstrates precise alignment between survey questions and the latest research trends in RAG (e.g., deep research, reasoning-intensive retrieval, context engineering), ensuring that each question directly references or builds upon current field developments rather than remaining generic.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 253:</span> <span class="node-desc">Integrates bibliometric analysis tasks directly into the survey, prompting respondents to extract, classify, and analyze real research metadata (e.g., author names, journal titles, research areas) from a provided dataset, thereby elevating the survey from generic questioning to active engagement with current literature.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 130:</span> <span class="node-desc">Integrates recent, field-specific advancements (such as deep research, reasoning-intensive retrieval, or context engineering) into survey questions or structure, demonstrating up-to-date awareness and tailoring the survey to current RAG research trends.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 170:</span> <span class="node-desc">Synthesizes recent research trends and subtopics (e.g., deep research, reasoning-intensive retrieval, context engineering) into distinct, well-motivated survey sections, each contextualized with current challenges and open questions, enabling respondents to engage with nuanced aspects of the field rather than generic or superficial prompts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 113:</span> <span class="node-desc">Synthesizes recent research trends and technical advancements into survey content, ensuring that questions or structure reflect up-to-date, nuanced understanding of the field (e.g., referencing specific innovations, challenges, or subdomains such as context engineering or reasoning-intensive retrieval).</span></div></li></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-20:</span> <span class="node-desc">Label: Current Research Integration  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 120:</span> <span class="node-desc">Integrates up-to-date references to specific workshops, conferences, or highly cited papers, demonstrating awareness of the current research landscape and providing actionable resources for further exploration.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 26:</span> <span class="node-desc">Integrates up-to-date, field-specific references or links to recent research papers, benchmarks, or resources, demonstrating awareness of the latest developments and providing respondents with avenues for further exploration.</span></div></li></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-8:</span> <span class="node-desc">Label: Up-to-Date RAG Research Integration  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 149:</span> <span class="node-desc">Synthesizes and integrates recent, verifiable research developments and named contributions in RAG (e.g., specific models, institutions, or researchers), providing concrete examples that demonstrate up-to-date field awareness and depth beyond generic topic listing.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 265:</span> <span class="node-desc">Explicitly contextualizes survey questions within the latest RAG advancements by referencing or integrating contemporary subfields, research directions, or real-world applications, thereby ensuring the survey remains current and relevant to ongoing developments.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 67:</span> <span class="node-desc">Selects and references up-to-date, authoritative sources (such as recent arXiv papers or leading research groups) to ground survey questions and context, thereby enhancing the survey’s credibility and relevance to current developments in RAG.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 195:</span> <span class="node-desc">Demonstrates awareness of current research discourse by referencing or inviting discussion of specific, up-to-date models, techniques, or debates (without fabricating details), thus situating the survey within the real, evolving landscape of RAG research.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 134:</span> <span class="node-desc">Demonstrates awareness of the evolving landscape by explicitly referencing or integrating very recent research directions, tools, or open problems (e.g., mentioning context engineering, multi-step reasoning, or new evaluation paradigms), showing up-to-date field knowledge beyond standard RAG concepts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 178:</span> <span class="node-desc">Demonstrates deep familiarity with the RAG research landscape by referencing specific, up-to-date papers, established terminology, and recognized subfields, thereby grounding the survey in the current state of the art and enhancing its credibility.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 227:</span> <span class="node-desc">Synthesizes recent, field-relevant advancements (such as reasoning-intensive retrieval and context engineering) into a cohesive, up-to-date overview, demonstrating awareness of current research trends and their practical implications for RAG.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 222:</span> <span class="node-desc">Synthesizes and contextualizes recent research advances by referencing specific papers, methods, or trends, demonstrating up-to-date field awareness and providing respondents with a clear sense of the state-of-the-art.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 159:</span> <span class="node-desc">Demonstrates domain expertise by referencing or synthesizing recent, field-specific research papers, frameworks, or concrete technical advances (e.g., named models, published methods), rather than only general concepts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 49:</span> <span class="node-desc">Integrates up-to-date, field-specific terminology and references to recent research trends (e.g., 'Choose-Set-Check', knowledge graphs, context-aware representation learning) that demonstrate awareness of the latest advancements and signal deep engagement with the evolving RAG landscape.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 40:</span> <span class="node-desc">Demonstrates awareness of the evolving RAG landscape by explicitly referencing and integrating the most current research directions and terminology (such as context engineering, expert systems fusion, or large-scale portfolio generation) into survey items, ensuring the instrument remains relevant and forward-looking.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 9:</span> <span class="node-desc">Demonstrates up-to-date awareness by explicitly referencing or integrating the latest research directions, terminology, and subtopics (e.g., reasoning-intensive retrieval, context engineering, hybrid knowledge sources), ensuring the survey reflects the current state of the field.</span></div></li></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-19:</span> <span class="node-desc">Label: Integration of Current Evidence  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 59:</span> <span class="node-desc">Integrates concrete, up-to-date references to specific research papers, named researchers, or recent technical breakthroughs in RAG, demonstrating awareness of the field’s evolving landscape and grounding the survey in verifiable progress.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 199:</span> <span class="node-desc">Incorporates concrete, up-to-date examples or references (e.g., named datasets, benchmarks, or real-world applications) that substantiate claims about progress and situate the survey in the current research landscape, moving beyond generic or hypothetical discussion.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 86:</span> <span class="node-desc">Integrates concrete, up-to-date examples of recent research papers, benchmarks, or real-world systems to illustrate each major topic (e.g., citing specific RAG architectures, datasets, or case studies), thereby grounding the survey in the current state of the field and enhancing its credibility and utility.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 21:</span> <span class="node-desc">Integrates recent, specific research developments and concrete examples (e.g., named studies, novel architectures, or benchmark results) directly into survey questions or context, demonstrating up-to-date field awareness and enabling respondents to engage with the latest advancements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 203:</span> <span class="node-desc">Integrates concrete, up-to-date examples or references to real-world applications, benchmarks, or evaluation methods (such as GPTBench, Minilm, or specific case studies), grounding the discussion in current practice and enhancing the survey’s credibility and utility.</span></div></li></ul></details></li></ul></details></li></ul></details></li><li class="level-3"><details class="tree-item" open><summary><div class="node"><span class="node-label">L3-3:</span> <span class="node-desc">Label: Nuanced Differentiation of RAG Subfields  </span></div></summary><ul><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-8:</span> <span class="node-desc">Label: Differentiated RAG Subfield Insights  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-15:</span> <span class="node-desc">Label: Nuanced Differentiation of RAG Subfields  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 25:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating survey questions that probe the unique challenges, mechanisms, and implications of each subfield (e.g., deep research, reasoning-intensive retrieval, context engineering), rather than treating them as interchangeable or listing them superficially.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 51:</span> <span class="node-desc">Frames survey questions that not only reference recent RAG advancements but also probe respondents' understanding of the distinct mechanisms, challenges, and practical implications of each (e.g., asking how reasoning-intensive retrieval changes evaluation metrics or what context engineering means for deployment), thereby eliciting nuanced, expert-level insights rather than surface-level agreement or awareness.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 75:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating survey questions that probe the distinct mechanisms, challenges, and impacts of each subfield (e.g., deep research, reasoning-intensive retrieval, context engineering), rather than treating them as interchangeable or listing them superficially.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 64:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating questions that probe the distinct mechanisms, challenges, and implications of subfields like deep research, reasoning-intensive retrieval, and context engineering, rather than merely listing them or referencing them generically.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 184:</span> <span class="node-desc">Frames survey questions that not only reference recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering) but also demonstrate nuanced understanding by distinguishing their unique mechanisms, challenges, and implications, thereby eliciting informed and meaningful responses from knowledgeable participants.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 255:</span> <span class="node-desc">Demonstrates nuanced differentiation between major RAG subtopics (e.g., deep research, reasoning-intensive retrieval, context engineering) by formulating targeted questions or sections that probe each area’s unique challenges, methods, and implications, rather than treating them as interchangeable or superficially related.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 128:</span> <span class="node-desc">Demonstrates nuanced differentiation between closely related RAG advancements (e.g., deep research vs. reasoning-intensive retrieval), crafting questions that probe understanding of their unique mechanisms, challenges, and contributions rather than treating them as interchangeable buzzwords.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 291:</span> <span class="node-desc">Demonstrates nuanced understanding of RAG subfields by crafting survey questions that probe the distinct mechanisms, challenges, and recent innovations in areas such as deep research, reasoning-intensive retrieval, and context engineering, enabling the collection of expert-level insights rather than generic opinions.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 152:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG research by accurately distinguishing between subfields (e.g., deep research, reasoning-intensive retrieval, context engineering), and providing concrete, up-to-date examples or techniques unique to each, rather than generic or superficial descriptions.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 144:</span> <span class="node-desc">Demonstrates clear differentiation and accurate contextualization of advanced RAG topics (such as deep research, reasoning-intensive retrieval, and context engineering) by formulating questions that reflect their unique mechanisms, challenges, and relevance, rather than treating them as interchangeable or superficially listing them.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 58:</span> <span class="node-desc">Demonstrates nuanced understanding of RAG subfields by formulating questions or prompts that probe the specific mechanisms, recent innovations, and open challenges within each area (e.g., deep research, reasoning-intensive retrieval, context engineering), rather than treating them as generic or interchangeable topics.</span></div></li></ul></details></li></ul></details></li></ul></details></li><li class="level-3"><details class="tree-item" open><summary><div class="node"><span class="node-label">L3-4:</span> <span class="node-desc">Label: Advanced RAG Insight Elicitation  </span></div></summary><ul><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-9:</span> <span class="node-desc">Label: Deep Experience Survey Design  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-16:</span> <span class="node-desc">Label: Expert-Level Experience Insights  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 71:</span> <span class="node-desc">Frames survey questions to elicit nuanced, experience-based insights from respondents with assumed domain familiarity, avoiding generic or introductory prompts and instead probing for advanced perspectives, challenges, or unmet needs in RAG advancements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 83:</span> <span class="node-desc">Frames survey questions that probe not only the existence of recent RAG advancements but also their practical implications, trade-offs, and limitations, enabling nuanced insights from expert respondents and supporting actionable analysis.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 285:</span> <span class="node-desc">Designs survey questions that not only cover the requested RAG subtopics (Deep Research, reasoning-intensive retrieval, context engineering) but also elicit nuanced, experience-based insights (e.g., open-ended questions about challenges, future directions, or novel techniques), demonstrating a sophisticated understanding of both the field and effective survey methodology.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 122:</span> <span class="node-desc">Frames survey questions that probe not only for factual knowledge or opinions, but also for respondents’ practical experience with specific RAG advancements (e.g., context engineering, reasoning-intensive retrieval), enabling nuanced insights into real-world adoption, challenges, and impact.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 63:</span> <span class="node-desc">Frames survey questions to elicit nuanced, experience-based insights from respondents (e.g., asking for specific challenges, personal contributions, or resource recommendations), thereby enabling richer data collection and deeper understanding of the field’s landscape.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 232:</span> <span class="node-desc">Designs survey questions that not only assess factual knowledge or awareness but also probe respondents' nuanced experiences, challenges, and perspectives regarding recent RAG advancements, enabling richer, more actionable insights beyond surface-level familiarity.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 146:</span> <span class="node-desc">Frames survey questions to elicit nuanced, experience-based insights from respondents (e.g., asking about specific challenges, domain applications, or perceptions of recent advancements), rather than relying solely on generic or superficial queries. This approach enables richer, more actionable feedback and demonstrates a sophisticated understanding of both the field and effective survey design.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 112:</span> <span class="node-desc">Presents a logically structured, comprehensive survey instrument that systematically covers all major facets of the prompt (e.g., background, current research, applications, challenges, and future directions), ensuring each section is relevant and collectively provides a holistic view of the RAG field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 44:</span> <span class="node-desc">Frames survey questions to elicit nuanced, experience-based insights from respondents (e.g., asking for specific challenges faced, comparative evaluations, or concrete improvement suggestions), rather than relying solely on generic or factual queries. This approach enables the survey to capture actionable, field-informed perspectives that can meaningfully inform future research or product development.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 198:</span> <span class="node-desc">Frames survey questions to elicit not only factual knowledge or opinions but also respondents’ practical experiences, challenges, and nuanced perspectives on RAG advancements, enabling richer, actionable insights beyond surface-level familiarity.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 87:</span> <span class="node-desc">Designs survey questions that probe for nuanced, experience-based insights (e.g., challenges faced, specific use cases, or perceptions of recent advancements), rather than only factual recall or generic opinions, thereby enabling collection of actionable, field-relevant data.</span></div></li></ul></details></li></ul></details></li><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-15:</span> <span class="node-desc">Label: Deep Reflective Insight Elicitation  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-6:</span> <span class="node-desc">Label: Nuanced Expert Insight Elicitation</span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 168:</span> <span class="node-desc">Frames survey questions that not only reference RAG advancements but also probe for nuanced, respondent-driven insights—such as asking about specific challenges, trade-offs, or future research directions—thereby eliciting substantive, expert-level feedback rather than surface-level opinions.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 274:</span> <span class="node-desc">Frames survey questions to elicit nuanced, respondent-driven insights about recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), rather than merely listing topics or summarizing literature, thereby enabling collection of actionable, field-specific feedback.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 139:</span> <span class="node-desc">Frames survey questions that not only reference recent RAG advancements (such as deep research, reasoning-intensive retrieval, and context engineering) but also demonstrate nuanced understanding by probing their specific mechanisms, challenges, and practical implications, thereby eliciting informed and meaningful responses from domain experts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 127:</span> <span class="node-desc">Incorporates open-ended questions or sections that invite respondents to contribute novel perspectives, experiences, or critiques beyond predefined answer choices, thus enabling the survey to capture emergent trends and unanticipated insights in the rapidly evolving RAG field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 47:</span> <span class="node-desc">Frames survey questions to elicit nuanced, open-ended insights (e.g., asking for elaboration, examples, or critical evaluation) rather than relying solely on closed or superficial question formats, thereby enabling deeper understanding of respondent expertise and perspectives.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 101:</span> <span class="node-desc">Frames survey questions to elicit nuanced, respondent-driven insights about recent RAG advancements (such as deep research, reasoning-intensive retrieval, and context engineering), demonstrating an understanding of their distinct mechanisms and relevance, rather than merely listing them as buzzwords.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 289:</span> <span class="node-desc">Frames survey questions that not only reference recent RAG advancements but also probe respondents' understanding, experiences, or opinions about the specific mechanisms, challenges, or impacts of these advancements (e.g., asking how context engineering affects retrieval quality, or what challenges are faced in reasoning-intensive retrieval), thereby eliciting informative and actionable insights from knowledgeable participants.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 263:</span> <span class="node-desc">Provides concrete, technically detailed examples or mechanisms (such as specific model architectures, frameworks, or algorithmic strategies) that illustrate how RAG advancements are operationalized, moving beyond generalities to actionable or illustrative specifics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 145:</span> <span class="node-desc">Frames survey questions to elicit nuanced, respondent-driven insights about the distinct mechanisms, challenges, and future directions of RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), demonstrating a sophisticated grasp of their roles and interrelations rather than treating them as generic or interchangeable trends.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 241:</span> <span class="node-desc">Incorporates mechanisms for gathering expert or practitioner feedback (e.g., open-ended prompts for insights, requests for references to recent work), elevating the survey’s value for both research and community knowledge-building.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 252:</span> <span class="node-desc">Frames survey questions to elicit nuanced, actionable insights about respondents’ experiences, opinions, or expertise regarding RAG advancements, rather than relying solely on generic familiarity or agreement scales. This includes open-ended prompts, scenario-based items, or questions that probe for specific challenges, use cases, or future needs.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 165:</span> <span class="node-desc">Frames survey questions to elicit nuanced, respondent-driven insights about recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), demonstrating awareness of current research directions and open challenges rather than relying on generic or superficial prompts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 281:</span> <span class="node-desc">Demonstrates nuanced understanding by articulating open challenges, future directions, or unresolved questions in RAG, showing awareness of the field’s evolving landscape beyond current achievements.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 277:</span> <span class="node-desc">Integrates probing, open-ended questions that elicit nuanced perspectives on recent RAG advancements, encouraging respondents to reflect on challenges, future directions, and ethical considerations beyond surface-level familiarity.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 36:</span> <span class="node-desc">Frames survey questions to elicit nuanced, open-ended insights about recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), encouraging respondents to share specific experiences, challenges, and future outlooks rather than limiting them to predefined options. This approach surfaces richer, more actionable data and demonstrates deep understanding of the field's evolving landscape.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 256:</span> <span class="node-desc">Frames open-ended questions that elicit nuanced, expert-level insights into recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), rather than relying solely on generic or superficial prompts. This enables the survey to capture emerging trends and sophisticated perspectives from knowledgeable respondents.</span></div></li></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-25:</span> <span class="node-desc">Label: Reflective, Experience-Based Inquiry  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 147:</span> <span class="node-desc">Elicits open-ended, reflective responses that probe the respondent's direct experience, reasoning, or nuanced understanding of RAG advancements (e.g., asking for examples, explanations, or critical evaluations), thereby enabling richer expert insights beyond simple multiple-choice or factual recall.</span></div></li></ul></details></li></ul></details></li><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-5:</span> <span class="node-desc">Label: Expert-Level RAG Survey Design  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-2:</span> <span class="node-desc">Label: Nuanced, Actionable RAG Insights</span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 153:</span> <span class="node-desc">Frames open-ended survey questions that explicitly invite respondents to share critical perspectives, limitations, or challenges encountered with recent RAG advancements, enabling the collection of actionable insights rather than only positive or descriptive feedback.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 228:</span> <span class="node-desc">Frames survey questions to probe not only for factual knowledge or opinions, but also for respondents’ reasoning processes, decision criteria, or trade-off considerations regarding RAG advancements—e.g., asking for examples, justifications, or scenario-based responses that reveal depth of understanding.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 179:</span> <span class="node-desc">Frames survey questions to elicit nuanced, experience-based, or forward-looking insights from respondents (e.g., asking about challenges faced, anticipated future trends, or specific use cases), rather than limiting to factual recall or generic opinions, thereby enabling richer data collection and deeper field understanding.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 293:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating survey questions that probe not only for factual knowledge but also for critical evaluation, practical experience, and forward-looking perspectives (e.g., asking about challenges, future directions, and personal opinions on RAG's impact).</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 53:</span> <span class="node-desc">Frames survey questions to elicit nuanced, experience-based insights from respondents (e.g., asking for specific examples, challenges, or opinions on recent advancements), rather than relying solely on generic or factual queries. This approach enables richer, more actionable data collection and demonstrates a sophisticated understanding of both the field and survey methodology.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 74:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating survey questions that probe not only for awareness but also for critical perspectives, practical challenges, and future directions, thereby eliciting expert-level insights rather than surface-level responses.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 1:</span> <span class="node-desc">Provides nuanced analysis of the challenges, limitations, and open questions in RAG (such as dataset scarcity, computational constraints, or reasoning bottlenecks), rather than only listing advancements, thereby offering a critical perspective on the field’s trajectory.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 191:</span> <span class="node-desc">Frames survey questions to elicit nuanced, experience-based insights from respondents (e.g., asking about specific challenges, future directions, or comparative impact of advancements), rather than relying solely on generic or surface-level questions, thereby enabling richer data collection and deeper analysis.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 42:</span> <span class="node-desc">Frames survey questions to probe not only factual knowledge but also critical evaluation, future directions, and practical implications of RAG advancements, thereby eliciting deeper insights from respondents and demonstrating a sophisticated understanding of the field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 242:</span> <span class="node-desc">Frames survey questions to elicit not only factual knowledge or opinions but also critical reflection on open challenges, trade-offs, and future directions in RAG, thereby enabling richer, more actionable insights from respondents.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 35:</span> <span class="node-desc">Frames survey questions to elicit nuanced, forward-looking insights by prompting respondents to reflect on emerging challenges, future directions, or the practical impact of recent RAG advancements, rather than limiting questions to static descriptions or past developments.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 175:</span> <span class="node-desc">Designs survey items that probe both practical applications and theoretical advancements in RAG, enabling the collection of insights from a diverse respondent pool (e.g., practitioners and researchers) and supporting multi-faceted analysis of field progress.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 246:</span> <span class="node-desc">Designs survey items that elicit actionable insights by prompting respondents to compare, contrast, or critically evaluate the impact of specific RAG innovations (e.g., asking for concrete advantages, disadvantages, or use-case suitability of new methods), rather than merely reporting awareness or frequency of use.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 107:</span> <span class="node-desc">Frames survey questions or sections to elicit nuanced perspectives on recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering) by prompting respondents to compare, critique, or reflect on the impact, limitations, or open challenges of these developments, rather than merely listing or describing them.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 288:</span> <span class="node-desc">Frames survey questions to elicit both high-level perspectives and concrete, actionable insights (e.g., by combining open-ended prompts with targeted multiple-choice or ranking questions), enabling nuanced understanding of RAG progress and challenges.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 169:</span> <span class="node-desc">Frames survey questions to elicit actionable insights or expert perspectives that can inform future research directions or practical improvements in RAG, rather than merely collecting surface-level opinions or general feedback.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 24:</span> <span class="node-desc">Frames survey questions to elicit nuanced practitioner perspectives on both current challenges and future directions in RAG, demonstrating awareness of the field’s evolving landscape and encouraging actionable insights.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 84:</span> <span class="node-desc">Identifies and critically discusses open challenges, limitations, and future directions in RAG, demonstrating awareness of unresolved issues and ongoing debates within the research community.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 104:</span> <span class="node-desc">Frames survey questions to elicit nuanced, experience-based insights from respondents (e.g., asking for specific challenges faced, concrete examples, or personal perspectives on RAG advancements), rather than relying solely on generic or factual queries. This approach enables the survey to capture depth and diversity of expertise within the field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 72:</span> <span class="node-desc">Structures the survey to elicit actionable insights from respondents by including questions that probe for opinions on unresolved issues, preferences among competing approaches, or anticipated future directions, rather than limiting to factual recall or generic attitudes.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 177:</span> <span class="node-desc">Structures the survey to elicit actionable insights from knowledgeable respondents, such as by including open-ended questions that invite expert perspectives on unresolved challenges, future directions, or practical deployment issues in RAG.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 48:</span> <span class="node-desc">Frames survey questions to elicit nuanced, experience-based insights from respondents (e.g., asking for specific papers read, techniques used, or challenges faced), rather than relying solely on generic or superficial prompts. This approach enables the survey to capture expert perspectives and emerging trends, distinguishing it from surveys that only assess basic familiarity or opinions.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 278:</span> <span class="node-desc">Demonstrates awareness of the evolving landscape by explicitly referencing or probing for the most recent advancements, open research questions, or future directions in RAG, ensuring the survey remains current and forward-looking.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 98:</span> <span class="node-desc">Proposes additional survey questions that are not only directly relevant to the requested focus (practical implementation of context engineering in RAG), but also demonstrate awareness of real-world challenges, evaluation strategies, and ethical considerations, thereby enriching the survey’s practical utility and depth.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 18:</span> <span class="node-desc">Designs survey questions that not only cover the latest RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering) but also elicit nuanced, actionable insights by prompting respondents to reflect on practical experiences, challenges, and future directions, rather than merely assessing familiarity or listing features.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 82:</span> <span class="node-desc">Frames survey questions to elicit respondents' nuanced perspectives, experiences, or critical evaluations of RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), rather than merely testing factual recall or definitions.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 296:</span> <span class="node-desc">Designs survey questions that not only cover technical aspects but also probe for expert opinions on open challenges, future directions, and practical implications, thereby eliciting actionable insights beyond surface-level understanding.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 50:</span> <span class="node-desc">Frames survey questions or sections to elicit insights on both technical progress and practical implications (such as deployment challenges, real-world applications, or industry adoption), thereby ensuring the survey captures a holistic view of the field’s evolution.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 60:</span> <span class="node-desc">Frames survey questions to elicit both subjective experiences and actionable feedback from practitioners, such as challenges faced, improvement suggestions, and future research priorities, thereby enabling the survey to capture nuanced, real-world insights beyond factual knowledge.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 208:</span> <span class="node-desc">Structures the survey to elicit actionable, research-relevant feedback by targeting open-ended, thought-provoking questions that encourage respondents to reflect on practical applications, limitations, and future directions of RAG, rather than merely soliciting definitions or opinions.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 135:</span> <span class="node-desc">Integrates open-ended prompts that encourage respondents to identify and elaborate on perceived technical hurdles, limitations, or open research questions in RAG, fostering collection of actionable, field-driven insights.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 29:</span> <span class="node-desc">Designs survey questions that not only cover core RAG topics but also probe for nuanced respondent perspectives on emerging challenges, future directions, and practical implications, moving beyond surface-level inquiry to elicit expert insight.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 205:</span> <span class="node-desc">Frames survey questions or sections to actively prompt critical reflection or comparison (e.g., asking about trade-offs, limitations, or open challenges in RAG), encouraging deeper engagement and analysis rather than passive information recall.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 266:</span> <span class="node-desc">Frames survey questions to actively encourage critical reflection and forward-looking discussion (e.g., by prompting respondents to speculate on future breakthroughs or challenges in RAG), thereby fostering deeper engagement and insight beyond factual recall.</span></div></li></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-7:</span> <span class="node-desc">Label: Advanced Survey Design on RAG Insights  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 140:</span> <span class="node-desc">Crafts survey questions that not only reference recent RAG advancements but also probe for nuanced respondent insights into their mechanisms, trade-offs, and practical implications, enabling the collection of actionable, expert-level feedback rather than surface-level opinions.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 269:</span> <span class="node-desc">Designs survey questions that probe for critical analysis, synthesis, or evaluation of RAG developments (e.g., trade-offs, limitations, or future directions), rather than limiting to factual recall or surface-level comprehension.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 77:</span> <span class="node-desc">Frames recent RAG advancements through comparative analysis, highlighting how new methods improve upon or differ from prior approaches, and articulates the significance of these changes for practitioners or researchers.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 89:</span> <span class="node-desc">Integrates questions that explicitly connect recent RAG advancements to practical implications or real-world applications, prompting respondents to reflect on impact, adoption barriers, or integration challenges, thus elevating the survey's relevance and insightfulness.</span></div></li></ul></details></li><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-0:</span> <span class="node-desc">Label: Nuanced Survey Design on RAG Advances  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 234:</span> <span class="node-desc">Designs survey questions that explicitly reference and probe recent, nuanced advancements in RAG (e.g., reasoning-intensive retrieval, context engineering, deep research), demonstrating up-to-date field awareness and ensuring the survey captures cutting-edge trends rather than generic RAG topics.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 189:</span> <span class="node-desc">Frames survey questions that probe not only for factual knowledge but also for nuanced perspectives on recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), eliciting insights into practical challenges, trade-offs, and future directions, thereby enabling the survey to capture expert-level understanding and emerging trends.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 0:</span> <span class="node-desc">Designs survey questions that probe not only for general familiarity or opinions, but also elicit nuanced insights about recent technical advances (e.g., deep research, reasoning-intensive retrieval, context engineering), demonstrating up-to-date awareness and engagement with the evolving RAG landscape.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 78:</span> <span class="node-desc">Frames survey questions and answer choices to probe not only factual knowledge but also respondents' understanding of nuanced trade-offs, open challenges, and the implications of recent RAG advancements (e.g., context engineering, reasoning-intensive retrieval), thereby eliciting deeper insights beyond surface-level familiarity.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 201:</span> <span class="node-desc">Frames survey questions that not only reference recent RAG advancements (such as deep research, reasoning-intensive retrieval, and context engineering) but also demonstrate nuanced understanding by prompting respondents to explain, compare, or critically assess these concepts, thereby eliciting substantive insights from knowledgeable participants.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 108:</span> <span class="node-desc">Frames survey questions to explicitly probe respondents' awareness and opinions on cutting-edge subtopics (e.g., deep research, reasoning-intensive retrieval, context engineering), ensuring the survey captures the latest field-specific advancements rather than generic RAG knowledge.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 102:</span> <span class="node-desc">Demonstrates nuanced understanding of the RAG research landscape by formulating survey questions that probe both technical advancements (e.g., deep research, reasoning-intensive retrieval, context engineering) and their practical implications, enabling collection of insights from diverse stakeholders and expertise levels.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 7:</span> <span class="node-desc">Frames survey content to not only enumerate recent RAG advancements but also clearly distinguishes their unique mechanisms, challenges, and research directions, enabling respondents to demonstrate nuanced understanding rather than rote recall.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 6:</span> <span class="node-desc">Frames survey questions to elicit nuanced, open-ended insights about recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), rather than relying solely on generic or closed multiple-choice formats. Demonstrates an understanding of the field's complexity and encourages expert-level responses.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 238:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating questions that probe both foundational concepts and emerging research directions (e.g., deep research, reasoning-intensive retrieval, context engineering), and distinguishes between established practices and novel innovations within the survey structure.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 260:</span> <span class="node-desc">Frames survey questions to elicit nuanced, field-specific insights about recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), ensuring that prompts distinguish between foundational knowledge and cutting-edge progress.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 251:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating survey questions that probe specific, cutting-edge subtopics (e.g., Deep Research, reasoning-intensive retrieval, context engineering) and their practical implications, rather than relying on generic or superficial prompts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 81:</span> <span class="node-desc">Designs survey questions that probe not only general awareness or usage, but also elicit nuanced perspectives on recent technical advances (e.g., deep research, reasoning-intensive retrieval, context engineering), enabling the survey to capture expert-level insights and emerging trends in RAG.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 52:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating survey questions that probe specific subfields (e.g., deep research, reasoning-intensive retrieval, context engineering) and elicit expert-level insights, rather than relying on generic or superficial prompts.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 76:</span> <span class="node-desc">Frames survey questions to probe not only factual knowledge or usage, but also respondent perspectives on emerging research directions (e.g., deep research, reasoning-intensive retrieval, context engineering), thereby eliciting nuanced insights into both current practice and future trends in RAG.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 236:</span> <span class="node-desc">Frames survey questions to elicit nuanced, forward-looking insights by explicitly prompting respondents to compare, critique, or forecast the impact of recent RAG advancements (e.g., reasoning-intensive retrieval, context engineering), rather than merely listing or describing them. This approach encourages expert engagement and surfaces deeper field understanding.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 204:</span> <span class="node-desc">Synthesizes recent RAG advancements (such as Deep Research, reasoning-intensive retrieval, and context engineering) into targeted, field-specific survey questions that probe both technical understanding and practical implications, demonstrating nuanced engagement with current research directions.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 190:</span> <span class="node-desc">Frames survey questions that probe for nuanced understanding of recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering) and elicit both breadth and depth of respondent knowledge, rather than relying solely on superficial familiarity or binary yes/no options.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 250:</span> <span class="node-desc">Presents survey questions that probe nuanced, current challenges or open research questions in RAG (e.g., trade-offs in context engineering, limitations of reasoning-intensive retrieval), demonstrating awareness of the field’s evolving frontiers rather than only summarizing established knowledge.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 270:</span> <span class="node-desc">Frames survey questions to elicit nuanced, expert-level insights about recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), demonstrating awareness of current research directions and challenges rather than relying solely on generic or superficial queries.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 15:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating survey questions that probe not only for definitions and applications, but also for emerging subfields (e.g., reasoning-intensive retrieval, context engineering, Deep Research), their interrelations, and open research challenges, thereby reflecting up-to-date domain expertise.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 221:</span> <span class="node-desc">Frames survey questions to probe not only factual knowledge but also the respondent's understanding of nuanced advancements (e.g., reasoning-intensive retrieval, context engineering), ensuring the survey captures depth of expertise and recent trends rather than just surface-level familiarity.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 218:</span> <span class="node-desc">Frames survey questions in a way that actively tests nuanced understanding of distinctions between RAG and related concepts (e.g., RAR, context engineering), rather than merely recalling definitions, thereby eliciting deeper engagement and diagnostic insight into respondent expertise.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 23:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating survey questions that probe not only general awareness but also specific, emerging subfields (e.g., reasoning-intensive retrieval, context engineering, knowledge distillation, neural ranking techniques), thereby enabling the survey to capture expert-level insights and differentiate between superficial and in-depth respondent knowledge.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 73:</span> <span class="node-desc">Frames survey questions to elicit nuanced, expert-level insights on recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), demonstrating awareness of current research frontiers and open challenges rather than only reiterating generic or introductory content.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 115:</span> <span class="node-desc">Frames survey questions to elicit nuanced, actionable feedback on specific recent advancements in RAG (such as deep research, reasoning-intensive retrieval, and context engineering), rather than relying on generic or superficial queries. Demonstrates awareness of current research frontiers and crafts items that probe respondents' familiarity, opinions, or experiences with these targeted developments.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 17:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating survey questions or structure that specifically reference and probe into cutting-edge topics (e.g., Deep Research, reasoning-intensive retrieval, context engineering), rather than merely listing them or treating them superficially.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 279:</span> <span class="node-desc">Demonstrates nuanced understanding of RAG subfields by crafting survey questions that probe not only general awareness but also specific technical challenges, recent innovations, and future directions in areas like deep research, reasoning-intensive retrieval, and context engineering. Questions are tailored to elicit expert-level insights and reflect up-to-date trends in the field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 299:</span> <span class="node-desc">Frames survey questions to elicit expert-level insights, practical experiences, or nuanced opinions about RAG advancements (e.g., Deep Research, reasoning-intensive retrieval, context engineering), rather than relying on generic or surface-level items. Demonstrates awareness of current research frontiers and tailors questions to probe for depth and specificity.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 230:</span> <span class="node-desc">Demonstrates nuanced understanding of RAG by formulating questions that probe both foundational knowledge and recent, domain-specific advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), enabling the survey to capture both breadth and depth of expertise.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 292:</span> <span class="node-desc">Presents a survey that not only lists or describes recent RAG advancements but also explicitly structures the content as a functional survey instrument—posing clear, answerable questions or prompts that directly elicit participant responses on specific RAG topics (e.g., deep research, reasoning-intensive retrieval, context engineering), thereby enabling actionable data collection.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 280:</span> <span class="node-desc">Designs survey questions that probe not only factual knowledge but also the respondent's ability to critically evaluate, compare, or synthesize recent RAG advancements (e.g., asking for opinions on the impact of context engineering or trade-offs in reasoning-intensive retrieval), thereby eliciting deeper insights and distinguishing more sophisticated survey instruments.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 186:</span> <span class="node-desc">Frames survey questions to elicit nuanced, expert-level insights about recent RAG advances (e.g., deep research, reasoning-intensive retrieval, context engineering), demonstrating awareness of current research frontiers and encouraging thoughtful, substantive responses.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 231:</span> <span class="node-desc">Frames survey questions to elicit nuanced, domain-specific insights about recent RAG advancements (e.g., deep research, reasoning-intensive retrieval, context engineering), demonstrating awareness of current research directions and challenges rather than relying on generic or superficial items.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 45:</span> <span class="node-desc">Demonstrates nuanced understanding of recent RAG advancements by formulating questions that probe specific, cutting-edge techniques (e.g., reasoning-intensive retrieval, context engineering) and their practical implications, rather than only referencing them superficially or generically.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 235:</span> <span class="node-desc">Frames survey questions and structure to elicit nuanced, field-specific insights (e.g., distinguishing between types of reasoning in retrieval, or probing for opinions on context engineering techniques), rather than relying solely on generic or surface-level questions, thereby enabling collection of actionable, research-relevant data.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 66:</span> <span class="node-desc">Frames survey questions to elicit nuanced, open-ended insights about recent RAG advancements (e.g., Deep Research, reasoning-intensive retrieval, context engineering), demonstrating awareness of current research trends and encouraging expert-level responses.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 61:</span> <span class="node-desc">Synthesizes recent research trends and advanced RAG concepts into clear, targeted survey questions that probe both technical understanding and practical implications, demonstrating an ability to translate complex developments into actionable, respondent-facing items.</span></div></li></ul></details></li></ul></details></li></ul></details></li><li class="level-3"><details class="tree-item" open><summary><div class="node"><span class="node-label">L3-5:</span> <span class="node-desc">Label: Future-Oriented Innovation Exploration  </span></div></summary><ul><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-10:</span> <span class="node-desc">Label: Future-Focused Innovation Insights  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-17:</span> <span class="node-desc">Label: Future-Oriented Speculative Prompts  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 106:</span> <span class="node-desc">Incorporates forward-looking questions that explicitly prompt respondents to speculate on future breakthroughs, trends, or integration opportunities in RAG, thereby capturing both current state and anticipated evolution of the field.</span></div></li><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 19:</span> <span class="node-desc">Incorporates forward-looking or open-ended prompts that invite respondents to speculate on future directions, challenges, or opportunities in RAG, demonstrating an awareness of the evolving nature of the field.</span></div></li></ul></details></li></ul></details></li></ul></details></li><li class="level-3"><details class="tree-item" open><summary><div class="node"><span class="node-label">L3-6:</span> <span class="node-desc">Label: Evidence-Based Response Practices  </span></div></summary><ul><li class="level-2"><details class="tree-item" open><summary><div class="node"><span class="node-label">L2-11:</span> <span class="node-desc">Label: Promoting Evidence-Based Answers  </span></div></summary><ul><li class="level-1"><details class="tree-item" ><summary><div class="node"><span class="node-label">L1-18:</span> <span class="node-desc">Label: Evidence-Based Response Encouragement  </span></div></summary><ul><li class="level-0"><div class="node leaf-node"><span class="node-label">Base 20:</span> <span class="node-desc">Explicitly prompts respondents to provide evidence, examples, or references (such as datasets, case studies, or recent publications) when discussing advancements or challenges, thereby encouraging concrete, verifiable, and research-grounded responses rather than abstract opinions.</span></div></li></ul></details></li></ul></details></li></ul></details></li><li class="level-3"><details class="tree-item" open><summary><div class="node"><span class="node-label">L3-7:</span> <span class="node-desc">Label: Uncategorized Items  </span></div></summary><ul></ul></details></li>
            </ul>
        </body>
        </html>
        