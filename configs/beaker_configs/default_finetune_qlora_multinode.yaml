version: v2
description: open-instruct-finetune-multinode-test
tasks:
  - name: open-instruct-finetune-multinode-test
    replicas: 4
    leaderSelection: true
    hostNetworking: true
    propagateFailure: true
    propagatePreemption: true
    synchronizedStartTimeout: 15m
    image:
      beaker: Yizhongw03/open-instruct-multi-node
    command: [
      '/bin/sh', '-c'
    ]
    arguments: ['
        unset CUDA_LAUNCH_BLOCKING && accelerate launch
        --mixed_precision bf16
        --num_machines 4
        --num_processes 32
        --machine_rank $BEAKER_REPLICA_RANK
        --main_process_ip $BEAKER_LEADER_REPLICA_HOSTNAME
        --main_process_port 29400
        open_instruct/finetune.py
        --model_name_or_path /net/nfs.cirrascale/allennlp/yizhongw/hf_llama2_models/70B
        --tokenizer_name /net/nfs.cirrascale/allennlp/yizhongw/hf_llama2_models/70B
        --use_slow_tokenizer
        --train_file /net/nfs.cirrascale/allennlp/yizhongw/open-instruct-public/data/processed/tulu/tulu_v1_mix.jsonl
        --use_flash_attn
        --use_lora
        --use_qlora
        --lora_rank 64
        --lora_alpha 64
        --lora_dropout 0.1
        --gradient_checkpointing
        --max_seq_length 2048
        --preprocessing_num_workers 64
        --per_device_train_batch_size 1
        --gradient_accumulation_steps 4
        --learning_rate 2e-5
        --lr_scheduler_type linear
        --warmup_ratio 0.03
        --weight_decay 0.
        --num_train_epochs 5
        --output_dir /output/
        --with_tracking
        --report_to tensorboard
        --logging_steps 1
    ']
    envVars:
      - name: CUDA_DEVICE_ORDER
        value: PCI_BUS_ID
      - name: TRANSFORMERS_CACHE
        value: ./cache/
      - name: WANDB_PROJECT
        value: open-instruct
      - name: WANDB_WATCH
        value: false
      - name: WANDB_LOG_MODEL
        value: false
      - name: WANDB_DISABLED
        value: true
      - name: NCCL_NET
        value: IB
      - name: NCCL_DEBUG
        value: INFO
    datasets:
      - mountPath: /net/nfs.cirrascale
        source:
          hostPath: /net/nfs.cirrascale
    result:
      path: /output
    resources:
      gpuCount: 8
    context:
      priority: high
    constraints:
      cluster: [ai2/jupiter]